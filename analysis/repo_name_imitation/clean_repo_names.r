df = read.csv('data/repository_names_count_events_top1000.csv')
dfs = read.csv('data/repository_names_count_events_top1000_sorted_by_name.csv.csv')
dfs = read.csv('data/repository_names_count_events_top1000_sorted_by_name.csv')
head(dfs)
sum(dfs$aggregate_counts)
dfs = read.csv('data/repository_names_count_events_top1000_sorted_by_name.csv', asis=TRUE)
dfs = read.csv('data/repository_names_count_events_top1000_sorted_by_name.csv', stringsAsFactors=FALSE)
sum(dfs$aggregate_counts)
dfs$aggregate_counts
as.integer(dfs$aggregate_counts)
sum(dfs$aggregate_counts)
dfs$aggregate_counts = as.integer(dfs$aggregate_counts)
sum(dfs$aggregate_counts)
sum(dfs$aggregate_counts,na.rm=TRUE)
unique(dfs$aggregate_counts)
dfs$aggregate_counts
dfs = read.csv('data/repository_names_count_events_top1000_sorted_by_name.csv', stringsAsFactors=FALSE)
dfs$aggregate_counts
sub(dfs$aggregate_counts, '', '0')
sub(dfs$aggregate_counts, pattern='', '0')
sub(x=dfs$aggregate_counts, pattern='', replacement='0')
as.integer(sub(x=dfs$aggregate_counts, pattern='', replacement='0'))
?as.integer
as.numeric(sub(x=dfs$aggregate_counts, pattern='', replacement='0'))
as.integer(sub(x=dfs$aggregate_counts, pattern='', replacement='0'dfs = read.csv('data/repository_names_count_events_top1000_sorted_by_name.csv', stringsAsFactors=FALSE)))
dfs = read.csv('data/repository_names_count_events_top1000_sorted_by_name.csv', stringsAsFactors=FALSE)
sub(x=dfs$aggregate_counts, pattern='', replacement='0')
as.numeric(sub(x=dfs$aggregate_counts, pattern='', replacement='0'))
as.numeric(sub(x=dfs$aggregate_counts, pattern='', replacement='0'))sum(dfs$aggregate_counts)
dfs$aggregate_counts = as.numeric(sub(x=dfs$aggregate_counts, pattern='', replacement='0'))
sum(dfs$aggregate_counts)
table(dfs$aggregate_counts)
sum(dfs$aggregate_counts, na.rm=TRUE)
sum(dfs$count)
proportion = sum(dfs$aggregate_counts, na.rm=TRUE)/sum(dfs$count)
proportion
query = "SELECT repository_name, lower(repository_name) as repository_name_lower, count(lower(repository_name_lower)) as count FROM [githubarchive:github.timeline] group by repository_name_lower, repository_name order by count desc LIMIT 1000"
df = query_exec(query, 'metacommunities') 
library(bigrquery)
df = query_exec(query, 'metacommunities') 
query = "SELECT repository_name, lower(repository_name) as repository_name_lower, count(lower(repository_name)) as count FROM [githubarchive:github.timeline] group by repository_name_lower, repository_name order by count desc LIMIT 1000"
df = query_exec(query, 'metacommunities') 
head(df)
write.csv(df, 'data/repository_names_count_events_top1000.csv')
event_total = 289000000
sum(df$count)/event_total * 100
sub(x=df$repository_name_lower, '$\.', '')
sub(x=df$repository_name_lower, '$\\.', '')
repo_names = sub(x=df$repository_name_lower, '$\\.', '')
df$repo_names_clean = repo_names
tail(df$repo_names_clean)
df = df[order(df$repo_names_clean),]
head(df)
tail(df)
View(df)
sbu(x='.dit', '$\\.', '')
sub(x='.dit', '$\\.', '')
sub(x='.dit', '$.', '')
sub(x='.dit', '$//.', '')
sub(x='.dit', '.', '')
sub(x='.dit', '^.', '')
sub(x='.dit', '^.', '')
sub(x='.dit', '^//.', '')
sub(x='.dit', '^\.', '')
sub(x='.dit', '^\\.', '')
df$repo_names_clean = sub(x=df$repository_name_lower, '^\\.', '')
df = df[order(df$repo_names_clean),]
View(df)
savehistory(file='clean_repo_names.r')
