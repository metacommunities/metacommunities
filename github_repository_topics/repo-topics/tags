!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.9~svn20110310	//
REDIS_HOST	3-Analyse_repo_topic_coverage.py	/^REDIS_HOST = '127.0.0.1'$/;"	v
X_test	repo_domain_classifier.py	/^X_test = indicator_m[mask]$/;"	v
X_train	repo_domain_classifier.py	/^X_train = indicator_m[split,]$/;"	v
Y_pred	repo_domain_classifier.py	/^Y_pred = clf.predict(X_test)$/;"	v
Y_test	repo_domain_classifier.py	/^Y_test = y[mask].values$/;"	v
Y_train	repo_domain_classifier.py	/^Y_train = y[split].values$/;"	v
a_df	1b_Generate_repo_details.py	/^a_df = aggregate_many_queries(df)$/;"	v
aggregate_many_queries	1b_Generate_repo_details.py	/^def aggregate_many_queries(df):$/;"	f
alpha	1c_Validate_Repo_Topics.py	/^alpha = 1.5$/;"	v
alpha	repo_domain_classifier.py	/^alpha = 1.5$/;"	v
alpha	social_media.py	/^alpha = 1.5$/;"	v
alpha	social_media_proper.py	/^alpha = 1.5$/;"	v
api_df	1a_Generate_repo_topic_data.py	/^api_df = construct_repo_df(api_query, description=False)$/;"	v
api_query	1a_Generate_repo_topic_data.py	/^api_query = 'api|sdk'$/;"	v
args	repo_creation_dates.py	/^    args = parser.parse_args()$/;"	v
ax	3-Analyse_repo_topic_coverage.py	/^ax = plt.gca()$/;"	v
beta	1c_Validate_Repo_Topics.py	/^beta = 1.5$/;"	v
beta	repo_domain_classifier.py	/^beta = 1.5$/;"	v
beta	social_media.py	/^beta = 1.5$/;"	v
beta	social_media_proper.py	/^beta = 1.5$/;"	v
bits_to_reponames	restore_repos_redis.py	/^def bits_to_reponames(bits):$/;"	f
book_df	1a_Generate_repo_topic_data.py	/^book_df = construct_repo_df(bookquery)$/;"	v
book_df	generate_repo_data.py	/^book_df = construct_repo_df(bookquery)$/;"	v
bookquery	1a_Generate_repo_topic_data.py	/^bookquery = '|'.join(['book', 'article', 'guide', 'how to', 'manual'])$/;"	v
bookquery	generate_repo_data.py	/^bookquery = '|'.join(['book', 'article', 'guide', 'how to', 'manual'])$/;"	v
bucket_size	restore_repos_redis.py	/^bucket_size = 1000$/;"	v
c	1c_Validate_Repo_Topics.py	/^c  = collections.Counter(words_stemmed)$/;"	v
c_words	1c_Validate_Repo_Topics.py	/^c_words = collections.Counter(words)$/;"	v
cartonmachine_df	1b_Generate_repo_details.py	/^cartonmachine_df = device_specific_repos(query, use_description=False)$/;"	v
cax	3-Analyse_repo_topic_coverage.py	/^cax = divider.append_axes("right", size="5%", pad=0.1)$/;"	v
cbar	3-Analyse_repo_topic_coverage.py	/^cbar = f.colorbar(mat, ticks=[0, 6, 12], cax=cax)$/;"	v
clf	repo_domain_classifier.py	/^clf = nb.BernoulliNB(alpha = 1.5)$/;"	v
cloud_df	1b_Generate_repo_details.py	/^cloud_df = device_specific_repos(query, use_description=True)$/;"	v
compiler_df	1a_Generate_repo_topic_data.py	/^compiler_df = construct_repo_df(compiler_query, description=False)$/;"	v
compiler_df	generate_repo_data.py	/^compiler_df = compiler_df2$/;"	v
compiler_df2	generate_repo_data.py	/^compiler_df2 = construct_repo_df(compiler_query, description=False)$/;"	v
compiler_query	1a_Generate_repo_topic_data.py	/^compiler_query = '|'.join(compilers.name.str.strip()).lower().replace('++', '\\\\\\+\\\\\\+')$/;"	v
compiler_query	generate_repo_data.py	/^compiler_query = '|'.join(compilers.name.str.strip()).lower().replace('++', '\\\\\\+\\\\\\+')$/;"	v
compilers	1a_Generate_repo_topic_data.py	/^compilers = pd.read_csv('topic_lists\/compilers.csv', header=None, names = ['name'])$/;"	v
compilers	generate_repo_data.py	/^compilers = pd.read_csv('topic_lists\/compilers.csv', header=None, names = ['name'])$/;"	v
conf	1d_Generate_repo_dates.py	/^conf = ConfigParser.ConfigParser()$/;"	v
conf	4_Analyse_forking.py	/^conf = ConfigParser.ConfigParser()$/;"	v
conf	repo_creation_dates.py	/^conf = ConfigParser.ConfigParser()$/;"	v
construct_id_repo_hashset	restore_repos_redis.py	/^def construct_id_repo_hashset(repo_id):$/;"	f
construct_repo_df	1a_Generate_repo_topic_data.py	/^def construct_repo_df(query, description = False, local =True):$/;"	f
construct_repo_df	generate_repo_data.py	/^def construct_repo_df(query, description = True):$/;"	f
construct_repo_df_using_local	1a_Generate_repo_topic_data.py	/^def construct_repo_df_using_local(query):$/;"	f
construct_repo_id_set	restore_repos_redis.py	/^def construct_repo_id_set():$/;"	f
convert_set_to_bits	restore_repos_redis.py	/^def convert_set_to_bits(set_to_convert, repo_id_dict, delete_existing = False):$/;"	f
create_domain_training_set	1c_Validate_Repo_Topics.py	/^def create_domain_training_set(domain):$/;"	f
css_df	1a_Generate_repo_topic_data.py	/^css_df = construct_repo_df(cssquery)$/;"	v
css_df	generate_repo_data.py	/^css_df = construct_repo_df(cssquery)$/;"	v
csslist	1a_Generate_repo_topic_data.py	/^csslist = pd.read_csv('topic_lists\/css_list.csv', header=None, names = ['name'])$/;"	v
csslist	generate_repo_data.py	/^csslist = pd.read_csv('topic_lists\/css_list.csv', header=None, names = ['name'])$/;"	v
cssquery	1a_Generate_repo_topic_data.py	/^cssquery = 'css|'+'|'.join(csslist['name'][:30]).lower()$/;"	v
cssquery	generate_repo_data.py	/^cssquery = 'css|'+'|'.join(csslist['name'][:30]).lower()$/;"	v
data	3-Analyse_repo_topic_coverage.py	/^data = intersect_norm_df.transpose().as_matrix()$/;"	v
data_query1	1a_Generate_repo_topic_data.py	/^data_query1 = 'statistic|data scien|'+'|'.join(datasoftware['name'][:50].str.strip()).lower()$/;"	v
data_query1	generate_repo_data.py	/^data_query1 = '|'.join(datasoftware['name'][:50].str.strip()).lower()$/;"	v
data_query2	1a_Generate_repo_topic_data.py	/^data_query2 = '|'.join(datasoftware['name'][50:100].str.strip()).lower()$/;"	v
data_query2	generate_repo_data.py	/^data_query2 = '|'.join(datasoftware['name'][50:100].str.strip()).lower()$/;"	v
data_query3	1a_Generate_repo_topic_data.py	/^data_query3 = '|'.join(datasoftware['name'][100:].str.strip()).lower()$/;"	v
data_query3	generate_repo_data.py	/^data_query3 = '|'.join(datasoftware['name'][100:].str.strip()).lower()$/;"	v
datasoftware	1a_Generate_repo_topic_data.py	/^datasoftware = pd.read_csv('topic_lists\/data_stats.csv', header=None, names = ['name'])$/;"	v
datasoftware	generate_repo_data.py	/^datasoftware = pd.read_csv('topic_lists\/data_stats.csv', header=None, names = ['name'])$/;"	v
datastat_df	1a_Generate_repo_topic_data.py	/^datastat_df = construct_repo_df(data_query1, description=False, local=True)$/;"	v
datastat_df	1a_Generate_repo_topic_data.py	/^datastat_df = pd.concat([datastat_df, datastat_df2, datastat_df3])$/;"	v
datastat_df	generate_repo_data.py	/^datastat_df = construct_repo_df(data_query1)$/;"	v
datastat_df	generate_repo_data.py	/^datastat_df = pd.concat([datastat_df, datastat_df2, datastat_df3])$/;"	v
datastat_df2	1a_Generate_repo_topic_data.py	/^datastat_df2 = construct_repo_df(data_query2, description=False, local=True)$/;"	v
datastat_df2	generate_repo_data.py	/^datastat_df2 = construct_repo_df(data_query2)$/;"	v
datastat_df3	1a_Generate_repo_topic_data.py	/^datastat_df3 = construct_repo_df(data_query3, description=False, local=True)$/;"	v
datastat_df3	generate_repo_data.py	/^datastat_df3 = construct_repo_df(data_query3)$/;"	v
db_df	1a_Generate_repo_topic_data.py	/^db_df = construct_repo_df(dbquery, description=False)$/;"	v
db_df	generate_repo_data.py	/^db_df = construct_repo_df(dbquery, description=False)$/;"	v
dblist	1a_Generate_repo_topic_data.py	/^dblist = pd.read_csv('topic_lists\/db_list.csv', header=None)$/;"	v
dblist	generate_repo_data.py	/^dblist = pd.read_csv('topic_lists\/db_list.csv', header=None)$/;"	v
dbquery	1a_Generate_repo_topic_data.py	/^dbquery = '|'.join(dblist['name']).lower()$/;"	v
dbquery	generate_repo_data.py	/^dbquery = '|'.join(dblist['name']).lower()$/;"	v
delete	1a_Generate_repo_topic_data.py	/^delete = False$/;"	v
device_query	1a_Generate_repo_topic_data.py	/^device_query = 'arduino|raspberry|android|ios|blackberry|armv|symbian'$/;"	v
device_query	generate_repo_data.py	/^device_query = 'arduino|raspberry|android|ios|blackberry|armv|symbian'$/;"	v
device_specific_repos	1b_Generate_repo_details.py	/^def device_specific_repos(query, use_description = False):$/;"	f
devices_df	1a_Generate_repo_topic_data.py	/^devices_df = construct_repo_df(device_query)$/;"	v
devices_df	generate_repo_data.py	/^devices_df = construct_repo_df(device_query)$/;"	v
df	1b_Generate_repo_details.py	/^df = device_specific_repos('api')$/;"	v
df	1b_Generate_repo_details.py	/^df = device_specific_repos('api|sdk', description=False)$/;"	v
df	1b_Generate_repo_details.py	/^df = pd.DataFrame({'name':['cloud', 'virtual']} )$/;"	v
divider	3-Analyse_repo_topic_coverage.py	/^divider = make_axes_locatable(ax)$/;"	v
doc_df	1a_Generate_repo_topic_data.py	/^doc_df = construct_repo_df(doc_query, description=False)$/;"	v
doc_df	generate_repo_data.py	/^doc_df = construct_repo_df(doc_query, description=False)$/;"	v
doc_query	1a_Generate_repo_topic_data.py	/^doc_query = '\\\\b' + '\\\\b|\\\\b'.join(doc_types.dropna()).lower() + '\\\\b'$/;"	v
doc_query	1a_Generate_repo_topic_data.py	/^doc_query = '|'.join(docs_list.extension.str.strip()).lower()$/;"	v
doc_query	generate_repo_data.py	/^doc_query = '\\\\b' + '\\\\b|\\\\b'.join(doc_types.dropna()).lower() + '\\\\b'$/;"	v
doc_query	generate_repo_data.py	/^doc_query = '|'.join(docs_list.extension.str.strip()).lower()$/;"	v
doc_types	1a_Generate_repo_topic_data.py	/^doc_types = file_formats[docs + pub + refs + pres].filetype$/;"	v
doc_types	generate_repo_data.py	/^doc_types = file_formats[docs + pub + refs + pres].filetype$/;"	v
docs_list	1a_Generate_repo_topic_data.py	/^docs_list = pd.read_csv('topic_lists\/docs.csv', header = None, names = ['extension', 'description'])$/;"	v
docs_list	generate_repo_data.py	/^docs_list = pd.read_csv('topic_lists\/docs.csv', header = None, names = ['extension', 'description'])$/;"	v
domain	1c_Validate_Repo_Topics.py	/^domain = 'tests'$/;"	v
domain	repo_domain_classifier.py	/^domain = 'editors'$/;"	v
domain	social_media_proper.py	/^domain = 'editors'$/;"	v
domain_test	1c_Validate_Repo_Topics.py	/^domain_test = pd.DataFrame(indicator_m[mask], columns = keywords)$/;"	v
domain_test	repo_domain_classifier.py	/^domain_test = pd.DataFrame(indicator_m[mask], columns = keywords)$/;"	v
domain_test	social_media_proper.py	/^domain_test = pd.DataFrame(indicator_m[mask], columns = keywords)$/;"	v
domain_training	1c_Validate_Repo_Topics.py	/^domain_training  = pd.DataFrame(indicator_m[split,], columns =  keywords)$/;"	v
domain_training	repo_domain_classifier.py	/^domain_training  = pd.DataFrame(indicator_m[split,], columns =  keywords)$/;"	v
domain_training	social_media_proper.py	/^domain_training  = pd.DataFrame(indicator_m[split,], columns =  keywords)$/;"	v
dot_df	1a_Generate_repo_topic_data.py	/^dot_df = construct_repo_df(dotquery)$/;"	v
dot_df	generate_repo_data.py	/^dot_df = construct_repo_df(dotquery)$/;"	v
dotquery	1a_Generate_repo_topic_data.py	/^dotquery = 'bash|zsh|tmux|csh|vim|emacs|dot?file'$/;"	v
dotquery	generate_repo_data.py	/^dotquery = 'bash|zsh|tmux|csh|vim|emacs|dot?file'$/;"	v
dst_keys	3-Analyse_repo_topic_coverage.py	/^dst_keys = []$/;"	v
ed_query_1	1a_Generate_repo_topic_data.py	/^ed_query_1 = 'editor|' + '|'.join(editors['name'][:50].str.strip()).lower().replace('++', '\\\\\\+\\\\\\+')$/;"	v
ed_query_1	generate_repo_data.py	/^ed_query_1 = '|'.join(editors['name'][:50].str.strip()).lower().replace('++', '\\\\\\+\\\\\\+')$/;"	v
ed_query_2	1a_Generate_repo_topic_data.py	/^ed_query_2 = '|'.join(editors['name'][50:].str.strip()).lower().replace('++', '\\\\\\+\\\\\\+')$/;"	v
ed_query_2	generate_repo_data.py	/^ed_query_2 = '|'.join(editors['name'][50:].str.strip()).lower().replace('++', '\\\\\\+\\\\\\+')$/;"	v
editor_df	1a_Generate_repo_topic_data.py	/^editor_df = construct_repo_df(ed_query_1,local=True, description=False)$/;"	v
editor_df	1a_Generate_repo_topic_data.py	/^editor_df = editor_df.append(editor_df2)$/;"	v
editor_df	generate_repo_data.py	/^editor_df = construct_repo_df(ed_query_1)$/;"	v
editor_df	generate_repo_data.py	/^editor_df = editor_df.append(editor_df2)$/;"	v
editor_df2	1a_Generate_repo_topic_data.py	/^editor_df2 = construct_repo_df(ed_query_2, local=True)$/;"	v
editor_df2	generate_repo_data.py	/^editor_df2 = construct_repo_df(ed_query_2)$/;"	v
editors	1a_Generate_repo_topic_data.py	/^editors = pd.read_csv('topic_lists\/editors.csv', header = None, names = ['name'])$/;"	v
editors	generate_repo_data.py	/^editors = pd.read_csv('topic_lists\/editors.csv', header = None, names = ['name'])$/;"	v
edu_df	1a_Generate_repo_topic_data.py	/^edu_df = construct_repo_df(edu_query)$/;"	v
edu_query	1a_Generate_repo_topic_data.py	/^edu_query = education.lower()$/;"	v
education	1a_Generate_repo_topic_data.py	/^education = 'mooc|coursera|EdX|khan academy|opencourseware|P2PU|Udacity|Udemy'$/;"	v
evaluate_all_models	repo_domain_classifier.py	/^def  evaluate_all_models(start = 0.5, end=10, step=0.5):$/;"	f
evaluate_all_models	social_media_proper.py	/^def  evaluate_all_models(start = 0.5, end=10, step=0.5):$/;"	f
evaluate_domain_model	repo_domain_classifier.py	/^def evaluate_domain_model(alpha  = 1.5, beta  = 1.5):$/;"	f
evaluate_domain_model	social_media_proper.py	/^def evaluate_domain_model(alpha  = 1.5, beta  = 1.5):$/;"	f
f	3-Analyse_repo_topic_coverage.py	/^f = plt.figure(figsize = (10,10))$/;"	v
file_formats	1a_Generate_repo_topic_data.py	/^file_formats = file_formats.apply(lambda x: x.str.strip().str.lower())$/;"	v
file_formats	1a_Generate_repo_topic_data.py	/^file_formats = pd.read_csv('topic_lists\/file_formats.csv', sep='\\t', header=None, names = ['domain', 'filetype', 'description'])$/;"	v
file_formats	generate_repo_data.py	/^file_formats = file_formats.apply(lambda x: x.str.strip().str.lower())$/;"	v
file_formats	generate_repo_data.py	/^file_formats = pd.read_csv('topic_lists\/file_formats.csv', sep='\\t', header=None, names = ['domain', 'filetype', 'description'])$/;"	v
fork_repos	4_Analyse_forking.py	/^fork_repos = []$/;"	v
forkcount	4_Analyse_forking.py	/^forkcount = spoon.forks_count$/;"	v
forks	4_Analyse_forking.py	/^forks = spoon.get_forks()$/;"	v
fresh_intersects	3-Analyse_repo_topic_coverage.py	/^    fresh_intersects = False$/;"	v
fresh_intersects	3-Analyse_repo_topic_coverage.py	/^    fresh_intersects = True$/;"	v
fs	4_Analyse_forking.py	/^    fs = forks.get_page(page)$/;"	v
full_repo_count_df	2a_Count_repos.py	/^full_repo_count_df = pd.io.gbq.read_gbq(query)$/;"	v
g	4-Analyse-topic-change.py	/^g = Github('rian39', 'inc14ives')$/;"	v
game_df	1a_Generate_repo_topic_data.py	/^game_df = construct_repo_df(game_query)$/;"	v
game_df	generate_repo_data.py	/^game_df = construct_repo_df(game_query)$/;"	v
game_list	1a_Generate_repo_topic_data.py	/^game_list  = ['game', 'xbox', 'playstation', 'wii', 'kinect', 'nintendo', 'minecraft', 'warcraft', 'multiplayer']$/;"	v
game_list	generate_repo_data.py	/^game_list  = ['game', 'xbox', 'playstation', 'wii', 'kinect', 'nintendo', 'minecraft', 'warcraft', 'multiplayer']$/;"	v
game_query	1a_Generate_repo_topic_data.py	/^game_query = '|'.join(game_list)$/;"	v
game_query	generate_repo_data.py	/^game_query = '|'.join(game_list)$/;"	v
generate_repo_data_from_local_archive	repo_creation_dates.py	/^def generate_repo_data_from_local_archive(start = '2013-03-01', days = 1):$/;"	f
gengeolist	1a_Generate_repo_topic_data.py	/^gengeolist  = ['gis', 'geo']$/;"	v
gengeolist	generate_repo_data.py	/^gengeolist  = ['gis', 'geo']$/;"	v
geo_df	1a_Generate_repo_topic_data.py	/^geo_df = construct_repo_df(geoquery)$/;"	v
geo_df	generate_repo_data.py	/^geo_df = construct_repo_df(geoquery)$/;"	v
geolist	1a_Generate_repo_topic_data.py	/^geolist  = pd.read_csv('topic_lists\/geo_gis.csv', header=None, names = ['name'])$/;"	v
geolist	generate_repo_data.py	/^geolist  = pd.read_csv('topic_lists\/geo_gis.csv', header=None, names = ['name'])$/;"	v
geoquery	1a_Generate_repo_topic_data.py	/^geoquery = '|'.join(geolist['name'].str.strip()).lower()$/;"	v
geoquery	1a_Generate_repo_topic_data.py	/^geoquery = geoquery + '|geo|gis'$/;"	v
geoquery	generate_repo_data.py	/^geoquery = '|'.join(geolist['name'].str.strip()).lower()$/;"	v
geoquery	generate_repo_data.py	/^geoquery = geoquery + '|geo|gis'$/;"	v
get_creation_dates	1d_Generate_repo_dates.py	/^def get_creation_dates(query, number):$/;"	f
get_creation_dates_from_API	repo_creation_dates.py	/^def get_creation_dates_from_API(query, number):$/;"	f
get_repo_by_id	restore_repos_redis.py	/^def get_repo_by_id(id):$/;"	f
get_repos_by_ids	restore_repos_redis.py	/^def get_repos_by_ids(ids):$/;"	f
gh	4_Analyse_forking.py	/^gh = gh.Github(login_or_token = conf.get('github', 'user'),$/;"	v
git	1d_Generate_repo_dates.py	/^git = gh.Github(login_or_token = conf.get('github', 'user'),$/;"	v
git	repo_creation_dates.py	/^git = gh.Github(login_or_token = conf.get('github', 'user'),$/;"	v
git_df	1a_Generate_repo_topic_data.py	/^git_df = construct_repo_df(git_query, description=False)$/;"	v
git_df	generate_repo_data.py	/^git_df = construct_repo_df(git_query, description=False)$/;"	v
git_query	1a_Generate_repo_topic_data.py	/^git_query = 'git|(github)'$/;"	v
git_query	generate_repo_data.py	/^git_query = 'git|(github)'$/;"	v
icon_df	1a_Generate_repo_topic_data.py	/^icon_df = construct_repo_df(iconquery)$/;"	v
icon_df	generate_repo_data.py	/^icon_df = construct_repo_df(iconquery)$/;"	v
iconlist	1a_Generate_repo_topic_data.py	/^iconlist = ['icon','font', 'emoji', 'theme']$/;"	v
iconlist	generate_repo_data.py	/^iconlist = ['icon','font', 'emoji', 'theme']$/;"	v
iconquery	1a_Generate_repo_topic_data.py	/^iconquery = '|'.join(iconlist)$/;"	v
iconquery	generate_repo_data.py	/^iconquery = '|'.join(iconlist)$/;"	v
id_repo	restore_repos_redis.py	/^id_repo = rs['id_repo']$/;"	v
ide_df	1a_Generate_repo_topic_data.py	/^ide_df = construct_repo_df(ide_query, description=False,local=True)$/;"	v
ide_df	generate_repo_data.py	/^ide_df = construct_repo_df(ide_query, description=False)$/;"	v
ide_query	1a_Generate_repo_topic_data.py	/^ide_query = '|'.join(ides['name'].str.strip()).lower().replace('++', '\\\\\\+\\\\\\+')$/;"	v
ide_query	generate_repo_data.py	/^ide_query = '|'.join(ides['name'].str.strip()).lower().replace('++', '\\\\\\+\\\\\\+')$/;"	v
ides	1a_Generate_repo_topic_data.py	/^ides = pd.read_csv('topic_lists\/ide_list.csv', header=None, names = ['name']).drop_duplicates()$/;"	v
ides	generate_repo_data.py	/^ides = pd.read_csv('topic_lists\/ide_list.csv', header=None, names = ['name']).drop_duplicates()$/;"	v
image_df	1a_Generate_repo_topic_data.py	/^image_df = construct_repo_df(image_query)$/;"	v
image_df	generate_repo_data.py	/^image_df = construct_repo_df(image_query)$/;"	v
image_query	1a_Generate_repo_topic_data.py	/^image_query = '|'.join(image_terms)$/;"	v
image_query	generate_repo_data.py	/^image_query = '|'.join(image_terms)$/;"	v
image_terms	1a_Generate_repo_topic_data.py	/^image_terms = ['video','image','jpeg', 'mp3', 'mpeg', 'audio', 'sound','photograph', 'camera', 'webcam']$/;"	v
image_terms	generate_repo_data.py	/^image_terms = ['video','image','jpeg', 'mp3', 'mpeg', 'audio', 'sound','photograph', 'camera', 'webcam']$/;"	v
index	3-Analyse_repo_topic_coverage.py	/^index = key_sizes.keys()$/;"	v
indicator_m	1c_Validate_Repo_Topics.py	/^indicator_m = np.zeros([sm.shape[0], len(keywords)])$/;"	v
indicator_m	repo_domain_classifier.py	/^indicator_m = np.zeros([sm.shape[0], len(keywords)])$/;"	v
indicator_m	social_media.py	/^indicator_m = np.zeros([sm.shape[0], len(keywords)])$/;"	v
indicator_m	social_media_proper.py	/^indicator_m = np.zeros([sm.shape[0], len(keywords)])$/;"	v
int_m	3-Analyse_repo_topic_coverage.py	/^int_m  = intersect_pivot_df.as_matrix()$/;"	v
integration_df	1a_Generate_repo_topic_data.py	/^integration_df = construct_repo_df(integration_query, description = True)$/;"	v
integration_df	generate_repo_data.py	/^integration_df = construct_repo_df(integration_query, description = True)$/;"	v
integration_list	1a_Generate_repo_topic_data.py	/^integration_list = pd.read_csv('topic_lists\/integration.csv', header =None, names = ['name'])$/;"	v
integration_list	generate_repo_data.py	/^integration_list = pd.read_csv('topic_lists\/integration.csv', header =None, names = ['name'])$/;"	v
integration_query	1a_Generate_repo_topic_data.py	/^integration_query = '|'.join(integration_list.name.str.strip()).lower()$/;"	v
integration_query	generate_repo_data.py	/^integration_query = '|'.join(integration_list.name.str.strip()).lower()$/;"	v
intersect_df	3-Analyse_repo_topic_coverage.py	/^    intersect_df = pd.DataFrame({'domain1':src_keys, 'domain2':dst_keys, 'intersection':intersects}, columns=['domain1', 'domain2', 'intersection'])$/;"	v
intersect_df	3-Analyse_repo_topic_coverage.py	/^    intersect_df = pd.read_csv('data\/intersect_df.csv', header=0)$/;"	v
intersect_df	3-Analyse_repo_topic_coverage.py	/^intersect_df = intersect_df.set_index('domain1')$/;"	v
intersect_df	3-Analyse_repo_topic_coverage.py	/^intersect_df = intersect_df.sort(['domain1', 'domain2'])$/;"	v
intersect_norm_df	3-Analyse_repo_topic_coverage.py	/^intersect_norm_df = intersect_pivot_df.apply(np.log1p)$/;"	v
intersect_pivot	3-Analyse_repo_topic_coverage.py	/^intersect_pivot = intersect_df.pivot('domain1', 'domain2', 'intersection')$/;"	v
intersect_pivot_df	3-Analyse_repo_topic_coverage.py	/^intersect_pivot_df = intersect_pivot.fillna(value=0, inplace=False)$/;"	v
intersects	3-Analyse_repo_topic_coverage.py	/^intersects = []$/;"	v
ip_df	1a_Generate_repo_topic_data.py	/^ip_df = construct_repo_df(ipquery)$/;"	v
ip_df	generate_repo_data.py	/^ip_df = construct_repo_df(ipquery)$/;"	v
iplist	1a_Generate_repo_topic_data.py	/^iplist  = pd.read_csv('topic_lists\/internet_protocols.csv', header=None, names = ['name'])$/;"	v
iplist	generate_repo_data.py	/^iplist  = pd.read_csv('topic_lists\/internet_protocols.csv', header=None, names = ['name'])$/;"	v
ipquery	1a_Generate_repo_topic_data.py	/^ipquery = '|'.join(iplist['name'].str.strip()).lower()$/;"	v
ipquery	generate_repo_data.py	/^ipquery = '|'.join(iplist['name'].str.strip()).lower()$/;"	v
javascript_df	1a_Generate_repo_topic_data.py	/^javascript_df = construct_repo_df(javascript_query)$/;"	v
javascript_df	generate_repo_data.py	/^javascript_df = construct_repo_df(javascript_query)$/;"	v
javascript_list	1a_Generate_repo_topic_data.py	/^javascript_list = pd.read_csv('topic_lists\/javascript_front.csv', header=None, names=['name'])$/;"	v
javascript_list	generate_repo_data.py	/^javascript_list = pd.read_csv('topic_lists\/javascript_front.csv', header=None, names=['name'])$/;"	v
javascript_query	1a_Generate_repo_topic_data.py	/^javascript_query = 'widget|'+'|'.join(javascript_list.name.str.strip()).lower()$/;"	v
javascript_query	generate_repo_data.py	/^javascript_query = 'widget|'+'|'.join(javascript_list.name.str.strip()).lower()$/;"	v
key_sizes	3-Analyse_repo_topic_coverage.py	/^key_sizes = {k:red.scard(k) for k in keys}$/;"	v
keys	1c_Validate_Repo_Topics.py	/^keys = red.keys('*')$/;"	v
keys	3-Analyse_repo_topic_coverage.py	/^keys = keys_all.difference(keys_int)$/;"	v
keys	3-Analyse_repo_topic_coverage.py	/^keys = list(keys)$/;"	v
keys_all	3-Analyse_repo_topic_coverage.py	/^keys_all = set(red.keys('*'))$/;"	v
keys_int	3-Analyse_repo_topic_coverage.py	/^keys_int = set(red.keys('*:*'))$/;"	v
keywords	1c_Validate_Repo_Topics.py	/^keywords = [t[0] for t in terms]$/;"	v
keywords	repo_domain_classifier.py	/^keywords = [t[0] for t in terms]$/;"	v
keywords	social_media.py	/^keywords = [t[0] for t in terms]$/;"	v
keywords	social_media_proper.py	/^keywords = [t[0] for t in terms]$/;"	v
labs	3-Analyse_repo_topic_coverage.py	/^labs = topic_plt.set_yticklabels(index)$/;"	v
load_repo_collection	restore_repos_redis.py	/^def  load_repo_collection(name):$/;"	f
load_repo_id	restore_repos_redis.py	/^def load_repo_id():$/;"	f
long_title_df	1a_Generate_repo_topic_data.py	/^long_title_df = long_title_df.ix[-long_title_df.name.str.contains('Bayesian')]$/;"	v
long_title_df	1a_Generate_repo_topic_data.py	/^long_title_df = pd.io.gbq.read_gbq(long_title_query)$/;"	v
long_title_df	generate_repo_data.py	/^long_title_df = long_title_df.ix[-long_title_df.name.str.contains('Bayesian')]$/;"	v
long_title_df	generate_repo_data.py	/^long_title_df = pd.io.gbq.read_gbq(long_title_query)$/;"	v
long_title_query	1a_Generate_repo_topic_data.py	/^long_title_query = 'SELECT name, full_name, fork FROM [github_proper.repo_list] where length(name) > 40'$/;"	v
long_title_query	generate_repo_data.py	/^long_title_query = 'SELECT name, full_name, fork FROM [github_proper.repo_list] where length(name) > 40'$/;"	v
mask	1c_Validate_Repo_Topics.py	/^mask = np.ones(len(y), dtype=bool)$/;"	v
mask	repo_domain_classifier.py	/^mask = np.ones(len(y), dtype=bool)$/;"	v
mask	social_media_proper.py	/^mask = np.ones(len(y), dtype=bool)$/;"	v
mat	3-Analyse_repo_topic_coverage.py	/^mat = sp.matshow(data, cmap=cm.coolwarm)$/;"	v
mirror_df	1b_Generate_repo_details.py	/^mirror_df = device_specific_repos(query, use_description=True)$/;"	v
ml_df	1a_Generate_repo_topic_data.py	/^ml_df = construct_repo_df(ml_query, description=False, local=True)$/;"	v
ml_df	generate_repo_data.py	/^ml_df = construct_repo_df(ml_query)$/;"	v
ml_list	1a_Generate_repo_topic_data.py	/^ml_list = pd.read_csv('topic_lists\/ml.csv', header=None, names = ['name'])$/;"	v
ml_list	generate_repo_data.py	/^ml_list = pd.read_csv('topic_lists\/ml.csv', header=None, names = ['name'])$/;"	v
ml_query	1a_Generate_repo_topic_data.py	/^ml_query  = 'data mining|machine learning|feature selection|prediction|' + '|'.join(ml_list['name'].str.strip()).lower()$/;"	v
ml_query	generate_repo_data.py	/^ml_query  = '|'.join(ml_list['name'].str.strip()).lower()$/;"	v
my_colors	3-Analyse_repo_topic_coverage.py	/^my_colors = 'rgbkymc'$/;"	v
n	1c_Validate_Repo_Topics.py	/^n = domain_training.shape[0]$/;"	v
n	repo_domain_classifier.py	/^n = domain_training.shape[0]$/;"	v
n	social_media.py	/^n = soc_media_training.shape[0]$/;"	v
n	social_media_proper.py	/^n = domain_training.shape[0]$/;"	v
n_c	1c_Validate_Repo_Topics.py	/^n_c = sum(domain_training[response_domain] == True)$/;"	v
n_c	repo_domain_classifier.py	/^n_c = sum(domain_training[response_domain] == True)$/;"	v
n_c	social_media.py	/^n_c = sum(soc_media_training['is_social'] == True)$/;"	v
n_c	social_media_proper.py	/^n_c = sum(domain_training[response_domain] == True)$/;"	v
number	1d_Generate_repo_dates.py	/^number = 10000$/;"	v
package_df	1a_Generate_repo_topic_data.py	/^package_df = construct_repo_df(package_query)$/;"	v
package_df	generate_repo_data.py	/^package_df = construct_repo_df(package_query)$/;"	v
package_query	1a_Generate_repo_topic_data.py	/^package_query = 'zip|tar|gz|'+ '|'.join(packagelist['name'].str.strip()).lower()$/;"	v
package_query	generate_repo_data.py	/^package_query = '|'.join(packagelist['name'].str.strip()).lower()$/;"	v
packagelist	1a_Generate_repo_topic_data.py	/^packagelist = pd.read_csv('topic_lists\/package_manager.csv', header=None, names = ['name'])$/;"	v
packagelist	generate_repo_data.py	/^packagelist = pd.read_csv('topic_lists\/package_manager.csv', header=None, names = ['name'])$/;"	v
page_df	1a_Generate_repo_topic_data.py	/^page_df = construct_repo_df(page_query, description = False)$/;"	v
page_df	generate_repo_data.py	/^page_df = construct_repo_df(page_query, description = False)$/;"	v
page_query	1a_Generate_repo_topic_data.py	/^page_query  = 'github.com|github.io'$/;"	v
page_query	generate_repo_data.py	/^page_query  = 'github.com|github.io'$/;"	v
pages	4_Analyse_forking.py	/^pages = forkcount\/30$/;"	v
parser	repo_creation_dates.py	/^    parser = argparse.ArgumentParser(description="Monitor GitHub activity.")$/;"	v
password	1d_Generate_repo_dates.py	/^                        password = conf.get('github', 'password'))$/;"	v
password	4_Analyse_forking.py	/^                        password = conf.get('github', 'password'))$/;"	v
password	repo_creation_dates.py	/^                        password = conf.get('github', 'password'))$/;"	v
path	1d_Generate_repo_dates.py	/^path = '\/home\/mackenza\/.history_git\/'$/;"	v
path	4_Analyse_forking.py	/^path = '\/home\/mackenza\/.history_git\/'$/;"	v
path	repo_creation_dates.py	/^path = '\/home\/mackenza\/.history_git\/'$/;"	v
pipe	1a_Generate_repo_topic_data.py	/^pipe = red.pipeline()$/;"	v
pipe	restore_repos_redis.py	/^pipe = red.pipeline()$/;"	v
policy_df	1a_Generate_repo_topic_data.py	/^policy_df = construct_repo_df(policy_query)$/;"	v
policy_df	generate_repo_data.py	/^policy_df = construct_repo_df(policy_query)$/;"	v
policy_query	1a_Generate_repo_topic_data.py	/^policy_query = '|'.join(['policy', 'law', 'manifesto', 'agreement', 'guideline'])$/;"	v
policy_query	generate_repo_data.py	/^policy_query = '|'.join(['policy', 'law', 'manifesto', 'agreement', 'guideline'])$/;"	v
predict_domain	repo_domain_classifier.py	/^def predict_domain(x_ix, w_jc, w_0c):$/;"	f
predict_domain	social_media_proper.py	/^def predict_domain(x_ix, w_jc, w_0c):$/;"	f
programming_df	1a_Generate_repo_topic_data.py	/^programming_df = construct_repo_df(programming_query, description=True)$/;"	v
programming_df	1a_Generate_repo_topic_data.py	/^programming_df = pd.concat([programming_df, programming_df2])$/;"	v
programming_df2	1a_Generate_repo_topic_data.py	/^programming_df2 = construct_repo_df(programming_query2, description=True)$/;"	v
programming_query	1a_Generate_repo_topic_data.py	/^programming_query = '\\\\bC\\\\b|java|php|javascript|perl|ruby|python|scala|pig'$/;"	v
programming_query2	1a_Generate_repo_topic_data.py	/^programming_query2 = 'clojure|fortran|lisp|actionscript|objective-c|\\\\bSQL\\\\b|lua|visual basic'$/;"	v
query	1a_Generate_repo_topic_data.py	/^query = 'facebook'$/;"	v
query	1a_Generate_repo_topic_data.py	/^query = 'facebook|twitter'$/;"	v
query	1b_Generate_repo_details.py	/^query = 'cloud'$/;"	v
query	1b_Generate_repo_details.py	/^query = 'corrugated-box-machine'$/;"	v
query	1b_Generate_repo_details.py	/^query = 'mirror'$/;"	v
r	4-Analyse-topic-change.py	/^        r = g.get_repo(r)$/;"	v
r	4_Analyse_forking.py	/^r = fork_repos[0]$/;"	v
rdates	1d_Generate_repo_dates.py	/^rdates = get_creation_dates('servers', number)$/;"	v
read_one_github_hour	repo_creation_dates.py	/^def read_one_github_hour(filename, save_to_redis = True):$/;"	f
red	1a_Generate_repo_topic_data.py	/^red = redis.Redis(db='1')$/;"	v
red	1b_Generate_repo_details.py	/^red = redis.Redis(db='1')$/;"	v
red	1c_Validate_Repo_Topics.py	/^red = redis.Redis(db='1')$/;"	v
red	1d_Generate_repo_dates.py	/^red = redis.Redis(db ='1')$/;"	v
red	2a_Count_repos.py	/^red = redis.Redis(db='1')$/;"	v
red	3-Analyse_repo_topic_coverage.py	/^red = redis.Redis(db='1', host=REDIS_HOST)$/;"	v
red	4-Analyse-topic-change.py	/^red  = redis.Redis(db='1')$/;"	v
red	generate_repo_data.py	/^red = redis.Redis(db='1')$/;"	v
red	repo_creation_dates.py	/^red = redis.Redis(db ='1')$/;"	v
red	restore_repos_redis.py	/^    red = redis.Redis(db='1')$/;"	v
red	restore_repos_redis.py	/^    red = redis.Redis(db='3')$/;"	v
repo_count_df	2a_Count_repos.py	/^repo_count_df = pd.io.gbq.read_gbq(query)$/;"	v
repo_id	restore_repos_redis.py	/^repo_id = rs['repo_id']$/;"	v
repo_keys	1c_Validate_Repo_Topics.py	/^repo_keys = [k  for k in keys if k.find(':') == -1]$/;"	v
repo_query	1a_Generate_repo_topic_data.py	/^def repo_query(query):$/;"	f
repo_table	1a_Generate_repo_topic_data.py	/^repo_table = 'metacommunities:github_proper.repo_list'$/;"	v
repo_table	2a_Count_repos.py	/^repo_table = 'metacommunities:github_proper.repo_list'$/;"	v
repo_table	generate_repo_data.py	/^repo_table = 'metacommunities:github_proper.repo_list'$/;"	v
repos_df	3-Analyse_repo_topic_coverage.py	/^repos_df  = pd.DataFrame(key_sizes.values(), index = index, columns=['repo_count'])$/;"	v
repos_sample	2a_Count_repos.py	/^repos_sample = pd.io.gbq.read_gbq(query_sample)$/;"	v
res	1a_Generate_repo_topic_data.py	/^res = pipe.execute()$/;"	v
res	1a_Generate_repo_topic_data.py	/^res =pipe.execute()$/;"	v
response_domain	1c_Validate_Repo_Topics.py	/^response_domain = 'is_{}'.format(domain)$/;"	v
response_domain	repo_domain_classifier.py	/^response_domain = 'is_{}'.format(domain)$/;"	v
response_domain	social_media_proper.py	/^response_domain = 'is_{}'.format(domain)$/;"	v
rs	restore_repos_redis.py	/^rs = load_repo_id()$/;"	v
sci_df	1a_Generate_repo_topic_data.py	/^    sci_df = sci_df.append(df)$/;"	v
sci_df	1a_Generate_repo_topic_data.py	/^sci_df = pd.DataFrame()$/;"	v
sci_df	generate_repo_data.py	/^    sci_df = sci_df.append(df)$/;"	v
sci_df	generate_repo_data.py	/^sci_df = pd.DataFrame()$/;"	v
sci_dfs	1a_Generate_repo_topic_data.py	/^sci_dfs = []$/;"	v
sci_dfs	generate_repo_data.py	/^sci_dfs = []$/;"	v
sci_qs	1a_Generate_repo_topic_data.py	/^sci_qs = []$/;"	v
sci_qs	generate_repo_data.py	/^sci_qs = []$/;"	v
scilist	1a_Generate_repo_topic_data.py	/^scilist  = pd.read_csv('topic_lists\/science.csv', header=None, names = ['name'])$/;"	v
scilist	generate_repo_data.py	/^scilist  = pd.read_csv('topic_lists\/science.csv', header=None, names = ['name'])$/;"	v
server	1a_Generate_repo_topic_data.py	/^server = pd.read_csv('topic_lists\/opsadmin.csv', header=None, names = ['name', 'type'], na_filter=True, sep='\\t')$/;"	v
server	generate_repo_data.py	/^server = pd.read_csv('topic_lists\/opsadmin.csv', header=None, names = ['name', 'type'], na_filter=True, sep='\\t')$/;"	v
server_df	1a_Generate_repo_topic_data.py	/^server_df = construct_repo_df(serverquery, description=False)$/;"	v
server_df	generate_repo_data.py	/^server_df = construct_repo_df(serverquery, description=False)$/;"	v
serverquery	1a_Generate_repo_topic_data.py	/^serverquery   = '|'.join(server['name'].str.strip()).lower()$/;"	v
serverquery	generate_repo_data.py	/^serverquery   = '|'.join(server['name'].str.strip()).lower()$/;"	v
sm	1c_Validate_Repo_Topics.py	/^sm = pd.read_csv(train_csv, header = 0, sep='\\t')$/;"	v
sm	repo_domain_classifier.py	/^sm = pd.read_csv(train_csv, header = 0, sep='\\t')$/;"	v
sm	social_media.py	/^sm = pd.read_csv('data\/socialmedia_repos_training.csv', sep = '\\t')$/;"	v
sm	social_media_proper.py	/^sm = pd.read_csv(train_csv, header = 0, sep='\\t')$/;"	v
sm_terms	1c_Validate_Repo_Topics.py	/^sm_terms = [' '.join(re.findall('[A-Z][a-z]*', t)).lower() if re.match('[A-Z]', t) else t.lower() for t in sm_terms]$/;"	v
sm_terms	1c_Validate_Repo_Topics.py	/^sm_terms = [re.sub('[\\d]{2,}|[_\\W*]', ' ', s.split('\/')[1]) for s in sm['repo']]$/;"	v
sm_terms	repo_domain_classifier.py	/^sm_terms = [' '.join(re.findall('[A-Z][a-z]*', t)).lower() if re.match('[A-Z]', t) else t.lower() for t in sm_terms]$/;"	v
sm_terms	repo_domain_classifier.py	/^sm_terms = [re.sub('[\\d]{2,}|[_\\W*]', ' ', s.split('\/')[1]) for s in sm['repo']]$/;"	v
sm_terms	social_media.py	/^sm_terms = [re.sub('[\\d*_\\W*]', ' ', s.split('\/')[1]).lower() for s in sm.repo]$/;"	v
sm_terms	social_media_proper.py	/^sm_terms = [' '.join(re.findall('[A-Z][a-z]*', t)).lower() if re.match('[A-Z]', t) else t.lower() for t in sm_terms]$/;"	v
sm_terms	social_media_proper.py	/^sm_terms = [re.sub('[\\d]{2,}|[_\\W*]', ' ', s.split('\/')[1]) for s in sm['repo']]$/;"	v
sm_words	1c_Validate_Repo_Topics.py	/^sm_words = [w for s in sm_terms for w in s.split(' ') if len(w) >= 2]$/;"	v
sm_words	repo_domain_classifier.py	/^sm_words = [w for s in sm_terms for w in s.split(' ') if len(w) >= 2]$/;"	v
sm_words	social_media.py	/^sm_words = [w for s in sm_terms for w in s.split(' ') if len(w) > 2]$/;"	v
sm_words	social_media_proper.py	/^sm_words = [w for s in sm_terms for w in s.split(' ') if len(w) >= 2]$/;"	v
sm_words_counts	1c_Validate_Repo_Topics.py	/^sm_words_counts = collections.Counter(sm_words_stemmed)$/;"	v
sm_words_counts	repo_domain_classifier.py	/^sm_words_counts = collections.Counter(sm_words_stemmed)$/;"	v
sm_words_counts	social_media.py	/^sm_words_counts = collections.Counter(sm_words_stemmed)$/;"	v
sm_words_counts	social_media_proper.py	/^sm_words_counts = collections.Counter(sm_words_stemmed)$/;"	v
sm_words_stemmed	1c_Validate_Repo_Topics.py	/^sm_words_stemmed = [stemmer.stem(w) for w in sm_words]$/;"	v
sm_words_stemmed	repo_domain_classifier.py	/^sm_words_stemmed = [stemmer.stem(w) for w in sm_words]$/;"	v
sm_words_stemmed	social_media.py	/^sm_words_stemmed = [stemmer.stem(w) for w in sm_words]$/;"	v
sm_words_stemmed	social_media_proper.py	/^sm_words_stemmed = [stemmer.stem(w) for w in sm_words]$/;"	v
smdf	1b_Generate_repo_details.py	/^smdf = socialmedia_df.copy()$/;"	v
soc_media_training	social_media.py	/^soc_media_training  = pd.DataFrame(indicator_m, columns =  keywords)$/;"	v
soc_sampe	4-Analyse-topic-change.py	/^soc_sampe = red.srandmember('social_media', 100)$/;"	v
socialmedia	1a_Generate_repo_topic_data.py	/^socialmedia = pd.read_csv('topic_lists\/social_media.csv', header=0)$/;"	v
socialmedia	1b_Generate_repo_details.py	/^socialmedia = pd.read_csv('topic_lists\/social_media.csv', header=0)$/;"	v
socialmedia	generate_repo_data.py	/^socialmedia = pd.read_csv('topic_lists\/social_media.csv', header=0)$/;"	v
socialmedia_df	1a_Generate_repo_topic_data.py	/^socialmedia_df = construct_repo_df(socialmediaquery, description = False)$/;"	v
socialmedia_df	1b_Generate_repo_details.py	/^socialmedia_df = aggregate_many_queries(socialmedia[:4])$/;"	v
socialmedia_df	1b_Generate_repo_details.py	/^socialmedia_df = pd.concat([socialmedia_df, wikipedia_df])$/;"	v
socialmedia_df	generate_repo_data.py	/^socialmedia_df = construct_repo_df(socialmediaquery, description = False)$/;"	v
socialmediaquery	1a_Generate_repo_topic_data.py	/^socialmediaquery = 'wikipedia|'+'|'.join(socialmedia['name'].str.strip()).lower()$/;"	v
socialmediaquery	generate_repo_data.py	/^socialmediaquery = 'wikipedia|'+'|'.join(socialmedia['name'].str.strip()).lower()$/;"	v
sp	3-Analyse_repo_topic_coverage.py	/^sp = f.add_subplot(111)$/;"	v
spam_df	1a_Generate_repo_topic_data.py	/^spam_df = construct_repo_df(spam_query, description = False)$/;"	v
spam_df	1a_Generate_repo_topic_data.py	/^spam_df = pd.concat([spam_df, long_title_df])$/;"	v
spam_df	1a_Generate_repo_topic_data.py	/^spam_df = spam_df.drop_duplicates()$/;"	v
spam_df	generate_repo_data.py	/^spam_df = construct_repo_df(spam_query, description = False)$/;"	v
spam_df	generate_repo_data.py	/^spam_df = pd.concat([spam_df, long_title_df])$/;"	v
spam_df	generate_repo_data.py	/^spam_df = spam_df.drop_duplicates()$/;"	v
spam_query	1a_Generate_repo_topic_data.py	/^spam_query = 'crack|download|free.*mp3'$/;"	v
spam_query	generate_repo_data.py	/^spam_query = 'crack|download|free.*mp3'$/;"	v
split	1c_Validate_Repo_Topics.py	/^split = np.random.randint(0, sm.shape[0], sm.shape[0]\/2)$/;"	v
split	repo_domain_classifier.py	/^split = np.random.randint(0, sm.shape[0], sm.shape[0]\/2)$/;"	v
split	social_media_proper.py	/^split = np.random.randint(0, sm.shape[0], sm.shape[0]\/2)$/;"	v
spoon	4_Analyse_forking.py	/^spoon = gh.get_repo('octocat\/Spoon-Knife')$/;"	v
src_keys	3-Analyse_repo_topic_coverage.py	/^src_keys = []$/;"	v
stemmer	1c_Validate_Repo_Topics.py	/^stemmer = nltk.stem.SnowballStemmer('english', ignore_stopwords=True)$/;"	v
stemmer	repo_domain_classifier.py	/^stemmer = nltk.stem.SnowballStemmer('english', ignore_stopwords=True)$/;"	v
stemmer	social_media.py	/^stemmer = nltk.stem.SnowballStemmer('english', ignore_stopwords=True)$/;"	v
stemmer	social_media_proper.py	/^stemmer = nltk.stem.SnowballStemmer('english', ignore_stopwords=True)$/;"	v
step	1a_Generate_repo_topic_data.py	/^step = 100000$/;"	v
store_key	3-Analyse_repo_topic_coverage.py	/^    store_key = c[0]+':'+c[1]$/;"	v
store_repos	restore_repos_redis.py	/^def  store_repos(repo_collection, ids):$/;"	f
term_count	1c_Validate_Repo_Topics.py	/^term_count  = 200$/;"	v
term_count	repo_domain_classifier.py	/^term_count  = 200$/;"	v
term_count	social_media_proper.py	/^term_count  = 200$/;"	v
terms	1c_Validate_Repo_Topics.py	/^terms = sm_words_counts.most_common(term_count)$/;"	v
terms	repo_domain_classifier.py	/^terms = sm_words_counts.most_common(term_count)$/;"	v
terms	social_media.py	/^terms = sm_words_counts.most_common(200)$/;"	v
terms	social_media_proper.py	/^terms = sm_words_counts.most_common(term_count)$/;"	v
test_df	1a_Generate_repo_topic_data.py	/^test_df = construct_repo_df(test_query, description=False,local=True)$/;"	v
test_df	generate_repo_data.py	/^test_df = construct_repo_df(test_query, description=False)$/;"	v
test_id_repo_hashset	restore_repos_redis.py	/^def test_id_repo_hashset(start, end, repo_id):$/;"	f
test_query	1a_Generate_repo_topic_data.py	/^test_query = 'test|try|demo|hello|getting started|starting|beginning|train|learn|sample|spoon-knife'$/;"	v
test_query	generate_repo_data.py	/^test_query = 'test|try|demo|hello'$/;"	v
testing	restore_repos_redis.py	/^testing = False$/;"	v
theta_0	1c_Validate_Repo_Topics.py	/^theta_0 = (n-n_c)\/float(n)$/;"	v
theta_0	repo_domain_classifier.py	/^theta_0 = (n-n_c)\/float(n)$/;"	v
theta_0	social_media_proper.py	/^theta_0 = (n-n_c)\/float(n)$/;"	v
theta_c	1c_Validate_Repo_Topics.py	/^theta_c = n_c\/float(n)$/;"	v
theta_c	repo_domain_classifier.py	/^theta_c = n_c\/float(n)$/;"	v
theta_c	social_media.py	/^theta_c = n_c\/float(n)$/;"	v
theta_c	social_media_proper.py	/^theta_c = n_c\/float(n)$/;"	v
theta_j0	1c_Validate_Repo_Topics.py	/^theta_j0 = (domain_training.ix[domain_training[response_domain] != True, 0 : term_count].sum(axis=0) +alpha-1)\/(n - n_c  + alpha + beta - 2)$/;"	v
theta_j0	repo_domain_classifier.py	/^theta_j0 = (domain_training.ix[domain_training[response_domain] != True, 0 : term_count].sum(axis=0) +alpha-1)\/(n - n_c  + alpha + beta - 2)$/;"	v
theta_j0	social_media_proper.py	/^theta_j0 = (domain_training.ix[domain_training[response_domain] != True, 0 : term_count].sum(axis=0) +alpha-1)\/(n - n_c  + alpha + beta - 2)$/;"	v
theta_jc	1c_Validate_Repo_Topics.py	/^theta_jc = (n_jc + alpha -1)\/(n_c + alpha + beta -2)$/;"	v
theta_jc	repo_domain_classifier.py	/^theta_jc = (n_jc + alpha -1)\/(n_c + alpha + beta -2)$/;"	v
theta_jc	social_media.py	/^theta_jc = (n_jc + alpha -1)\/(n_c + alpha + beta -2)/;"	v
theta_jc	social_media_proper.py	/^theta_jc = (n_jc + alpha -1)\/(n_c + alpha + beta -2)$/;"	v
topic_plt	3-Analyse_repo_topic_coverage.py	/^topic_plt = repos_df.repo_count.plot(kind='barh', color = my_colors)$/;"	v
train_csv	1c_Validate_Repo_Topics.py	/^train_csv = 'data\/{}_repos_training.csv'.format(domain)$/;"	v
train_csv	repo_domain_classifier.py	/^train_csv = 'data\/{}_repos_training.csv'.format(domain)$/;"	v
train_csv	social_media_proper.py	/^train_csv = 'data\/{}_repos_training.csv'.format(domain)$/;"	v
training_df	1c_Validate_Repo_Topics.py	/^training_df = pd.read_csv('data\/{0}_repos_training.csv'.format(domain), header=0, sep='\\t')$/;"	v
ts	3-Analyse_repo_topic_coverage.py	/^ts = time.time()$/;"	v
un	3-Analyse_repo_topic_coverage.py	/^un =red.sunionstore('repos:union', *keys)$/;"	v
w_0c	1c_Validate_Repo_Topics.py	/^w_0c = np.sum(np.log ((1-theta_jc)\/(1-theta_j0))) + np.log(theta_c\/theta_0)$/;"	v
w_0c	repo_domain_classifier.py	/^w_0c = np.sum(np.log ((1-theta_jc)\/(1-theta_j0))) + np.log(theta_c\/theta_0)$/;"	v
w_0c	social_media_proper.py	/^w_0c = np.sum(np.log ((1-theta_jc)\/(1-theta_j0))) + np.log(theta_c\/theta_0)$/;"	v
w_jc	1c_Validate_Repo_Topics.py	/^w_jc = np.log((theta_jc*(1-theta_j0))\/(theta_j0*(1-theta_jc)))$/;"	v
w_jc	repo_domain_classifier.py	/^w_jc = np.log((theta_jc*(1-theta_j0))\/(theta_j0*(1-theta_jc)))$/;"	v
w_jc	social_media_proper.py	/^w_jc = np.log((theta_jc*(1-theta_j0))\/(theta_j0*(1-theta_jc)))$/;"	v
wf_df	1a_Generate_repo_topic_data.py	/^wf_df = construct_repo_df(wfquery)$/;"	v
wf_df	generate_repo_data.py	/^wf_df = construct_repo_df(wfquery)$/;"	v
wflist_df	1a_Generate_repo_topic_data.py	/^wflist_df = pd.read_csv('topic_lists\/webframe_list.csv', header=None, names=['name'])$/;"	v
wflist_df	generate_repo_data.py	/^wflist_df = pd.read_csv('topic_lists\/webframe_list.csv', header=None, names=['name'])$/;"	v
wfquery	1a_Generate_repo_topic_data.py	/^wfquery = '|'.join(wflist_df['name'][:30]).lower()$/;"	v
wfquery	generate_repo_data.py	/^wfquery = '|'.join(wflist_df['name'][:30]).lower()$/;"	v
wikipedia_df	1b_Generate_repo_details.py	/^wikipedia_df = device_specific_repos('wikipedia')$/;"	v
word	1c_Validate_Repo_Topics.py	/^                word = stemmer.stem(j)$/;"	v
word	repo_domain_classifier.py	/^                word = stemmer.stem(j)$/;"	v
word	social_media.py	/^        		word = stemmer.stem(j)$/;"	v
word	social_media_proper.py	/^                word = stemmer.stem(j)$/;"	v
words	1c_Validate_Repo_Topics.py	/^words = sort([w for s in sc_terms for w in s.split(' ') if len(w) >= 2])$/;"	v
words_stemmed	1c_Validate_Repo_Topics.py	/^words_stemmed = [stemmer.stem(w) for w in words]$/;"	v
xr	3-Analyse_repo_topic_coverage.py	/^xr=chisq.test(int_m)$/;"	v
y	1c_Validate_Repo_Topics.py	/^y = sm[response_domain]$/;"	v
y	repo_domain_classifier.py	/^y = sm[response_domain]$/;"	v
y	social_media.py	/^            y = sm.is_socmedia.astype(np.bool).values$/;"	v
y	social_media_proper.py	/^y = sm[response_domain]$/;"	v
y_actual	repo_domain_classifier.py	/^y_actual  = [ domain if act else 'other' for  act in domain_test[response_domain]]$/;"	v
y_actual	social_media_proper.py	/^y_actual  = [ domain if act else 'other' for  act in domain_test[response_domain]]$/;"	v
y_test_predicted	repo_domain_classifier.py	/^y_test_predicted = [domain if predict_domain(i, w_jc, w_0c) else 'other' for i in range(0, domain_test.shape[0])]$/;"	v
y_test_predicted	social_media_proper.py	/^y_test_predicted = [domain if predict_domain(i, w_jc, w_0c) else 'other' for i in range(0, domain_test.shape[0])]$/;"	v
