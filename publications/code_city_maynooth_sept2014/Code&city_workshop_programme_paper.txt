Code and the City Workshop
ERC The Programmable City Project

3-4 September 2014, NUI Maynooth
Venue
Phoenix Boardroom
1st Floor, Phoenix Building, North Campus, NUI Maynooth
(see locations in the attached Maynooth Map)

Timetable
2nd September
Opening reception, The O'Neills Pub
3rd September
9.30: Tea/coffee
10.00-10.30: Welcome and Opening talk, Prof. Rob Kitchin
10.30-12.30: Session 1: Code, coding and interfaces
12.30-13.30: Lunch
13.30-15.30: Session 2: Code and mobility
15.30-16.00: Coffee break
16.00-18.00: Session 3: Locative/social media
19.30 - late: Dinner, The Gatehouse Restaurant
4th September
9.30 Tea/coffee
10.00-12.00: Session 4: Cities, knowledge classification and ontology
12.00-12.45: Lunch
12.45-14.45: Session 5: Cities, code and governance
14.45-15.15: Coffee break
15.15-16.45: Session 6 - Discussion/wrap up

1

Code and the city: Reframing the conceptual terrain
Rob Kitchin, NIRSA, National University of Ireland Maynooth
Software has become essential to the functioning of cities. It is deeply and pervasively embedded
into the systems and infrastructure of the built environment and in the management and governance
of urban societies. Software-enabled technologies and services augment and facilitate how we
understand and plan cities, how we manage urban services and utilities, and how we live urban
lives. This paper will provide an overarching overview of the ways in which software has become
an indispensible mediator of urban systems and the consequent implications, and makes the case for
the study of computational algorithms and how cities are captured in and processed through code.

Session 1: Code, coding and interfaces
Code-crowd: How software repositories express urban life
Adrian Mackenzie, Sociology, Lancaster University
Is code an expression of urban life? This paper analyses around 10 million software repositories on
Github.com from the perspective of how they include cities. The methodology here relies on dataintensive work with bodies of code at a number of different levels. It maps the geographies of
Github organisations and users to see how location anchors coding work. More experimentally, it
tracks how urban spaces, movements and architectures figure in and configure code. The paper's
focus is less on how code shapes cities and more on apprehending code and coding as a way of
experientially inhabiting cities. This approach might better highlight how code expresses urban
experiences of proximity, mixing, movement, nearness, distance, and location. It might also shed
light on the plural forms of spatiality arising from code, particularly as algorithmic processes
become more entangled with each other.

Encountering the city at hackathons
Sophia Maalsen and Sung-Yueh Perng, National University of Ireland,
Maynooth
The growing significance of hackathons is currently developing in a mutually informing way. On
the one hand, there is an increasing use of hackathons to address issues of city governance – Chris
Vein, US CTO for government innovation has described them as ‘sensemaking’ tools for
government, encouraging agencies to make use of hackathons and “let the collective energy of the
people in the room come together and really take that data and solve things in creative and
imaginative ways” (Llewellyn 2012). On the other, regular hack nights appear as creative urban
space for citizens to discuss problems they encounter and which are not necessarily considered by
government, and produce solutions to tackle these issues.
2

In this paper, we explore potential opportunities and tensions, as well as excitement and
inattentiveness, emerging as solutions are proposed and pursued. Through this, we reflect upon how
such processes translate the city and transform ways of living in places where the solutions are
applied. We further ask whether the positive discourse surrounding hackathons is justified or
whether there are limits to their ability to deal with the complexity of urban issues.

Interfacing urban intelligence
Shannon Mattern, Media Studies, New School NY
Technology companies, city governments, and design firms – the entities teaming up to construct
our highly-networked cities of the future – have prototyped interfaces through which citizens can
engage with the smart city. But those prototypes, almost always envisioned as screens of some sort,
embody institutional values that aren’t always aligned with those of citizens who rightfully claim a
“right to the city.” Based on promotional materials from Cisco, Siemens, IBM, Microsoft, and their
smart-city-making counterparts, it seems that one of the chief preoccupations of our future-cities is
to reflect their data consumption and hyper-efficient (often "widgetized") activity back to
themselves. We thus see city “control centers” lined with screens that serve in part to visualize, and
celebrate, the city’s own supposedly hyper-rational operation. Public-facing interfaces, meanwhile,
are typically rendered via schematic mock-ups, with little consideration given to interface design.
They’re portrayed as conduits for transit information, commercial and service locations and
reviews, and information about cultural resources and tourist attractions; and as portals for
gathering user-generated data. Across the board, these interfacing platforms tend to frame their
users as sources of data that feed the urban algorithmic machines, and as consumers of data
concerned primarily with their own efficient navigation and consumption of the city.
In this talk, I'll consider how we might we design urban interfaces for urban citizens, who have a
right to know what’s going on inside “’black boxed’ [urban] control systems” – and even engage
with the operating system as more than mere data-generators or reporters-of-potholes-and-poweroutages. In considering what constitutes an ideal urban interface, we need to examine those
platforms that are already in existence, and those that are proposed for future cities. Even the purely
hypothetical, the speculative – the “design fiction" – can illuminate what’s possible, technologically,
aesthetically, and ideologically; and can allow us to ask ourselves what kind of a “public face” we
want to front our cities, and, even more important, what kinds of intelligence and agency –
technological and human – we want our cities to embody.

Session 2: Code and mobility
Moving applications: A multilayered approach to mobile
computing

3

Jim Merricks White, National University of Ireland, Maynooth
Mobile computing plays an increasingly important role in the way that space is experienced in the
city. This has political consequences, both at the micro level of everyday production and
consumption, and at the macro level of institutional and political economy. While geographers have
explored the ontological role which might be played by hardware, software, data and mapping
within this spatial paradigm, there remains little concerted effort to explore mobile computing as a
technological system which incorporates all of these socio-technical assemblages. By drawing on
adjacent disciplines of science and technology studies (STS) and media and communication studies,
this essay proposes a multilayered model for such a holistic inquiry: hardware—software—
data(base)—GUI (graphical user interface).
By applying this model to a self-reflexive exploration of the taxi service Hailo and the mobility
tracking application Moves, I attempt to demonstrate how it might be put to work as a heuristic tool.
Following on from my desire to expose and explore the politics of mobile computing, the model is
used to draw attention to the networks of power which make up these mobile computing services.

Digital urbanism in crises: A hopeful monster?
Monika Büscher, With Michael Liegl, Katrina Petersen, Mobilities.Lab,
Lancaster University, UK
Intersecting mobilities of data, people and resources are an integral part of a new digital urbanism.
Thrift speaks of Lifeworld.Inc, a new entertainment-security sector driven contexture where
people’s everyday activities, movements, physiological data, thoughts, desires and fears are so
richly documented in real time that commercial enterprise as well as urban services (transport,
energy, security) can dynamically anticipate and shape them ‘just-in-time’ (2011). While this opens
up novel opportunities for more efficiency, comfort, and sustainability in networked urban
mobilities, it also provides new leverage for mobilizing disaster response. In a ‘century of disasters’
(eScience 2012), where urbanization has increased vulnerability and climate change contributes to
increased frequency and severity of disasters, this opens up a perspicuous site for investigations of
post-human practices, phenomenologies and ethics. Big data analytics and information sharing for
risk prevention and disaster response can exacerbate the unprecedented surveillance contemporary
societies practice (Harding 2014), Kafka-eske transformations of privacy and civil liberties (Solove
2004) and a splintering urbanism (Graham & Marvin 2001). At the heart of these transformations is
a digital phenomenology of invisibility, immateriality and ‘intelligence’ that does not lend itself to
human control. ‘Smart cities’ may depend on smart citizens (Greenfield 2013), but the technologies
contemporary societies produce do not support human intelligence. We report from ‘inside the belly
of the beast’ of innovation in mobilizing Lifeworld.Inc data for disaster response (Balka 2006).
Drawing on experience from collaborative research and design projects (e.g.
http://www.bridgeproject.eu/en), we discuss the relationship between lived cyborg practice,
phenomenology and ethics in networked urban mobilities. Using a disaster perspective for a
disclosive ethical investigation (Introna 2007) does disclose some potentially disastrous
transformations, but it also highlights avenues for alternative, radically careful as well as carefully
radical design (Latour 2009).

Abstract urbanism
4

Matthew Fuller and Graham Harwood, Cultural Studies, Goldsmiths
The urban riots of the USA in the late 1960s were some of the most powerful political events of that
era. As well as drawing numerous responses from media, the civil rights movement, black
nationalists, and groups such as the Situationist International, the uprising also triggered a range of
research responses including some of the first computational models of cities. T.C. Schelling’s
“Models of Segregation” attempted to provide a logical model for racial segregation and laid much
of the groundwork for what later became agent-based modeling. Such work is expressed
contemporarily for instance in the riot and insurgency modeling of J.M. Epstein and others. For the
state, such events mark a schizophrenic relationship to the contingency of riot and how the
algorithms play out in such a scenario. How can it govern events that both demonstrate and excite
its power and also undermine it? This paper will propose a tracing of the genealogy of such models
alongside a reading of other ways of using urban modeling in relation to the urban riots of that era
and now. A parrallel reference point here will be the work of W. Bunge a quantitative geographer
and spatial theorist. Bunge consistently argued that geometrical patterns and morphological laws
express disadvantage and injustice under contemporary capitalism, and that identified patterns could
be remedied by rational methods.
The history of computing, from G.W. Leibniz onwards, tangles with the problematic of developing
rational approaches to complex, multi-dimensional problems with a high-degree of what J. Law
describes as “messiness”. This paper will examine the ways in which rationality, or ratio, is
positioned in relation to urban conflict as a means of discussing the relations between the city and
software. The paper will develop a discussion of ratio in relation to questions of abstraction,
reduction and empiricism. We are especially concerned to find a relationship between abstraction
and the empirical that, by working with the materiality of computational systems recognises, and
perhaps works with, the tendency to reduction(ism) but through which modes of abstraction may
also work with the highly and complexly empirical.

Session 3: Locative/social media
Digital social interactions in the city: Reflecting on locationbased social media
Luigina Ciolfi, Human-Centred Computing, Sheffield Hallam
University
Gabriela Avram, University of Limerick
Location-based social media increasingly mediates social and interpersonal interactions in urban
settings. Such practices become coded in software representing both the log and content of social
interactions and the location to which they relate. Therefore a digital “cloud” of social interactions
becomes embedded into the physical reality of the city, of its neighbourhoods, public places, cafés,
transportation hubs and any other location identified by social media users (by user-initiated
5

“check-ins” or by the content that they generate, such as photographs) and by the tools they use (for
example, through automatic geo-tagging). Two sets of issues to be investigated are emerging: firstly
referring to how such localised interactions are populating the algorithms and infrastructures
provided by the software: how are the platform of location-based social media framing people's
perceptions and identifications of locations? How is code both facilitating and representing a set of
social interactions relating to various spatial configurations?A second set of issues regards the rematerialisation of such cloud of interactions in the physical world: could it be made somehow
perceivable and/or tangible in the physical world by the way in which certain environments are
designed?
Overall, could new approaches to urban planning and environmental design become concerned with
accommodating and facilitating these social interactions as they do so by supporting in-presence,
analogue ones?
This paper will attempt to define and discuss these issues drawing both from interaction design and
human-computer interaction literature on physical/digital interactions and from two preliminary
empirical studies of location-based social media use in two cities.

Feeling place in the city: strange ontologies, Foursquare
and location-based social media
Leighton Evans, National University of Ireland Maynooth
Certain instances of the use of location-based social media in cities can result in deep
understandings of novel locations. The contributions of other users and the information pushed to
users when in particular locales can help users rapidly attune themselves to places and achieve an
understanding of the place. The use of a computational device and location-based social networking
to achieve this understanding indicates an alteration in the achievement of placehood using
computational technology. Practices and methods of understanding place can, in some situations, be
delegated to the device and application. This paper explores how the moment that place is
appreciated as place (that is, as a meaningful existential locale) can be reconciled with the
delegation of the epistemologies of placehood to a computational device and location-based social
media application. Drawing on data from an ethnographic study of Foursquare users, the
phenomenological appreciation of place is understood as co-constituent between the device,
application and the mood of the user. Code and computational devices are contextualised as a
constant foregrounding presence in the city, and the engagement of the user, device, code and data
in understanding place is a moment of revealing that is co-constituent of all these elements. This
exploratory paper engages Peter Sloterdijk’s theory of spheres as a framework to understand how
these four elements interact, and how that interaction of elements can orient a user to a revealing of
the city that can be understood as a phenomenological revealing of place.

Cultural curation and urban Interfaces: Locative media as
experimental platforms for cultural data
Nanna Verhoeff, Media and Culture Studies, Utrecht University
My contribution is concerned with the way in which urban interfaces are used for access to cultural
6

collections – whether institutionally embedded, or bottom-up, participatory collections. Designed in
code and exploring affordances of new location-based and/or mobile technologies for urban spacemaking, these interfaces are thought to be powerful tools for ideals of participatory urban culture. I
propose to approach these “projects” as curatorial machines, as urban experimental laboratories for
cultural data. This entails a threefold perspective, on curation, on code, and on principles of creative
(sometimes artistic or playful) experimentation.
For this, we may remind ourselves of the curatorial project of museal and archival institutions, of
preserving, and “caring” for the object, as well as creating new contexts for the object and providing
access for an urban public – a field which is very much in transition as a result of current ambitions
for new public engagement and ideals of participation, pervasive in all socio-economic and political
regions of contemporary culture. Simultaneously we witness the current interest in the principles of
data curation as the care for, interaction with, interpretation and visualisation of digital data, as the
datafication and codification of culture invades all corners of urban life. Design of interfaces is
central in how we can access, work with, and make meaning with digital culture. Departing from
the concept of dispositif in the analysis of interfaces, I propose to bring together the fact that the
interfaces are coded and designed, to (playfully) experiment with their affordances.
In my approach to this intersection of datafication of, and the proliferation of interfaces for
“culture”, I aim to develop heuristic tools for critical evaluation of this phenomenon, broadly
bracketed as [urban interfaces] as interfaces of cultural curation.

A Window, a message, or a medium? Learning about cities
from Instagram
Lev Manovich, Computer Science, The Graduate Center, City
University of New York
Short Abstract:
What are we learning when analyzing can social media data? Is it a window into real-world social
and cultural behaviors, a reflection of lifestyles of particular demographics who use mobile
platforms and particular network services, or an artifact of mobile apps hardware and software? In
other words - is social media a "message" or a "medium"? I will discuss these questions using
recent projects from my lab where we analyzed and visualized millions of Instagram photos.
Long Abstract:
Over last few years, tens of thousands of researchers in social computing and computational social
sciences started to use available data from social networks and media sharing services (such as
Twitter, Foursquare and Instagram) created by users of mobile platforms. The research uses
techniques from statistics, machine learning, and visualization, among others, to analyze all kinds of
patterns contained in this data and also (less frequently) propose new models for understanding the
social. The examples include analysis of information propagation in Twitter, predicting popularity
of photos on Flickr, proposing new sets of city neighborhoods using Foursquare users check-ins,
and understanding connections between musical genres using listening data from Echonest.
In my talk I will address a fundamental question we face in doing this research: what exactly are we
7

learning when analyzing can social media data? Is it a window into real-world social and cultural
behaviors, a reflection of lifestyles of particular demographics who use mobile platforms and
particular network services, or only an artifact of mobile apps? In other words - is social media a
"message" or a "medium"?
I will discuss this question using three recent projects from my lab (softwarestudies.com). The
projects use large sets of Instagram images and accompanying data together with data science and
visualization tools. Phototrails.net (2013) analyzes 2.3 million photos from 13 global cities to
investigate how different kinds of events are represented in these photos. The project also
investigates if the universal affordances of Instagram app (same interface and same set of filters
available to all users) result in universal digital visual language. Selfiecity.net (2014) analyzes the
distinct artifact of mobile platforms – selfies. We compare thousands of selfies to see if cultural
specificity of different places and cultural is preserved in this genre. Finally, our third project
compares Instagram photos taken by visitors in a few major modern art museums, asking if
photographs of famous works of the art differ depending on what these artworks are and where they
are situated.

Session 4: Cities, knowledge classification and
ontology
Cities and context: The codification of small areas through
geodemographic classification
Alex Singleton, Geography, University of Liverpool
Geodemographic classifications group small area geography into categories based on shared
population and built environment characteristics. This process of “codification” aims to create a
common language for the description of salient internal structure of places, and by extension, enable
their comparison across geographic contexts. The typological study of areas is not a new
phenomenon, and contemporary geodemographics emerged from research conducted in the 1970s
that aimed at providing a new method of targeting deprivation relief funding within the city of
Liverpool. This city level model was later extended for the national context, and became the
antecedent of contemporary geodemographic classification. This paper explores the origins of
geodemographics, to first illustrate that the coding of areas is not just a contemporary practice; and
then extends this discussion to consider how methodological choices influence classification
structure. Being open with such methods is argued as being essential for classifications to engender
greater social responsibility.

The city and the Feudal Internet: Examining institutional
materialities

8

Paul Dourish, Informatics, UC Irvine
In "Seeing like a City," Marianne Valverde turns to urban regulation to counter some of James
Scott's arguments about the homogenizing gaze of high modern statehood. Cities, she notes, are
highly regulated, but without the panoptic order that Scott suggests. They operate instead as a
splintered patchwork of regulatory boundaries – postal codes, tax assessment districts, business
improvement zones, school catchment areas, zoning blocks, sanitation districts, and similar
divisions that don't quite line up. Arguments about online experience and the consequences of the
Internet have a similar air to Scott's analysis of statehood – they posit a world of consistent,
compliant, and compatible information systems, in which the free flow of information and the
homogenizing gaze of the digital erases boundaries (both for good and ill).
In fact, the organization of the Internet -- that is, of our technologically- and historically-specific
internet –is one of boundaries, barriers, and fiefdoms. We have erected all sorts of internal barriers
to the free flow of information for a range of reasons, including the desire for autonomy and the
extraction of tolls and rents. In this talk I want to explore some aspects of the historical specificity
of our Internet and consider what this has to tell us about the ways that we talk about code and the
city.

Semantic cities: Coded geopolitics and rise of the semantic
web
Heather Ford and Mark Graham, Oxford Internet Institute, University
of Oxford
In 2012, Google rolled out a service called Knowledge Graph which would enable users to have
their search query resolved without having to navigate to other websites. So, instead of just
presenting users with a diverse list of possible answers to any query, Google selects and frames data
about cities, countries and millions of other objects sourced from sites including Wikipedia, the CIA
World Factbook and Freebase under its own banner.
For many, this heralded Google’s eventual recognition of the benefits of the Semantic Web: an idea
and ideal that the Web could be made more efficient and interconnected when websites share a
common framework that would allow data to be shared and reused across application, enterprise,
community, and geographic boundaries. This move towards the Semantic Web can be starkly seen
in the ways that Wikipedia, as one of the foundations for Google’s Knowledge Graph, has begun to
make significant epistemic changes. With a Google funded project called WikiData, Wikipedia has
begun to use Semantic Web principles to centralise ‘factual’ data across all language versions of the
encyclopaedia. For instance, this would mean that the population of a city need only be altered once
in WikiData rather in all places where it occurs in Wikipedia’s 285 language versions.
For Google, these efficiencies provide a faster experience for users who will stay on their website
rather than navigating away. For Wikipedia, such efficiencies promise to centralise the updating
process so that data are consistent and so that smaller language Wikipedias can obtain automated
assistance in translating essential data for articles more rapidly.

9

This paper seeks to critically interrogate these changes in the digital architectures and
infrastructures of our increasingly augmented cities. What shifts in power result from these changes
in digital infrastructures? How are semantic standardisations increasingly encoded into our urban
environments and experiences? And what space remains for digital counter-narratives, conflict, and
contention?
To tackle those questions, we trace data about two cities as they travel through Google’s algorithms
and the Semantic Web platforms of Wikidata and Wikipedia. In each case, we seek to understand
how particular reflections of the city are made visible or invisible and how particular publics are
given voice or silenced. Doing so leads us to ultimately reflect on how these new alignments of
code and content shape how cities are presented, experienced, and brought into being.

Session 5: Cities, code and governance
Coding alternative modes of governance: Learning from
experimental “peer to peer cities”
Alison Powell, Media & Communications, LSE
Within the last twenty years the concept of the “smart city” has emerged and re-emerged, focusing
on various ways that technology layers new capacities over existing urban infrastructures. These
“smart cities” are changing. The “smart city” of the early 2000s was a communicative city, while
the smart city of the 2010s is a data city. The dynamics of these are different: a communicative city
promises representation through voice – the ability to speak and listen - while a data city promises
representation through information – information collected about individuals is fed back to civic
decision makers who enact decisions based upon it. Data is thus a product flowing from citizen to
government. In data cities governance is also different: both communicative and data cities could be
the result of top-down governance decisions or subject to bottom-up reconfigurations, the ways that
those decisions are enacted are quite different. A communicative city promises a democratic value
to citizens of greater access to information, while a data city promises a value to governments of
greater access to data about citizens. This structural inequity is particularly evident when we
consider what must happen to data in a data city – it must be calculated.
Within a macro-political perspective, centralized calculation of data gathered from citizens is
essential for developing visions of responsive, data-rich, centrally controlled smart cities. This
seems to close off the potential for an alternative mode of governance for the contemporary data
city. However, the expansion of participatory culture has created efforts to democratize collection of
data about cities, through citizen science projects including air quality and noise mapping. In these
projects, the legitimacy of the hierarchical city is challenged by the oppositional data collected by
citizens, taken as evidence of an opposition between the “constituted knowledge” of institutions like
city governance and the “adaptive knowledge” of loosely organized communities of practice (see
Mansell, 2013). This contest of knowledge contrasts the two modes of combining citizenship,
technology and space, the ‘hierarchical city’ and the ‘peer to peer’ city. Participatory data collection
does seem to enact an alternative to centralized authority, but it is not clear whether data – without
10

calculation – is really shifting governance.
Building upon the central contrast between hierarchical and peer to peer cities, this paper considers
how the “micro politics” of cities are altered as calculation is integrated into civic participation.
Drawing on historical and contemporary examples of peer to peer cities including community
networks, citizen science, it argues that peer to peer calculation is the most significant yet most
difficult activation of alternative governance of urban space.

Big data and stratification urban futures
Agnieszka Leszczynski, Geography, University of Birmingham
Code has been recognized as intimately implicated in the socio-spatial stratification of cities. Big
data in particular are underwriting a sweeping intensification of practices of socio-spatial sorting,
which refers to the organization of city spaces into social and economic categories so as to
categorize and effectively manage the individuals who inhabit them. These practices directly shape
and reinforce material urban geographies of social disparity. One of the primary areas where we
find evidence of this is in the increasing leveraging of big data towards the prefiguring of urban
spatial pre-futures of deviance. Big data and attendant analytics are reproducing and reifying
disenfranchisement alog axes of race, class, socioeconomic status, and geography at scales from
the city as a whole to individual neighbourhoods so as to create material spaces for specific kinds of
vertical surveillance interventions (e.g., increased police presence), and to justify the targeting of
particular neighborhoods and neighbourhood populations for these practices (e.g., by prefiguring
them as criminalized a priori). The ways in which this is enacted in practice is
discussed with reference to, amongst others, the EMOTIVE Twitter analytics software program
designed as a riot prevention system in the UK, and the Chicago Police Department’s turn to big
data analytics as a predictive policing measure.

The Cryptographic city
David M. Berry, Media & Communication, University of Sussex
Questions about opacity and transparency have been turned upside down in the post-Snowden era.
With the certainty of tracking technologies, surveillance and monitoring, a new turn towards
anonymity, opaque presence and crypto-identity has emerged in digital networks. This paper looks
to examine questions of cryptography and encryption in relation to the city, particularly in relation
to the increasing mediation of life through algorithms, software and code. Key questions are the
relationship between opacity and opaque presence and notions of publicness and city space, but also
the way in which the city as a programmable city will increasingly rely upon the cryptographic
layers. Through an engagement with the notion of ‘capture' the paper seeks to think through the
limits of what we might call plaintext code/space and reflect on the crypto code/spaces and their
materialities.

11

Code and the City: Reframing the conceptual terrain
Rob Kitchin, National Institute for Regional and Spatial Analysis (NIRSA), National
University of Ireland Maynooth, County Kildare, Ireland.
For presentation at the Code and the City workshop, 3rd-4th September 2014, Programmable
City, NIRSA, National University of Ireland Maynooth

Abstract
Cities are rapidly becoming composed of digitally-mediated components and infrastructures,
their systems augmented and mediated by software, with widespread consequences for how
they are managed, governed and experienced. This transformation has been accompanied by
critical scholarship that has sought to understand the relationship between code and the city.
Whilst this work has produced many useful insights, in this paper I argue that it also has a
number of shortcomings. Principal amongst these is that the literatures concerning code and
the city have remained quite divided. Studies that focus on code are often narrow in remit,
fading out the city, and tend to fetishize and potentially decontextualises code at the expense
of the wider socio-technical assemblage within which it is embedded. Studies that focus on
the city tend to examine the effects of code, but rarely unpack the constitution and mechanics
of the code producing those effects. To provide a more holistic account of the relationship
between code and the city I forward two interlinked conceptual frameworks. The first places
code within a wider socio-technical assemblage. The second conceives the city as being
composed of millions of such assemblages. In so doing, the latter seeks to provide a means
of productively building a conceptual and empirical understanding of programmable
urbanism that scales from individual lines of code to the complexity of an entire urban
system.
Key words: code, city, programmable urbanism, software studies, urban studies

I

Introduction

1

‘The modern city exists as a haze of software instructions. Nearly every urban
practice is becoming mediated by code’ (Amin and Thrift 2002: 125)
Over the past few decades software has become essential to the functioning of cities. It is
deeply and pervasively embedded into the systems and infrastructure of the built environment
and in the management and governance of urban societies. Digital technologies and services
augment and facilitate how we understand and plan cities, how we manage urban services
and utilities, and how we live urban lives. Software is used to produce, mediate, augment,
and regulate systems and tasks. In so doing, networked digital technologies are helping to
produce what has been termed ‘smart cities’: densely instrumented urban systems that can be
monitored, managed and regulated in real-time (see Townsend 2013; Kitchin 2014) and
whose data can be used to better depict, model and predict urban processes and simulate
future urban development (Batty et al., 2012).
Thousands of papers and reports document the development of new digital
technologies and their potential impact on cities and citizens or have examined the role
software plays in managing urban infrastructures and practices. The vast majority of studies,
however, focus on the development of new innovations and the production, deployment and
effects of software from a non-critical, technological, engineering and governance
perspective. A relatively small proportion take a more critical perspective, detailing how
certain digital technologies produce new socio-spatial practices and effects (such as spatial
sorting, algorithmic regulation, anticipatory governance, and control creep) and forms of
networked urbanism and their wider social, political and economic consequences to urban life
(e.g., Mitchell 1995; Graham and Marvin 2001; Graham 2005; Foth 2008; Shepard 2011).
Only in a handful of cases, however, has critical and conceptual attention been focused on the
nature of software itself, its underlying code, and its relationship to urban management,
governance and practices (e.g., Thrift and French 2002; Kitchin and Dodge 2011; Kelley
2014).
Drawing inspiration from software studies -- a new field that takes software, and its
production and deployment, as its object of critical analysis (see Fuller 2008; Berry 2011;
Manovich 2013) -- these critical interventions consider the ways in which cities and citizens

2

are translated into code and how this code is then used to reshape cities and mediate the lives
of their inhabitants. The principle argument forwarded it is that:
1. code is an actant that possesses ‘secondary agency’ (Mackenzie 2006), that is, it is
ceded the power to process data and to make automated, automatic and autonomous
decision-making and action, thus making aspects of the city sentient (Dodge and
Kitchin 2007; Shepard 2011);
2. code transduces space, that is, it alters the unfolding production of space through its
deployment (Dodge and Kitchin 2005);
3. the city becomes programmable, that is, open to recoding and remediation, but also to
being buggy and hackable (Kitchin 2011).
Code, it is thus argued, through its work as an actant produces forms of coded space, wherein
code augments or mediates the production of space but is not essential to its production, and
code/space, wherein code is essential to a space being produced as intended. Much of the
city is now produced as code/space, wherein if the code fails the space is not transduced as
desired (e.g., if checkout software crashes then a space is transduced as a warehouse not a
supermarket, or if check-in software crashes then the space is transduced as a large waiting
room -- in both cases there is no longer any manual way to process transactions; code and
space are mutually constituted). Moreover, code and forms of automated management are
actively and extensively employed in the management and governance of urban systems,
especially with respect to critical infrastructure and utilities (e.g., transport, energy, water)
and policing, security and surveillance.
Despite the rapid development and deployment of digital technologies for augmenting
city management and urban life, and the creation and rollout of new forms of networked
urbanism, it is fair to say that critical analyses of the relationship between code and cities is
small in number, underdeveloped conceptually, and lacking detailed empirical case material
(the same can be said for software studies more generally). The speed of technological
innovation and material deployment, and the power of the discursive regimes driving their
adoption, is outpacing and outflanking critical reflection and intervention. Moreover, critical
social scientists and humanities scholars are still struggling to get to grips conceptually with a
series of interrelated phenomena -- code, ubiquitous computing, big data, networked
urbanism, and smart cities -- at the same time as trying to map out and dissect their
3

consequences and implications. My book with Martin Dodge, Code/Space: Software and
Everyday Life (2011), was an attempt to provide such an overarching, holistic conceptual
framework and to make sense of the changes digital technologies were making to the urban
condition. As with all such texts it was provisional -- a staging post rather than definitive
guide.
In this chapter I want to revisit some of the conceptual ideas we developed and to
rework and extend them, focusing particularly on deepening and widening our
conceptualisation of code and software. The rest of the chapter is divided into two sections.
The first focuses on code itself and the importance of delving into the nuts and bolts and
mechanics of its constitution and operation, whilst at the same time not overly fetishizing
code at the expense of the wider socio-technical assemblage within which it is embedded.
The second focuses on how these socio-technical assemblages are framed within the wider
discursive and material technological terrain and urban landscape, and interact and scale to
produce densely instrumented cities consisting of millions of coded objects/systems all in
dynamic flux. In this sense, the two sections are trying to find a way of dealing with the issue
of productively building a conceptual understanding that scales from individual lines of code
to the complexity of an entire urban system; of building a conceptual edifice that moves
beyond marrying software studies to urban studies. This is no easy challenge, and I would
see the arguments I make as another provisional step that others will hopefully help develop
and make more robust.
II

Thinking about code and the city

In Code/Space we argued that software needed to be understood as being both a product of
the world and a producer of the world. Code -- the lines of declarations, procedures,
commands and algorithms, expressed in different languages (assembly, scripting, procedural,
etc) -- that when compiled create software are not simply the result of a neutral, technical
exercise. Rather coding needs to be understood as a complex and contingent process, shaped
by the abilities and worldviews of programmers and engineers, working in companies or on
their own time, situated in social, political and economic contexts (Rosenburg 2007).
Software development occurs in a collaborative framework, with individuals performing as
part of a team or re-appropriating code from libraries or ideas from websites, books and
magazines. Often several teams will work on different aspects of the same programme which

4

are then stitched together. Teams can have different visions about what they are trying to
achieve, and have different skill levels to tackle the job at hand. Software then is not an
immaterial, stable, value-free product, it is a complex, multifaceted, mutable set of relations
created through diverse sets of discursive, economic and material practices rooted in
particular locales. Moreover, this software does not simply represent the world, but actively
participates in it, transducing space, reshaping work, transforming practices, and so on
(Dourish 2001).
We argued for a need to, on the one hand, delve further into the nature of code itself,
and in particular to start to unpick how coding is actively practised and code created in
context, and on the other to examine the work that code does in the world. Here, I want to
focus on the former. In trying to make sense of code and coding with respect to urban
systems we advocated: (1) a focus on the code itself, deconstructing the lines of code and
examining the ways in which elements of the world, and ways to think about and process
them, are captured and formalised in sets of interlinked algorithms, and excavating how the
code and algorithms evolve through revisions and editions as they incorporate new ideas,
ambitions, policy and law; (2) ethnographies of coders and coding projects, including their
wider social, political and economic framing. In other words, we posited a very software
studies approach to making sense of code and cities.
I am still of the view that an in-depth focus on code and coding would be an
enormously profitable endeavour. Given the huge growth in forms of algorithmic governance
-- everything from recommendation systems, to automated forms of surveillance, to profiling
and sorting -- it is becoming increasingly important to understand the aetiology of code (how
algorithms are constructed and operate), how they are utilised, and to tease apart their
inherent politics (see Gillespie 2014; Kitchin 2014b). This is evident in two recent, excellent
software studies texts: Nick Montfort et al’s (2012) 10 Print, a detailed analysis of a single,
but iconic, line of code; and Lev Manovich’s (2013) Software Takes Command, in which he
provides an in-depth genealogy of the ‘softwarization’ of cultural media -- art, photos, film,
television, music -- that has taken place since the 1970s. That said, I have a major concern
with this approach in and of itself: it adopts an analytical lens that over-fetishizes and
potential decontextualises code at the expense of its wider assemblage of production and use.
Since the publication of Code/Space I have written another monograph -- The Data
Revolution (2014c) -- which I loosely thought of as the third book in a trilogy of sorts

5

(Mapping Cyberspace: infrastructure; Code/Space: software; The Data Revolution: data) and
started a large, five year European Research Council funded project, The Programmable City,
than involves ten subprojects focused on the intersections of ubiquitous computing, software,
big data and the creation of smart cities. Both projects have highlighted that the relationship
between code and the city is complex and diverse. Code/software are critical to networked
urbanism, but so too are data, platforms, hardware, interfaces, and users. And none of these
can be fully understood without being considered in relation to one another, nor outside of
their wider context. This has been bought home to me in two ways, which when combined
provide a path forward.
First, in The Data Revolution I develop the argument that to fully comprehend an
open data system, or a big data product, or a research data infrastructure, one needs to
examine its entire data assemblage (see Table 1). The apparatuses and elements detailed in
Table 1 interact with and shape each other through a contingent and complex web of
multifaceted relations. And just as data are a product of the assemblage, the assemblage is
structured and managed to produce those data (Ribes and Jackson 2013). Data and their
assemblage are thus mutually constituted, bound together in a set of contingent, relational and
contextual discursive and material practices and relations. This argument can be equally
extended to code/software (indeed, this is an extension of a discussion first expressed in
Code/Space and also at the start of this section). For example, an app like Foursquare or a
city GIS system consist of a large amalgam of apparatuses and elements that shape how they
are conceived, developed, administered, operated, and interactions with them deployed. A
GIS is underpinned by a realist system of thought; it pulls together and combines hundreds of
analytic and visualisation algorithms and dozens of datasets and has to be able to handle lots
of different data formats, standards, and protocols; it has a diverse set of accompanying forms
of supporting documentation, trade and academic journals; the system and its data are
maintained, updated and used by many collaborating stakeholders, through a diverse set of
practices, undertaken by many workers, using a range of materials and infrastructures; its
operational costs are a source of contention; its use is shaped by legal frameworks and
regulations; it is one part of a multi-billion dollar industry and community of practice; and so
on. And GISs continue to evolve and mutate as “new ideas and knowledges emerge,
technologies are invented, organisations change, business models are created, the political
economy alters, regulations and laws are introduced and repealed, skill sets develop, debates

6

take place, and markets grow or shrink” (Kitchin and Lauriault 2014). They are thus always
in a state of becoming. One cannot fully grasp the constitution, operation and work of a GIS
by concentrating attention on its code, despite the fact that without code a GIS could not
exist. It has to be framed as a socio-technical assemblage.
Table 1: The apparatus and elements of a data assemblage
Apparatus
Systems of thought
Forms of knowledge
Finance
Political economy
Governmentalities and legalities

Materialities and infrastructures
Practices
Organisations and institutions

Subjectivities and communities
Places
Marketplace

Elements
Modes of thinking, philosophies, theories, models, ideologies, rationalities,
etc.
Research texts, manuals, magazines, websites, experience, word of mouth,
chat forums, etc.
Business models, investment, venture capital, grants, philanthropy, profit,
etc.
Policy, tax regimes, incentive instruments, public and
political opinion, etc.
Data standards, file formats, system requirements,
protocols, regulations, laws, licensing, intellectual property
regimes, ethical considerations, etc.
Paper/pens, computers, digital devices, sensors, scanners, databases,
networks, servers, buildings, etc.
Techniques, ways of doing, learned behaviours, scientific conventions, etc.
Archives, corporations, consultants, manufacturers, retailers, government
agencies, universities, conferences, clubs and societies, committees and
boards, communities of practice, etc.
Of data producers, experts, curators, managers, analysts, scientists,
politicians, users, citizens, etc.
Labs, offices, field sites, data centres, server farms, business parks, etc, and
their agglomerations
For data, its derivatives (e.g., text, tables, graphs, maps), analysts, analytic
software, interpretations, etc.

Source: Kitchin (2014a: 25)
Second, I have been trying to assemble my thoughts with respect to making
conceptual sense of algorithms (Kitchin 2014b) and interfaces (Kitchin et al., 2014) that
draws on related, but distinctly labelled literatures (e.g., critical code studies, HCI, new media
studies), thus adding to my existing ideas with respect to infrastructure, code and data. This
has led to a consideration, drawing on the discussion and conceptual diagrams of Montfort et
al. (2012), Bogost and Montfort (no date), Van Dijik (2013, detailed in White 2014) and
White (2014) (see Figure 1), of the make-up of the digital technology stack (the elements that
work together) underpinning particular digital innovations/products/services that are
deployed in cities. In my version of the stack there are six elements: material platform
(infrastructure - hardware), code platform (operating system), data(base), code/algorithms
7

(software), interface, and reception/operation (user/usage). Each layer has effects with
regards to the others. For example, the hardware influences the choice of operating system,
which shapes the choice of programming environment; the form and extent of the data
influences how algorithms are constructed, as do user expectations and patterns of use; the
interface is constrained by the hardware and shapes user experience of a technology, and so
on (Montfort et al. 2012 has a nice discussion about how a single line of code and its output is
effected by what language it is expressed in, what parameters are selected, and the hardware
it is run on). Prioritising code, at the expense of the rest of the stack, places a constraint on
developing a holistic, socio-technical understanding of how a digital technology is conceived
and works in practice (White 2014). This holistic approach is also presently limited by each
layer in the stack being the focus of a particular field of study -- new media studies, HCI,
software studies, critical data studies, platform studies (see Figure 1).

Figure 1: Digital technology stacks

Taken together, the notion of a data assemblage and technology stack, has led to the
creation of an initial wider conceptual framing for The Programmable City project (from my
perspective -- whether the other ten researchers working on the project subscribe to it is an
open question) that intertwines these ideas into an overarching notion of a digital sociotechnical assemblage (see Figure 2). Within this perspective, code/software is just one
element, albeit a critical one, in a much wide assemblage that frames the interrelationship
between code and the city. And making sense of a socio-technical assemblage needs to draw
on ideas and empirical insights from a range of fields within critical social science and
science and technology studies, including new media studies, game studies, human computer
8

interaction, software studies, critical code studies, critical data studies, platform studies, as
well as anthropology, sociology, political science, economics and human geography.
Unpacking a digital socio-technical assemblage then is no easy task, but it is manageable as a
large case study given it is focused on a single assemblage, such as an program/app/system.
The city, however, consists of millions of interconnected socio-technical assemblages,
working in concert and contest to transduce the urban condition. A key question then is how
to make sense of this dense, interconnected web of assemblages that are constantly working
in dynamic flux? It is to this conundrum I now turn.

Figure 2: Conceptualising the constitution of a digital socio-technical system

III

Thinking about code and the city

The problem with examining in detail individual socio-technical assemblages is that the city
largely disappears from view. Certain elements get examined, but in isolation, meaning that a
more holistic understanding of how various systems combine and interact to produce the
whole is never formulated. Clearly cities are large, complex, multifaceted, open systems and
it is all but impossible to fully comprehend all their interlocking systems. Nevertheless, it is
9

possible to map out the ways in which socio-technical assemblages (mis)align, work together,
compete, coalesce to form larger assemblages, and so on. To date, very little detailed
empirical research has been conducted on how socio-technical assemblages are framed within
the wider discursive and material technological terrain and urban landscape, and interact and
scale to produce densely instrumented cities. Yet such research would usefully illustrate how
networked urbanism is being built and functions in practice.
In contrast, urban studies suffers from the converse problem. Since the early 1990s,
as noted in the introduction, a fairly substantial literature on the development of networked
urbanism and smart cities has emerged. These studies have focused on examining the effects
of networked, digital infrastructure on the management and regulation various urban systems,
and urban governance and economy more broadly, providing useful insights into how
software-enabled technologies are transforming cities and urban life. However, there is a
major omission in such work: it discusses the effects of digital socio-technical assemblages,
but rarely unpacks the constitution and mechanics of those assemblages. For example, a
paper might discuss anticipatory governance and its effects on civil liberties, or the security
vulnerabilities of the internet of things and its consequences with respect to privacy, without
explicating the specific ways in which systems are configured, code and algorithms work,
data are parsed and analyzed, users interface, engage, resist, and so on. In part, this is
because the socio-technical assemblages are black-boxed and it takes a bit more effort to
leverage access or to undertake approaches that would shine a light into the box (see Kitchin
2014b), but it is mainly to do with adopting a viewpoint that examines effects rather than the
causes. In Code/Space we illustrated this by comparing approaches that examine the
underlying epidemiology of ill-health and the effects of ill-health on the world. Our
argument was that whilst one can gain an understanding of the relationship between health
and society by studying how ill-health affects social relations, one can gain deeper insights by
also considering the specifics of different diseases, their aetiology, and how these manifest
themselves in shaping social relations. Similarly, one could examine how telematic networks
shape traffic management without studying how such effects are manifestly the result of how
the telematic assemblage constituted and configured, with rules and procedures formalised
within algorithms and code.
It seems to me, therefore, that we have a major disconnect occurring in the
literature. Science and technology scholars are focused on the nature of specific elements of

10

socio-technical systems. Urban scholars are focused on the embedding of digital
technologies into urban environments and their social, political and economic effects.
Occasionally these perspectives meet, but largely remain apart. A key question, for me at
least, is how to marry them into a conceptual whole, or at least place them in productive
tension. The solution seems to be to scale the socio-technical perspective up, and drill the
urban studies focus down so that they overlap in view and epistemology.
Figure 3 provides an initial attempt at setting out a conceptual framework for what I
term ‘programmable urbanism’ -- the instrumented, mutable form of smart cities -- that scales
between individual socio-technical assemblages and their components to the city and their
dense interconnection and embedding within a wider discursive, political and economic
landscape. The framework thus seeks to promote and support research that attempts to
simultaneously unpack socio-technical assemblages and chart their interconnections and
interdependencies and how they scale to frame and create city life. It thus aims to produce a
holistic analysis, examining how programmable urbanism is framed within a wider
discursive, political and economic landscape (the rhetoric of smart cities, for example) and
how it is built, functions and has effects in practice. The apparatus of ‘political economies’,
‘finance’, ‘governmentalities & legalities’, etc. appear in each socio-technical assemblage
and the wider landscape of smart cities to denote that there are a multitude of discursive and
material elements at play, some supporting individual assemblages and others the broader
terrain of city policy, that often align but can also be in conflict. For example, smart city
policy within a city might generally support technocratic forms of governance, but preclude
some forms due to legal interventions. Yet there could be active discursive field supporting
the rollout of precluded socio-technical assemblages.
Figure 3: A conceptual framework for programmable urbanism

11

Enacting this framework through empirical study would be an arduous task for an
individual, but it is certainly not beyond the bounds of a research team or network of
collaborators. It would also be possible to draw insights by stitching together the findings
and ideas from across the literature to create a synoptic analysis. It therefore seems plausible
that its vision could be realised, enabling us to gain an enhanced understanding of the
relationship between code and the city that scales from lines of code to the city in action.
IV

Conclusion

Cities are rapidly becoming composed of digitally-mediated components and infrastructures,
their systems augmented and mediated by software, with widespread consequences for how
they are managed, governed and experienced. A smart city is not a vision of a future city, as
often depicted in the media; it already exists in practice through the millions of
interconnected, digital socio-technical assemblages embedded into the fabric of cities that
frame how people travel, communicate, manage, play, consume, work, and so on. The
challenge for critical scholars is to understand the tightening bonds between code and the
12

city: how such bonds are configured and work in practice, and what they mean for how cities
operate and citizen’s lives.
My argument in this paper has been that whilst there has been much progress in
examining programmable urbanism there is much conceptual and empirical work to be done.
To date, the literatures concerning code and the city have remained quite divided, and both
have shortcomings. On the one hand, studies that focus on code are narrow in remit, fading
out the city, and tend to fetishize code at the expense of the wider socio-technical assemblage
within which it is embedded. On the other, studies that focus on the city tend to examine the
effects of code but rarely unpacks the constitution and mechanics of the code producing those
effects.
My contention has been that we need to marry the ideas within these two literatures
to provide a more holistic account of the relationship between code and the city. Building on
ideas initially developed in Code/Space (Kitchin and Dodge 2011), I have forwarded two,
interlinked conceptual frameworks. The first places code within a wider socio-technical
assemblage. The second conceives the city as being composed of millions of such
assemblages. In so doing, the latter seeks to provide a means of productively building a
conceptual and empirical understanding of programmable urbanism that scales from
individual lines of code to the complexity of an entire urban system. It is certainly not
comprehensive in scope or captures the complex processes and interdependencies at play.
But it does, I believe, provide an initial scaffold for seeking to scale software studies up
towards the city and to drill urban studies down towards code.

Acknowledgements
The research for this paper was funded by a European Research Council Advanced
Investigator Award to Rob Kitchin, entitled ‘The Programmable City’. ERC-2012-AdG323636-SOFTCITY

References
Amin, A. and Thrift, N. (2002) Cities: Reimagining the Urban. Polity, London.

13

Batty, M., Axhausen, K.W., Giannotti, F., Pozdnoukhov, A., Bazzani, A., Wachowicz, M.,
Ouzounis, G. and Portugali, Y. (2012) Smart cities of the future. European Physical Journal
Special Topics 214: 481–518
Berry, D. (2011) The Philosophy of Software: Code and Mediation in the Digital Age.
Palgrave, London.
Bogost, I. and Montfort, N. (n.d.) Levels. Platform Studies
http://platformstudies.com/levels.html (last accessed 7 August 2014)
Dodge, M. and Kitchin, R. (2005) Code and the transduction of space. Annals of the
Association of American Geographers 95(1): 162-80
Dodge, M. and Kitchin, R. (2007) The automatic management of drivers and driving spaces.
Geoforum 38(2): 264-75
Dourish, P. (2001) Where The Action Is. MIT Press, Cambridge, MA.
Foth, M. (2008) Handbook of Research on Urban Informatics: The Practice and Promise of
the Real-time City. Information Science Reference, New York.
Fuller, M. (2008) Software Studies: A Lexicon. MIT Press, Cambridge, MA
Graham, S.D.N. (2005) Software-sorted geographies. Progress in Human Geography 29(5):
562-80
Graham, S. and Marvin, S. (2001) Splintering Urbanism: Networked Infrastructures,
Technological Mobilities and the Urban Condition. Routledge, London.
Kelley, M.J. (2014) The semantic production of space: pervasive computing and the urban
landscape. Environment and Planning A 46(4): 837–851
Kitchin, R. (2011) The programmable city. Environment and Planning B 38: 945-951
14

Kitchin, R. (2014a) The real-time city? Big data and smart urbanism. GeoJournal 79(1): 114
Kitchin, R. (2014b) Thinking critically about algorithms. Programmable City Working Paper
3.
Kitchin, R. and Dodge, M. (2011) Code/Space: Software and Everyday Life. MIT Press,
Cambridge, MA.
Kitchin, R. and Lauriault, T. (2014) Towards critical data studies: Charting and unpacking
data assemblages and their work. Programmable City Working Paper 2, Social Science
Research Network http://ssrn.com/abstract=2474112
Kitchin, R., Lauriault, T. and McArdle, G. (in press, 2014) Knowing and governing cities
through urban indicators, city benchmarking and real-time dashboards. Regional Studies,
Regional Science
Mackenzie, A. (2006) Cutting Code: Software and Sociality. Peter Lang, New York.
Manovich, L. (2013) Software Takes Control. Bloomsbury, London.
Mitchell, W.J. (1995) City of Bits: Space, Place and the Infobahn. MIT Press, Cambridge,
MA.
Montfort, N., Baudoin, P., Bell, J., Bogost, I., Douglass, J., Marino, M.C., Mateas, M., Reas,
C., Sample, M. and Vawter, N. (2012) 10 PRINT CHR$ (205.5 + RND (1)); : GOTO 10.
MIT Press, Cambridge, MA.
Shepard, M. (2011) Sentient City: Ubiquitous Computing, Architecture, and the Future of
Urban Space. MIT Press, Cambridge, MA.

15

Ribes, D. and Jackson, S.J. (2013) Data bite man: The work of sustaining long-term study. In
Gitelman, L. (ed) “Raw Data” is an Oxymoron. MIT Press, Cambridge, pp 147-166.
Rosenberg, S. (2007) Dreaming in Code: Two Dozen Programmers, Three Years, 4,732 Bugs,
and One Quest for Transcendent Software. Three Rivers Press, New York.
Thrift, N. and French, S. (2002) The automatic production of space. Transactions of the
Institute of British Geographers 27(3): 309-35
Townsend, A. (2013) Smart Cities: Big Data, Civic Hackers, and the Quest for a New
Utopia. W.W. Norton & Co, New York.
Van Dijck, J. (2013). The Culture of Connectivity: A Critical History of Social Media.
Oxford: Oxford University Press.

16

Code-crowd: how software repositories express
urban life
Adrian Mackenzie Sociology Department, Lancaster University a.mackenzie@lancaster.ac.uk

Abstract
Is code an expression of urban life? This paper analyses around 10 million software repositories on GitHub.com from the perspective of how they include cities.
The methodology here relies on data-intensive work with bodies of code at a
number of diﬀerent levels. It maps the geographies of GitHub organisations and
users to see how location anchors coding work. More experimentally, it tracks
how urban spaces, movements and architectures ﬁgure in and conﬁgure code.
The paper’s focus is less on how code shapes cities and more on apprehending
code and coding as a way of experientially inhabiting cities. This approach
might better highlight how code expresses urban experiences of proximity, mixing, movement, nearness, distance, and location. It might also shed light on the
plural forms of spatiality arising from code, particularly as algorithmic processes
become more entangled with each other.

Introduction: centres, rules and indeterminacies
The initial step can be made through the venerable geographical act
of mapping the expanding realm of machinekind, clearly part of the
remaining terra incognita. (Horvath 1974, 188)
Writing in 2002, Nigel Thrift and Shaun French asked: ‘is there any way of
making a more general assessment of software in the city?’ (Thrift and French
2002, 314). They sketch some possibilities, ranging from hegemony to haunting:
It would be easy at this point to fall back on some familiar notions
to describe software’s grip on spaces like cities. One would be hegemony. But that notion suggests a purposeful project, whilst software
consists of numerous projects cycling through and continually being
rewritten in code. Another notion would be haunting. But again
the notion is not quite the right one. Ghosts are ethereal presences,
phantoms that are only half- there, which usually obtain their eﬀects
by stirring up emotions – of fear, angst, regret, and the like (Thrift
and French 2002, 311-312).
Their own empirical response to the question begins with the Y2K bug, and
the long lists of software potentially aﬀected by it: keypad locks, pagers, solar
panels, smoke detectors, camcorders, VCRs, elevators. Although these lists now
1

look dated, when a similar listing would include so many things that didn’t exist
in 2002, Thrift and French’s description of the eﬀect of software development on
urban space remains recognisable: ‘we will exist in a broadband world in which
the internet will be a permanently available ‘cloud’ of information able to be
called up through a number of appliances scattered through the environment.
These appliances will be something more than portals for information. Rather,
like many other devices which will not have internet connections, they will be
“practice-aware”‘(315) and ’will, through a process of cultural absorption into
practices, sink down from the representational into the non- representational
world, so becoming a part of a taken-for-granted set of passions and skills’ (318).
The fact that these developments more than a decade later are still very much in
train suggests that there is something quite predictable about the development
of software and coding in organising urban life and spaces.
What of the more general analysis of software in the city that Thrift and French
propose on the basis of the continually cycling and rewriting of code? In 2002
they listed three geographies that were driving code into cities: a geography of
writing code, a geography of power and control, and a geography of indeterminancy.
The ﬁrst of these geographies is the most obvious, the large and
complex geography of the writing of software – of the production of
lines of code – a geography that takes in many diﬀerent locations and
many diﬀerent languages and which has been built up progressively
since the invention of programming in the 1940s (Thrift and French
2002, 323).
According to Thrift and French, the geography of software writing clusters
around key places and regions: Silicon Valley, New York, London, and a number of auxiliary software mass production zones (often concentrating on tasks
like consulting, testing and support) in countries like Ireland and India. China,
Russia and Brazil are not mentioned. Second, a geography of power, which they
conceived in Foucaultean terms as the conduct of conduct, or massive proliferation of corporeally practiced rules, was unfurling through software: ‘in essence,
we can say that it [software] consists of rules of conduct able to be applied to determinate situations’ (Thrift and French 2002, 325). Through power-geography,
software increasingly interlinks rather than compartmentalises urban processes.
(Again, the ongoing growth of data analytics, virtualizing computing infrastructures, social media, mobile apps and sensors is largely consistent with this analysis of power.) The ﬁnal geography is the most open and the least geographically
localised:
the general profusion of software, its increasing complexity and consequent emergent properties, all count as means of producing playful
idioms that have not been captured by dominant orders. Software’s

2

very indeterminacy and lack of closure provide a means of creating
new kinds of order (328).
These playful idioms are largely irreducible to the centres of coding or powerladen control situations, and therefore will take on singular forms, unexpected
locations and non-representational aspects. Where does the geography of indeterminacy take shape? Against various attempts to see software and code as
either hegemonic, as law, as an epochal shift, as what has always haunted writing, or as the epitome of the post-human technics, Thrift and French sketched
the phenomenality of code as a form of traﬃc:
Software is more like a kind of traﬃc between beings, wherein one
sees, so to speak, the eﬀects of the relationship. What transpires
becomes reiﬁed in actions, body stances, general anticipations. We
would argue, then, that software is best thought of as a kind of
absorption, an expectation of what will turn up in the everyday
world.(Thrift and French 2002, 312)
These formulations are the most elliptical in the paper. But the ‘traﬃc between
beings’ they refer to here, the reiﬁcation of ‘general anticipations,’ the curiously
contrasting descriptions of software as absorption and expectation could be seen
as implicitly urban. They concern ‘traﬃc’ and ‘the everyday world.’
More than a decade later, when we think about software in ways that apprehends
both its power-laden capacity to format lives, experience, space and time, and
at the same time, sees software as itself a multiplicity, with its own becomings,
diﬀerences, and changes, do these geographies help us understand coded cities?
Writing in 2014, Thrift again asks about code in the city:
Take just the case of coded cities understood as a whole. Should we
think of them simply as projections of an autistic capitalist power in
which all consequences are externalized? Should we think of them
as entities gathered around matters of prescribed concern and uninterested in much that lies outside them? Should we see them as
tied into a kind of ethic of care by the need to roll over systems
which demand resilience? Should we see them as having an increasingly involved dream life, based on projection and retrojection of all
the searches, blogs and tweets that are continually being generated?
Should we see them as geometric beings, born out of constant requests for navigation? Should we see them as the result of newly
found abilities to represent arising out of advances in visualization?
There is no set format or single cause but what is clear is that it is
increasingly possible for these entities to learn – in however a limited
way – to transform themselves, to author themselves either through
emergent tendencies arising out of complexity or through simple happenstance which places them in unexpected situations which require
adaptation. (Thrift 2014, 13)
3

Thrift maps out an almost psychedelic sixfold topography of the ‘coded city’ –
as externalization of capitalist power, as prescribed matter of concern, as careladen responses to the demand for resilience, a projected-retrojected dream life,
as navigational geometry, and as materialized visualisation. And then suggests
that something links this diversity: the possibility for ‘these entities to learn
… to transform themselves.’ Echoing the 2001 discussion of indeterminacy, he
attributes this possibility to ‘emergent tendencies arising out of complexity’ or
‘unexpected situations which require adaptation.’
Although I like the sixfold evocation of the coded-city, I don’t ﬁnd emergence
or adaptation in general satisfying explanations of transformation. The 2001
formulations on indeterminacy and ‘traﬃc in beings’ occasioned by cycling and
rewriting codes appear more promising to me because they suggest both the
growth in code and the possibility of empirically tracing some forms of movement. I therefore propose that we understand coded cities’ ‘capacity to learn’
most immediately in terms of traﬃc in code. The ‘authoring,’ the ‘learning’,
and the transformations should not only be traceable in code, but coding itself
is one place where externalizations, matters of concern, geometries, projections,
visualizations, resilience-care, etc. come together and aﬀect each other.
Exploring the code traﬃc entails a theoretical move and a theory of movement.
The theoretical move is understand the ‘traﬃc between beings’ as moving and
mixing along various paths (such as those described by Thrift in 2014: projection, geometry, matters of concern, care-resilience, externalization, visualization,
etc.) through processes of imitation. I’m drawing on crowd sociology, including
the work of Gabriele Tarde and Robert E. Park, as a theory of imitative movement. For both Tarde the microsociologist of crowds and Park the urban sociologist, imitation is a tremendously powerful shaping force that semi-consciously
eﬀects repetition and invention, and generates new social forms of various kinds
(Borch 2012). In particular, Tarde speaks of ‘coadaptation of imitative ﬂuxes, a
cooperation, even in an individual brain, but always a multitude of agents social
and inﬁnitesimal, and their ordinary ideas’ (Tarde 1902, 270). While there is
much to discuss here (for instance, Tarde’s political conservatism and anachronism poses analytical problems), the ‘coadaptation’ of imitations in combination
with a multitude of inﬁnitesimal agents, beneath and around individuals, suggests some ways of tracking tendencies in code. Examining patterns of imitation
in code moves the emphasis away from code-shaping-cities to code-as-crowd. In
the code-crowd, imitation is not just follow-the-leader, although this is quite
prevalent, but also mutual shaping of imitative ﬂuxes running between people
and machines in places.1
To treat code-as-crowd is not to deny the production and power geographies of
code. It is not to say that code does not still act on cities, on space, on public and
1 This, I should note, is a departure from most crowd theory, crowd psychology and crowd
sociology. In most cases, objects hardly ﬁgure at all. As I will sketch below, points of
identiﬁcation occurs between systems, platforms, protocols and patterns just as much as
between individuals.

4

private practices. High proﬁle and much discussed changes taking place in computational platforms (mobile devices, cloud, etc) and in algorithmic processes
(machine learning) intricately reorganise urban life. What transpires there is
rapidly reiﬁed in actions, body stances, etc. But it might also be worth seeing
how cities, with their massive centralising tendencies, with their sometime globespanning relationalities, with their density of infrastructures, with their high
rates of reconstruction and repair, and above all with their aﬀective-practicalepidemiological contagions crowd into contemporary software. We would, from
this standpoint, no longer concentrate on following how software, code and
algorithms emanate from global centres as hypervisory control structures reorganizing cities. Furthermore, we would no longer focus on isolated pieces of code,
systems or applications but on the transverse ﬂows that change how code itself
moves and takes shape. We would apprehend coding itself as something closer
to pedestrian and vehicle movements in a busy street. That is to say, we might
attempt to see software and code as noisy, crowded, propagating aggregates in
which juxtapositions, proximities and patterns of imitation multiply through
each other, or convolve. To see code-as-crowd might bring us a few steps closer
to the traﬃc in beings that transforms itself. The practical paths that opens out
from seeing code-as-crowd concerns what we should look in studying software
and code. If code is a kind of traﬃc between beings, if is not only a community
but a metacommunity, not only an ecology but a crowd, then we need to ﬁnd
places where shape-shifting crowds assemble in code.2

From crowd-sourcing to source-code crowding: git as code
traﬃc
We can glimpse some of the traﬃc in code via source code repositories. A
huge number of code repositories (possibly around 50 million) are now hosted
publicly online at code repository sites such as GitHub.com, Bitbucket.com,
code.google.com and SourceForge.com. Focusing on one of these repository hosting platforms – GitHub.com, allegedly the ‘largest code repository on planet’
– might be a way to begin to ﬁnd a way of beginning to see traﬃc in code,
and to track how co-adaptive, inﬁnitesimal ﬂuxes ﬂow.3 The name ‘GitHub’
embodies a tension. git, an English word for a male person who acts foolishly or annoyingly, was chosen by Linus Torvalds in 2005 as the name for a
new concurrent versioning system for source code, the written texts on which
nearly all software development pivots. In 2002, Torvald’s work on GNU/Linux
epitomised for many people the emergent power of open source collaboration –
2 I’m not going to discuss this in any great detail here as this would require a lengthy
methodological digression. In what follows, however, various elements of a diﬀerent kind
of research practice in software-code as relational traﬃc, or code-as-crowd, are in play, and
they draw on various code and data infrastructures ranging from the APIs, cloud analytics
platforms such as Google BigQuery, newer forms of database and interactive data analysis
environments such as ipython and R.
3 It might also be a way of undermining the over emphasis on algorithms that blocks light,
I would suggest, on the richer cultural and social traﬃc in code forms.

5

‘crowd-sourcing’ – on the internet to build things outside the geographies of the
software industry. (But even then, as Thrift and French observed, Linux was
a quite centralised hierarchically and industry-supported software project). In
turn, git is a piece of software, a revision control system for code that allows
incremental changes made by many people working a common software project
to either coexist or ﬂow together. git is today probably the most widely used revision control system for code, followed by the interestingly named subversion.
git was meant to be radically de-centralised in the sense that no particular instance of a git repository would be the ‘master.’ ‘Local’ and ‘remote’ repositories
matter to git but their diﬀerences are only relative. Your local git repository
is my remote. And my local git repository is your remote. In principle, a decentralized network of repositories ‘push’ and ‘pull’ code to each other. Diﬀerent
repositories would clone and branch oﬀ from each other, and occasionally would
merge again, but not necessarily. The geography of coding becomes less aligned
to individual developers in speciﬁc times places and times, and more open to
a range of diﬀerent styles of code movement, ranging from a miasma of microprojects through to vast hierarchical code contortions. In practice, a whole
series of converging and diverging movements of cloning, forking, pulling, pushing, requesting, branching and merging comes out of git. These movements,
while certainly not unique or unprecedented in the history of inscriptive techniques, occur on a variety of scales. For instance, some git commands replicate
whole bodies of code, while others simply add, remove or alter small bits of
code. These scale-variations, I would suggest, matter to the ﬂows of imitation
that occur. Movements of code can take place very incrementally, as small bits
of code move around and they can take place on a large-scale as whole bodies
of code travel between diﬀerent bits of software. git as a contemporary site of
coding merits much more empirical description than this, but for the present
purposes git represents the distributed cycling and re-writing traﬃc in code.
Since late 2007, GitHub has provided a hosting platform for many git repositories. Obviously the name ‘GitHub’ adds a ‘hub’ to the de-centred ﬂows of git.
Given the multiplying scales of code traﬃc, what do the large code repository
platforms like GitHub add? From the perspective of the git software, GitHub
is just another remote code repository. But given that many, in fact around
13 million, local git repositories have GitHub.com as their remote repository,
then GitHub becomes a hub for git. The network and code traﬃc that now
runs through GitHub is on the scale of a mid-size social media platform. That
is, with 13 million repositories, 6 million developers, and around 250 million
events in the public event stream, GitHub itself is a kind of code city. It expresses something of the coded city, and the six-fold tendencies we discussed
above should be legible there in various combinations.

6

git in code-cities
In the spirit of git, GitHub.com as a platform, and indeed as a social media platform for coding, promises a radically de-centered patterning of movement. Several hundred GitHub staﬀ are scattered across a dozen or so countries, a somewhat dispersed geography for a relatively specialised software company started
in 2007 in San Francisco. GitHub work life is also putatively non-hierarchical,
with no management hierarchy, only a git-like structure of ﬂuid teams working
on projects. In principal, GitHub itself therefore makes itself into something
like a crowd or a swarm.4 GitHub as a social media platform adds many layers
of social media-style interface to code repositories, which by tradition have been
rather austere almost Reformation-style architectures. That is, they adorn code
repositories with all the social media-style apparatus of following, watching, liking, and tagging. So the social life of code repositories is formatted much more
in terms of watchers and followers in the same way that messages on Twitter
or pages on Facebook are watched and followed. Imitation and suggestion are
very much the modus-operandi of coding on GitHub.
How would a social media platform aﬀect the traﬃc in beings or the cyclingrewriting practices of coding? If we look at the 233 staﬀ listed as the GitHub
team, there is some evidence of their crowd-networked existence as they write
code to socially network coding. Githubbers such as defunkt, mojombo or
technoweenie have thousands of followers and hundreds of repos (i.e. repositories) to their names. Some of their repositories are heavily forked (copied),
suggesting that ‘passionate imitation’ occurs around their code. Precisely what
is being followed here requires more detailed investigation, but these several hundred team members all use GitHub itself to do their work on building GitHub.
So the hub-ness or centrality of GitHub is something to be produced or made
via a combination of geography, rules of conduct and new forms of order. As
a repository of repositories, GitHub’s mode of existence as code is a recursively
generated movement propelled in part by the Githubbers’ network of repositories and their interconnections with other repositories.
The geography of their work on GitHub is still very much centred on San Francisco, despite claims of de-centralization. Geographic proximity still matters in
code in many settings. But this centring is perhaps less important than the
kind of movements that occur in and around it. The table below oﬀers a view
on what happens as the several hundred Githubbers work on GitHub as a platform.5 It is important to note that only some of the GitHub code appears here.
4 The only problem with this is that the CEO and GitHub co-founder, Tom Preston-Werner
(a.k.a mojombo, id = ‘1’ in the GitHub user list – in other words, the ﬁrst Githubber ever)
has recently had to step down after much publicised allegations of sexist and discriminatory
language and behaviour in the workplace [@TBA]. I largely leave the workplace dynamics of
GitHub aside here, but they are symptomatic.
5 We can see some of what the GitHub team has been doing in GitHub repositories by
running queries against the GitHub API (Application Programmer Interface) or using the
GithubArchive.org archived datastream of GitHub activity. All of the numerical data in this
paper results from such queries. In the case of Table 1, the query process went: ﬁnd all the

7

Figure 1: ‘Figure 1: GitHub Team geography by country and city’

8

The GitHub team has private repositories. The most recursive repository of
all, github/github, the repository that contains the code for whatever GitHub
itself is, remains private.
type

count

PushEvent

112028

IssueCommentEvent

84098

PullRequestEvent

35990

CreateEvent

31080

IssuesEvent

25953

PullRequestReviewCommentEvent

16390

WatchEvent

13627

DeleteEvent

8033

FollowEvent

5400

ForkEvent

5283

CommitCommentEvent

4542

GistEvent

3063

GollumEvent

2260

ReleaseEvent

910

MemberEvent

897

PublicEvent

569

DownloadEvent

350

ForkApplyEvent

6

Table 1: Repository events generated by GitHub Team since early 2012
We can see the events shown in Table 1 (and Figure 2) as rough indications
of movements in code. In some ways, the formatting of the events in the categories shown in Table 1 is problematic for our purposes because these formats
already occlude diﬀerences in practice. They mix git-related practices such
as forking or committing with GitHub-related practices such as pull-request or
following. Disentangling what belongs to git from what GitHub has added
public repositories on which the named ‘actor’ works, and count the diﬀerent actions they
perform on those repositories. If we run this query for all 233 Githubbers as well as mojombo,
then something of the network of work done on GitHub itself begins to appear.

9

Figure 2: ‘Figure 2: Events on GitHub Team public repositories’
would be diﬃcult, but then this is precisely the kind of thing that would happen in the code-crowd. Putting this diﬃculty aside, the ratio of diﬀerent event
types suggests something of the ﬂow of code. While PushEvents embody code
writing, many other events, including IssueCommentEvents, PullRequestEvents,
IssueEvents and WatchEvents, point to diﬀerent kinds of traﬃc in code. ‘Social’
events outweigh the technical events.

GitHub as collective imitation machine
The GitHub team has participated in some way or rather (including just watching) in a total of 17000 public repositories, but they work much more heavily
on several hundred of these (see Figure 3).
The top repositories present a fragmented view of GitHub as an imitative
process. There are quite a few that clearly relate to GitHub or git itself.
It is hardly surprising that Githubbers contribute to the git repository or
re-implementations of git such as libgit2, objective-git, rugged, hub (a
‘wrapper’ for git) or many-branch-repo. All of these projects are imitations,
re-implementations or variations on git. They also make contributions to
repositories that relate to GitHub, ranging from document websites such
as https://developer.github.com or http://teach.github.com, websites that
promote or showcase GitHub (https://government.github.com/) or its features (24pullrequests), repositories for testing GitHub (hellogitworld),
repositories that actsas Q&A sites about GitHub(feedback), repositories that

10

Figure 3: ‘Figure 3: The main repositories the GitHub team works on’
contain code for accessing the GitHub APIs (http://octokit.net) or link GitHub
with other webservices (github-services) or other code development platforms
(git-tfs).
As well, GitHub team works heavily on conﬁguring the work of editing code itself. Repositories such as cloud9, dotfiles, gitignore, vimmode, rbenv, ace,
and atom ﬁgure prominently in the contriubtions of GitHubbers, and this is
also not surprising as the work of coding involves a lot of editing and drawing
on existing code. Conﬁguring editing tools and software development environments is a major preoccupation with software developers. The most worked on
repository, homebrew, is just such a conﬁguration repository – it implements a
software package management systems for MacOS computers. In terms of the
theory of code-crowd, this conﬁguration work render semi-conscious the practice
of moving through, reading and writing code. Conﬁguration work on writing
code attracts much attention generally on GitHub. There are also quite a few
repositories that concern how people sit down and keep coding. Play is a music
server: ‘We have employees all over the world, but Play lets us all listen to the
same music as if we were all in the oﬃce together. This has actually made a big
mpact on our culture’ (https://github.com/github/play). Similarly, Hubot and
Hubot-scripts are part of a software robot system that the GitHub team extensively use to maintain the GitHub platform, run the many online chatrooms
they use as they work with each other, to continuously deploy the changes they
11

make on the master branch of github\github into production and to send updates to various social media platforms. One Hubot runs the whole of GitHub.
Finally, many repositories listed here concern the infrastructure of GitHub.com
as a software platform. Some are language-speciﬁc environments heavily used
at GitHub such as rubinius, an implementation of the Ruby programming language. Some such as rails are web-framework libraries and they provide much
of the dynamic infrastructure that holds GitHub as a collection of servers and
databases. Other repositories such as choose-a-licence or linguist implement GitHub features to do with licensing or tagging repositories by programming language. Since GitHub repositories can also function as webpages, blogs,
or wikis, other repositories such as jekyll and gollum provide code for that.
Other heavily used repositories such as bootstrap, zepto and twui provide
elements of the graphic layout, colours, styles, fonts and icons that comprise
the visual appearance and interactive features of GitHub pages (and I return to
this kind of software below).
This brief circumnavigation of repositories that GitHub staﬀ themselves work
on or watch begins to ﬂesh out how traﬃc might move in the code-crowd. The
fabric of GitHub as a platform is somewhat recursively constructed and connected by many edges. It folds in many diﬀerent elements on various scales,
ranging from almost micro-perceptual conﬁgurations such as editor settings
through to large infrastructural developments such as elasticsearch. GitHub
comprises programming language implementations, server infrastructures, deployment mechanisms, web-frontend frameworks, various social media formats
(wiki, blog), Javascript page and graphic elements, as well as the code versioning system of git, robots that automate chatrooms and software they plays
the same music to developers in diﬀerent places and time. All of these together
recursively construct the platform, with varying degrees of coherence and visibility, ranging from the vital github/github repository through to the many
public facing repositories that Githubbers either release to the world or participate in publically. The loose concatenation of code elements comprising GitHub
is, I suggest, typical of the ways in which software hangs together today. Certain elements of the platform hold together more strongly together than others
and this registers in the event counts. For instance, the libgit2 generates a
large number of imitative events because the git functionality of committing,
branching, merging, forking, cloning, etc underpins nearly all of the other ﬂows
of imitation associated with the growth of 13.2 million repositories and several
hundred million events. Typically, for such entities, it migrates throughout the
software development ecosystem so that ‘bindings’ to libgit2 have been made
in almost any programming language imaginable, from Delphi to Lua, as well
as to database backends such as MySQL, redis, memcache or the ubiquitous
sqlite. The broader point here is that code traﬃc in and around GitHub is
itself constantly transformed, modiﬁed and intensiﬁed by the ﬂows of imitation
that Githubbers themselves semi-consciously generate as they assemble the platform. Music, robots, editors, libraries, databases and webpages intersect with
each other in the small-crowd teams of GitHub work and in the object of their

12

mimetic immersion, GitHub itself.
To return to Thrift and French’s three geographies in the light of this recursive
work of Githubbers on GitHub, we can now see that the geographical centring of
software writing still largely applies, but subject to some signiﬁcant transformations in how it relates to urban settings. The git version control processes open
centres to a more distributed and mutable bodies. It aﬀords heavily borrowing
from outside the platform, and makes code visible and at times even public for
many others. While the geography of power/control (conduct of conduct) no
doubt runs through much of what Githubber’s make (and here we could think of
the many DCMA takedown notices posted at https://github.com/github/dmca)
that seek to limit code traﬃc in various ways or the repo choosealicence that
seeks to regulate ﬂows of code according to legal licence), this power geography
seems secondary to the geography of indeterminacy that GitHub itself exempliﬁes and that it seeks to host into being by building out the GitHub platform.
Most importantly, we can see GitHub itself as a convolutional form, in which
diﬀerent aspects of the coded city – externalization, projection, visualization,
prescribed concern, ethics of care, navigibility – multiply through each other.
This convolutional growth occurs as traﬃc runs between people and objects of
various kinds (logects, codejects, etc). Even one platform, admittedly a key
platform for contemporary software development, recursively expresses in compressed form the sixfold ﬂows ranging across navigation, media, externalization
of relations of production, etc.

GitHub as convolutional process
The historical growth of code repository traﬃc since 2008 show something of
this human-object multiplication or convolution. The traﬃc in being can be
counted, like all traﬃc, in terms of event volumetrics (e.g. 13.2 million repositories). Such numbers, however, give us little sense of the convolutions in
that traﬃc. One important facet of those dynamics relates to what I have just
been describing: the composite and concatenated development of GitHub itself
as a social media platform that re-codes coding. But the device-speciﬁc formatting of code traﬃc that GitHub builds into events does not by any means
account for everything that happens there. That is, all the ‘social coding’ apparatus they create – Watchers, Followers, stars, showcases, search facilities, along
with their attempts to render crowds more like publics (see the ‘showcases’ at
http://github.com/explore for examples of this public-making) – does not saturate or exhaust the imitative ﬂuxes on GitHub. Just the opposite, they could be
seen as derivative attempts to capture and organize those ﬂuxes. The primary
ﬂuxes are more networked than the social media apparatus that GitHub wraps
around git because they are not reliant on the formats and facades supplied by
the GitHub platform. In other words, these convolutional ﬂuxes are the most
crowd-like aspects of coding, and they criss-cross geographies, cities, feeding
into and overloading the power geography of the code in many ways.

13

How would we sense something of these intense imitative ﬂuxes in the GitHub
traﬃc?6 Judging by their names, the ﬁrst 100 or so repositories on GitHub by
creation date suggest a rather orderly and sensible traﬃc in beings. Repository
names on GitHub are lightly formatted. Table 2, which shows the ﬁrst 50 repositories on GitHub, dating from 2007-8, illustrates something of this ﬂux. The
ﬁrst part of a repository name refers to a person or organisation (‘mojombo’,
‘wycats’, etc) and the second to the speciﬁc code repository. Both parts of the
full repository name are interesting. Their relation encapsulates the intersection
between people and objects that I think must ﬁgure centrally in any analysis
of code as traﬃc, or as imitative ﬂux. For the present purposes, however, the
second part of the name is more important since it refers more directly to the
code traﬀcic. In the early days of GitHub, these names are largely comprehensible in terms of the GitHub platform itself. Names like grit, a Ruby-language
version of git, git-wiki or merb-core (a Ruby web-development framework)
nearly all relate to various aspects of GitHub as a platform under development.
Other platforms and concerns are already present (amazon-ec2 or ebay4r) but
they are somewhat marginal to the work of developing a platform to host git
repositories.
orde

r repository name

1

mojombo/grit

2

wycats/merb-core

3

rubinius/rubinius

4

mojombo/god

5

vanpelt/jsawesome

6

wycats/jspec

7

defunkt/exception_logger

8

defunkt/ambition

9

labria/restful-authentication

10

technoweenie/restful-authentication

11

technoweenie/attachment_fu

12

topfunky/bong

13

anotherjesse/s3

14

anotherjesse/taboo

6 Here,

like Thrift’s, my analysis of the coded-city needs to become more psychedelic. Tracking imitative ﬂuxes means engaging with things that inherently lack any full formatting or
clear outline. I focus here on the names of repositories and the names of actors. I have argued
elsewhere that naming practices and code names spaces oﬀer a rich resource for thinking about
recursive and imitative processes in software culture [@Mackenzie_2014a].

14

15

mojombo/glowstick

16

wycats/merb-more

17

macournoyer/thin

18

jamesgolick/resource_controller

19

defunkt/cache_fu

20

bmizerany/sinatra

21

rtomayko/sinatra

22

jnewland/gsa-prototype

23

defunkt/mofo

24

schacon/ruby-git

25

mmower/simply_versioned

26

abhay/calais

27

mojombo/chronic

28

al3x/git-wiki

29

schacon/git-wiki

30

sr/git-wiki

31

queso/signal-wiki

32

drnic/ruby-on-rails-tmbundle

33

danwrong/low-pro-for-jquery

34

mojombo/yaws

35

grempe/amazon-ec2

36

peterc/switchpipe

37

up_the_irons/ebay4r

38

wycats/merb-plugins

39

atmos/ﬁtter_happier

40

brosner/oebfare

41

cristibalan/braid

42

evilchelu/braid

43

jnicklas/uploadcolumn

44

engineyard/eycap

45

chneukirchen/gitsum
15

46

brosner/django-mptt

47

technomancy/bus-scheme

48

Caged/groomlake

49

sevenwire/forgery

50

lazyatom/soup

Table 2: 50 early repositories on Github.com
A similar list from seven years later in 2014 reveals many complications (see
Table 3). The names of people and actors have become increasingly unrecognisable, even allowing for the internationalisation. The people/actor names
in GitHub become more and more like random patterns of key presses. (Indeed, thousands of repository and actor names comprise key sequences such as
qwerty or asdf or poiu or lkjh or 1234, all of which derive from the keyboard
layouts.) And something similar happens to the repository names. Only a few
components from the early days are recognisable in type (that is, things like
a blogengine or footer-fixed-boostrap, the bootstrap web development
framework is almost a ﬁxation for GitHubbers since it provides the look and
feel of GitHub itself). Many other elements of this stream are also recognisable
and long-standing ﬂuxes on GitHub: practice, Hello-World, testing and
temp repositories occur in huge numbers on Github (in the order of million or
more). These trivial ﬂuxes are like people starting to edge into a crowd, to form
part of a mass on the move. Broad swathes of generic imitation surface here
too. We can also see here the appearance of quite disparate matters of concern:
game-cho-android and AI_Project may have some similarities, but they at
ﬁrst appearance lie at quite a long distance away from each other.
orde

r repository name

12

m1tsu3/practice

2t

ylerdmace/ledomme

3y

ehiaelghaly/xssya

4i

stvan-antal/commandjs

5J

ohnKrigbjorn/ObjectOne

6c

henx/Ci35_1

7m

ohsenbezanj/AI_Project

8D

ineshkarthik/blogengine

9s

apanbhuta/Sapari

10 g

woodroof/chat-gwoodroof
16

11 t

ryuichi/Hello-World

12 p

rateek0020/NepTravelMate

13 d

iscoverﬂy/discoverﬂy.github.io

14 e

van-007/ng-wikiful

15 s

anemat/zipcode-jp

16 d

onreamey/PJKiller

17 d

iscoverﬂy/discover

18 j

kkorean/MIUI-KK

19 A

rtofacks1/ionic-app

20 j

kkorean/MIUI-JB

21 t

ycho01/rails-i18n

22 O

ksisane/Websockets

23 c

henxiruanhai/XScrollView

24 j

honM17/footer-ﬁxed-boostrap

25 M

cPringle/workshops

26 J

osemyD/testing-laravel

27 w

ngravette/FlogResources

28 E

thico/temp

29 T

ripod2K/cse223p

30 P

arbhat/tango_with_django_1.6

31 M

anuelAlanis/ios

32 k

owito/pnxstudio

33 r

aimana/activiti_merger

34 d

ylanling/connect_four

35 v

ipseo2014/game-cho-android

36 d

ylanling/connect

37 a

naloq/temvoc

38 a

554b554/algorithm-competition

39 a

7657z/12306_2

40 s

cwuhao/jumpybloc

41 j

jﬁne/post_mail
17

42 h

4di/PROYEK-TKPPL

43 E

XOgreen/TwitchBot

44 e

riccarpenterle/creepcreep

45 p

t1490/ubuntu-example

46 t

strimple/cookie-parser

47 A

ngAven/Pulse

48 l

yc4n/lyc4n.github.io

49 d

rjwhut/elebldc

50 m

ivim/fosiness

Table 3: 50 recent Github repositories
It is very hard to see any ﬂux of imitation here. Like the many repositories
named using convenient patterns of keystrokes, these repositories seem almost
like code-noise. If we start counting imitative events, things become a bit
clearer. For instance, in January 2013, around 200,000 repositories were forked
(or copied). Forking, I’m suggesting, is a basic imitative event in git-like practices. The most forked repositories have a now familiar look (see Table 4):
forks rep

ository

1478

bootstrap

1276

Spoon-Knife

763

dotﬁles

504

rails

426 ht

ml5-boilerplate

410

jquery

375

homebrew

345

linux

343

android

291 p

honegap-plugins

280

node

Table 4: Most forked repositories on Github in January 2013

18

This list is reasonably familiar since it has major platforms like linux, android
and node as well as well as the major test repository on Github Spoon-Knife.
But even if we just take the most forked repository bootstrap, this is not a
single imitative ﬂux. As we glimpsed already, the GitHub team takes a strong
interest in bootstrap, a set of components such as buttons, forms, progress
bars, tables, typographic elements and colour themes for web front end development. These visual elements ﬁgure heavily in the visual appearance of GitHub
as a social media platform, and hence, bootstrap already matters to the boostrapping of GitHub itself as a web-based platform. But bootstrap itself is not
singular entity. Look at what else was forked heavily in January 2013 relating
to bootstrap(see Table 5):
forks

repo

1478

bootstrap

109

bootstrap-datepicker

84

jekyll-bootstrap

60

bootstrap-wysihtml5

54

bootstrap-tour

48

twitter-bootstrap-rails

48

bootstrap-sass

46

bootstrap-datetimepicker

43

jquery-ui-bootstrap

42

bootstrap-modal

40

wordpress-bootstrap

36

bootstrap-daterangepicker

31

sass-twitter-bootstrap

31

Bootstrap-Image-Gallery

26

rails3-bootstrap-devise-cancan

26 bootstra

pwp-Twitter-Bootstrap-for-WordPress

24

metro-bootstrap

24

bootstrap-timepicker

23

bootstrap-toggle-buttons

23

MopaBootstrapBundle

19

twitter.bootstrap.mvc

19

19

bootstrap-switch

18

google-bootstrap

18

Bootstrap-IE6

17

gwt-bootstrap

17

django-bootstrap-toolkit

17

bootstrap-magic

17

android-bootstrap

16

sinatra-bootstrap

16

CodeIgniter-Bootstrap

Table 5: Forks of bootstrap related repositories during January 2013
While it was copied more often than any other repository in that month, the
bootstrap repository itself is massive overshadowed by all the variational imitations that accompany it. The total count of bootstrap related forks during January 2013 is for instance, 3074, almost twice the size of the forks of bootstrap
itself. Widening the frame a bit, we can see (Figure 4 & 5)that the since 2012,
bootstrap has been an important imitative ﬂux running through GitHub, and
has been the most highly ‘starred’ code repository on GitHub for several years.

20

From these stackplots of ForkEvents associated with the twitter/bootstrap
repository, we can begin to seem something diﬀerent about the imitative ﬂux.
The imitation varies over time as we would expect, but the patterns of imitation
are heavily interconnected with each other through repositories that juxtapose or
convolve diﬀerent repositories with each other. The several thousand bootstraprelated repositories are much more diverse than bootstrap itself. They combine
variously with mobile devices (‘Android’, ‘iOS’), with web-browser software(
‘IE6’), with various web-development infrastructures (django, rails, ASP, PHP),
with media platforms (WordPress, Google, CodeIgniter) and server management
systems (sinatra). They respond to events in the main bootstrap repository,
but also have a life apart from that repository that relates to other platforms
and other software projects.

Conclusion
We have little sense of how code ﬂows in cities, or of code-as-crowd. If code
itself is ﬂow, with its own recursive and convolutional dynamics working with
and against each other, then we might begin to see how see how the centring,
conduct and indeterminacies of code arise. I have been suggesting that we can
begin to get some measure of it by tracking how code moves through repositories,
and through other related settings. The repositories have become something like
the public places or squares where crowds assemble in cities. Unlike squares,
however, code repositories like GitHub are themselves part of the ﬂow of code.
They are part of the co-adaptation of imitative ﬂuxes. The ongoing production
of software is very much bound up with the ongoing transformation of urban
life through crowd dynamics. As we have seen, GitHub is itself made of and
part of the contemporary urban fabric.
The kinds of movements that I have been following on and in GitHub have
loosely borrowed from geographies of code cities. They include the centring

21

eﬀects of cities on the geography of software production, the ‘conduct of conduct’
and the indeterminacies of invention in software. But I have suggested that we
can see even in the elementary ﬂow of something like repository names the way
in which diﬀerent geographies come together in the code repositories. This ﬂow
of names is a poor substitute for the deeper interactions occurring as bodies of
code are cloned, forked, branched and merged.
While I have drawn loosely on the notions of crowd imitation found in Tarde or
Park, the more general argument does not depend so much on the precise theory
of crowds or urban life in question. For most urban crowd theorists, processes
of imitation lie at the heart of crowd formation and development. Imitation,
however, is usually either treated as a psychological process of suggestion or,
in the more Deleuzean formulations, as something that lies at the very core
of ﬂow: as Deleuze and Guattari write, ‘assemblages are passional, they are
compositions of desire. Desire has nothing to do with a natural or spontaneous
determination; there is no desire but assembling, assembled desire. The rationality, the eﬃciency, of an assemblage does not exist without the passions the
assemblages bring into play, without the desires that constitute it as much as
it constitutes them’ (Guattari and Deleuze 1988, 399). Deleuze and Guattari
had already developed a useful theory of crowd assembly, and their notion of
assembling as putting together, as composition, seems to me to still oﬀer useful
ways of thinking about how source code dynamics or the ‘source-crowd.’
There are many other dynamics on GitHub that we might analyse in these
terms. The very crude metrics of imitation based on forking could be turned
in various directions. I have mentioned the profusion of dotfile repositories
in the last few years. These repositories can be analysed in terms of microgestural and micro-perceptual diﬀerentations at work in the writing of code.
Choices of colour, font size, line separation, shortcuts for keystroke commands
and the multiplicity of conﬁgurations for code development could be used to
develop a much richer account of how people move through code, almost like a
‘gait analysis’ for code. Similarly, the metrics of the name space could, at a very
diﬀerent end of infrastructural dimensioning of code help us see how,for instance,
the scale of investments in infrastructures ripple across code-as-crowd. Many
of the inventive dynamics of GitHub could be identiﬁed as externalizations of
the investments in the scaling of digital media platforms to match the scales of
urban life.
Regardless of these possible directions of analysis, the broader point here is that
software today is less like a machine, a system or even an assemblage, and more
like a crowd. That is, it has ﬂuxing, ﬂowing and somewhat disordered existence
that generates powerful ﬂashes and movements, that creates atmospherics and
densely woven patches of order, but remain unstable and dynamic.

22

References
Borch, Christian. 2012. The politics of crowds: An alternative history of sociology. Cambridge University Press.
Guattari, Felix, and Gilles Deleuze. 1988. A thousand plateaus: capitalism and
schizophrenia. Athlone, 1988.
Horvath, Ronald J. 1974. “Machine Space.” Geographical Review 64 (2) (April
01): 167–188. doi:10.2307/213809. http://www.jstor.org.ezproxy.lancs.ac.uk/
stable/213809.
Tarde, Gabriel de. 1902. Psychologie économique. F. Alcan.
Thrift, Nigel. 2014. “The ‘sentient’ city and what it may portend.” Big Data &
Society 1 (1) (January 04): 2053951714532241. doi:10.1177/2053951714532241.
http://bds.sagepub.com/content/1/1/2053951714532241.
Thrift, Nigel, and Shaun French. 2002. “The automatic production of space.”
Transactions of the Institute of British Geographers 27 (3): 309–335. http:
//onlinelibrary.wiley.com/doi/10.1111/1475-5661.00057/abstract.

23

Encountering the city at hackathons
Sophia Maalsen and Sung-Yueh Perng
National University of Ireland, Maynooth

Abstract
The growing significance of hackathons is currently developing in a mutually informing
way. On the one hand, there is an increasing use of hackathons to address issues of city
governance – Chris Vein, US CTO for government innovation has described them as
‘sensemaking’ tools for government, encouraging agencies to make use of hackathons
and “let the collective energy of the people in the room come together and really take that
data and solve things in creative and imaginative ways” (Llewellyn 2012). On the other,
regular hack nights appear as creative urban space for citizens to discuss problems they
encounter and which are not necessarily considered by government, and produce
solutions to tackle these issues.
In this paper, we explore potential opportunities and tensions emerging as participants
discuss and pursue possible solutions. Through this, we reflect upon how such processes
translate the city and transform ways of living in places where the solutions are applied.
We further ask whether the positive discourse surrounding hackathons is justified or
whether there are limits to their ability to deal with the complexity of urban issues.

Introduction
Hackathons are programming marathons that are often organised as competitions and
close with judging the performance of codes or, more recently, apps. Often, they are
organised in variations of the following. They run somewhere between 12 to 48 hours
during weekends, and participants stay at the venue throughout the whole event. Lots of
free coffee, pizza or beer are provided and participants bring their own machines or
sometimes pre-assembled codes, if permitted, to join in the competitions. Participants form
teams on site or beforehand, depending on the rules organisers set. During this period of
time, teams emphasise on ‘collaborating to develop software products or prototypes aimed
at a particular problem or need, often offering awards for best solutions. The long-term
value of these codefests is informing new alliances and partnerships, discovering and
developing new ideas and approaches to problems, and providing the muscle needed to
make the new ideas and approaches a reality.’ (Popyack, 2014: 40)
Hackathons as an urban digital scene come with history, diversity and emerging dynamics.
Software developers have long had community events that predate hackathons where
1

they build codes and discuss issues or bugs they encounter during the process. However,
according to Meyer and Ermoshima (2013, 3) the term "hackathon" was coined the 4th
June 1999 by the open source community during an event in which coders worked on
cryptographic software and was adopted only ten days later as the name of a java
language coding competition. Although located in physically different places, these Java
developers had already been working collaboratively on OpenBSD, reflecting a distributed
form of collaboration. They eventually converged in Calgary, Canada, to create Internet
identity and security protocols and integrate them into an operating system, representing
an early incarnation of the hackathon. In its early stage, and within OpenBSD community,
attending hackathons had both technological and symbolic importance. The attendance
was funded and paid for by the foundation, apart from travel, and was by invitation only.
Hackathons, as claimed, were not ‘developer training events’ and only those who have
demonstrated their abilities or potentials would be invited to participate.
The term's use has since spread beyond tech communities into broader public use. Meyer
and Ermoshima (2013, 3) categorise hackathons into three types: “issue oriented” centred
around a problem or set of problems; "tech oriented" focused on developing systems; and
"data oriented" where the data sets required to be worked upon are supplied by the
organisers. These events are becoming increasingly appealing to entrepreneurs, venture
capitalists, and governments who see potential in these events to "reform their structure,
renew their methods of functioning, and attract the attention of developers" (Meyer and
Ermoshima 2013, 3). In some other market- and marketing-oriented events, there can be
no coding involved and the focus is shifted towards building marketing strategies and
companies quickly and effectively. In other instances, governments organise hackathons,
often in accordance with their release of public, open data, to satisfy specific urban needs
or functions, e.g. travel information update. The term hackathon has been further applied
to non-computing events to characterise events that have particular themes, focuses or
problems and are hosted during weekends, such as science or arts hackathons where
school pupils engage in projects achievable within a short period of time.
The social and ethical benefits derived from the use of open government data, has seen
an increase in "civic hackathons". Following the American "coding for democracy"
movement, Meyer and Ermoshima described the civic hacker as "technologists, civil
servants, designers, entrepreneurs, engineers - anybody - who is willing to collaborate with
others to create, build, and invent to address challenges relevant to our neighbourhoods,
our cities, our states and our country. To us a hacker is someone who uses a minimum of
resources and a maximum of brainpower and ingenuity to create, enhance or fix
something" (2013, 3). Thus, for them, hackathons contain an experimental element of
bricolage as well as being collaborative, heterogeneous and constituted by hybrid
networks, through which they question divisions of technical experts and others. This
creates an innovation and problem solving tool that creates "appropriate conditions to work
on a social challenge, to develop software and hardware solutions and to create a
sustainable community or ecosystem of technical and non-technical experts, lawyers,
activists and citizens" (Meyer and Ermoshima 2013, 6).
2

Despite their benefits, hackathons pose difficulties and questions as to the politics of
membership. Usually taking place in weekends and easily attracting developers,
hackathons tend to exclude women, parents, caregivers, contract or part-time workers and
those who have physical or medical conditions demanding them to take sufficient breaks
during the competition (further discussion in Porway, 2013). And by focusing on
programmers and app developers, processes of decision-making and prioritising could
marginalise the roles to be played by domain experts, social scientists, urban planners,
activists, public sector employees, local volunteers and interest groups. More crucially,
these processes can ignore the opinions and experiences of local residents whose
everyday lives are to be analysed, programmed and reconfigured and potentially altered
and disrupted. This is most acutely reflected in the apps that are produced and intended to
shape the "smart city", leading us to ask who is the smart city being designed by and for?
As Porway (2013) reflects on the NYC Reinvent Green Hackathon, rather than addressing
broader social problems faced by cities, there is a danger that hackathon"s only "solve the
participant's problems because as a young affluent hacker, my problem isn't improving the
city's recycling programs, it's finding kale on Sundays".
We want to know how is the energy, data, creativity and imagination, to which Vein
referred, interacting and is it having any real positive effect on the city and all of the
citizens who inhabit it? This paper further explores this theme by attending to two kinds of
forces often found at work during our participation at Code for Ireland meetups which do
not always seamlessly interact: what the developers want to do and what the government
or companies running the hackathon want to do. What vision do both see. Is it the same?
Do they want to contribute different things? Do they want different things from the
process? If not, how do different visions and supporters negotiate and align with each
other? By drawing on observations of hackathons at work, we comment on the messiness
of the process, also addressing the lack of research that has been done on hacking in
physical spaces, and question whether the products live up to the rhetoric.

An opening scene
Code for Ireland was launched in December 2013 and since then has had regular, monthly
meetings where participants can meet face-to-face, catch up with the progress of various
ongoing projects and provide networking opportunities for developers, community
members and other interested individuals. To further introduce Code for Ireland, we use
the following excerpt of the introduction from one of their meetups to show what this
voluntary organisation promotes and aims to develop:
We're a voluntary organisation just to give you an overview of how it started off,
which I'll just show you here now. Code for Ireland is about connecting
communities, who are looking to build out apps for their community, with technology,
so our software developers, front end designers, and then you've also got
3

government. So government have a lot of data so say we are looking to create a
disabled parking app, so where are all the disabled parking spaces in Dublin. We've
got Dublin City Council that have all that data, we've got the community that are
looking for an app like that, if there's needs like that, and then you've also got the
technologists who say, actually we know how to pull all that information together,
whether it's a data set, it's mapping expertise, or developing an app. So that's what
we're trying to do and then these people just get around a table and work out how
to build that, and that, what we're doing different to hackathons is, a hackathon you
get a group together, and then try and build something over say a day or a
weekend. This is a longer term approach. Can we build out an app for somewhere
in Dublin, that that can scale to Cork, to Kerry, to Belfast and then be reused and I
suppose with Code for Ireland the measure of how good an app is is really how
often it's been reused. So it's all open source, all the code was there for anybody to
redeploy.
From Code for Ireland’s perspective, they are placing the need of community in the front
line and using the events to recruit technologists to support community initiatives. They
have used various strategies to send out this messages including social media, setting up
their website and populating it with content about ongoing projects, creating a database of
diverse skill sets using online forms, and by word of mouth. Code for Ireland benefits from
having some members who have already been involved in open data and open
government initiatives in Ireland and thus are knowledgeable about where to find open and
existing datasets necessary for community projects, as well as experiences or connections
for requesting datasets that are not yet open to the public. Also, the organisation’s
emphasis on the need of local communities encourages people who only have partial or
little coding or software development backgrounds to participate. Since we started to
participate in the meetings from spring this year, there has always been participants
turning up for the first time, with backgrounds ranging from local government offices and IT
companies, to NGOs and local business. The momentum Code for Ireland is creating can
be demonstrated with an example of the turn out in the July meetup. Held in the Linked In
Dublin office, in a warm, breezy and bright summer evening, the meetup saw around 70
people registering their interests and about 40 people attending, working on 6 different
projects.
By organising regular events, and deliberately arranging them to take place on the
Thursday of the same week in a month, Code for Ireland tries to separate themselves from
a hackathon with their ‘longer term approach’. From a logistic perspective, this requires
repeated processes of sourcing and arranging venues, supplying pizza and beer, recruiting
administrative forces, distributing administration tasks and setting up marketing contents
and strategy. The following excerpt shows more clearly the kind of roles and skills needed
for ensuring that the meetup runs as expected.
So here some key roles, this is just for our team because we only started early on
this year so we're looking for like key members, like a good marketing person,
4

somebody on graphics, designers, and that's just even within the core Code for
Ireland team, never mind the apps that are looking to be built and then somebody
with social media expertise and admin people too
The logistics of regular hack nights provides a way to see how the landscape of civic
hacking is built. For the past few months, the meetings took place in the headquarters of
Facebook, Google and LinkedIn, the exception being the launch event which was held in
Dublin Castle, a popular historical venue for high-profile conferences and cultural events.
The meetups were all in the canteen area of the building, reinforcing the stereotypical
association of coders and developers with free food and drinks. But there is also an
element of Irish culture and hospitality here. During a conversation we had at another
coding event, the organiser was pondering whether food should be supplied to participants
in subsequent events. She felt obliged to ‘feed them’ because she felt it would not be right
to invite people to come straight after work, with empty stomachs, even though they can
bring their own dinner and they can benefit from their participation.
There is also irony or slight tension in the landscape of hack nights with regards to security
and transparency. In several occasions we and other participants had to sign
confidentiality agreement for entering the building, while effectively participating in an
event advocating openness and transparency. In others, we were not sure if we were
simply let politely in or were guarded, by the employees or the security the companies
hired, from the main entrance to the canteens so that we would not wander off, entering
restricted areas ‘by accident’. Despite these paradoxes, these same multinational IT
companies provide stability and sustainability for Code for Ireland by providing a place and
covering the costs for two to three gatherings.
Further building on the idea of understanding Code for Ireland as a cultural and digital
landscape, there is an emphasis within the organisation’s goals to build modular and
scalable apps that cuts across geographic boundaries and social needs, which raises
interesting questions for us. As the opening introduction continued (see transcription
below), the tension between code, geography and community starts to emerge. For Code
for Ireland, the app and code are stable and effective in the sense that functions can be
added depending on what community wants. Therefore, apps developed in an American
context can be quickly adapted by replacing a hydrant with a park. Complementing the
stability is the openness of the organisation and code, which allows the code to be further
disseminated to other Irish cities, or even to Northern Ireland.
So here's another thing that we're looking at. Code for All Ireland started from the
whole idea of Code for America and building apps, community apps, and what
these guys have already done is build out these apps which can scale across the
US but when we look at these apps there's a lot of them which can relate to Dublin,
to Galway, to Kerry, and because it's open source we can just enter that code. So
like, as for adopt a hydrant, which is looking after hydrants in Boston, we can

5

actually adopt a park, so you can take all that code and say I want to look after my
park and I'm going to get my community involved in it and do lots of stuff with it.
But what is less stable is the interest behind the code and the motivation that enables code
writing in the first place. Finding existing solutions is a good software development practice
to save time and resources, which are both scarce in voluntary activities. However, the
motivation for adopting hydrants is that they can be covered by the snow after winter
storms in Boston, and this can delay first responders in a fire situation. What would be the
motivation for adopting a park? So there is another issue regarding whether pursuing to
build an app for adopting something would become a duplicate effort. At the same time, we
could discuss the relationship between code and geography the other way around. Code
can be mutable, responding to similar initiatives which might be slightly modified in term of
requirements and specs according to the dynamics in local communities. It then becomes
clear that there are a lot of preparation and discussion needed before ‘we can just enter
that code’. This is an important element in a later stage when participants break into
groups to work on their projects, which we will discuss in the next section.

The place for hacking
The opening introduction is usually followed by a review of existing projects and call for
new project ideas. This part of the meetup is a combination of project updates and
feedback, as well as calls for new project ideas. Different backgrounds and skills that have
appeared at the events, are important ingredients for sharing ideas and expertise at this
stage, and throughout the rest of the evening. One can often hear the organiser reminding
participants, or even encouraging them, to move around between the projects: ‘It’s all
about sharing’, as it is repeatedly stressed.
Allowing participants to join in a project at any stage in its development, also fosters a
sense of openness within the organisation and the projects: open for joining the event,
conversations and projects taking place here and open for reappropriation and
reproduction elsewhere, by other groups of people and for different purposes. In early
hacking history, right to access was a critically important motivation, driving the writing of
open and free software, and the licensing of it to ensure the software would not be
privitised (Coleman, 2013). In a practical sense, Code for Ireland is pursuing openness
and sharing by starting to ask projects that are close to finish or have developed
considerably to move their codes to Github, an online service providing repository and
version tracking functionalities, among many others.
However, an app or a solution ready for re-deployment in other places are not always the
immediate outcome, or a criteria for evaluation, for the progress participants make at the
event. Openness often means right to access, to data, code and information and so on.
But it can also be thought of as an opportunity to learn, not only code but also the social
and human dynamics revolving around the processing of assembling code. The following
6

excerpt from a discussion occurred during the project update and feedback stage reflects
this aspect. The discussion started with recapping a project proposed in the previous
month. The participants proposed to build a Dublin dashboard, and one of them started the
update as following:
So it's intended priority is a big screen website rather an app on the phone. The
idea is for people to find out vital statistics about Dublin. So there are several
websites about cities … about Dublin city. The one for London will show you how
the tube is performing, or the air quality is like, and what the electricity demand is,
and so on. So the idea is to use similar information. So, you know the Dublinked ...
the open data. ... It'll be governed by what data is available, obviously, you know,
the more real-time the better.
While the project participant was preparing to close off the update, another event attendee
raised his hand and provided his advice, trying to warn the group not to repeat other
projects that already exist and are funded by major IT companies.
I was just gonna say you might want to watch out going down the path too far.
Because I'm kind of involved in Internet of Things space pretty heavy. … There is a
lot of smart city stuff happening by IBM, CISCO … . The application is here now,
and I have seen quite a few dashboards and applications coming out.
At this point, one of the Code for Ireland organisers interrupted, providing his support for
the dashboard project. The main reason to back the dashboard initiative within Code for
Ireland is the openness of different dashboard initiatives. Particularly for the ones that are
pursued by major tech companies,
Are they open though? This is the thing! Because lots of the IBM … You know what,
the other thing is you never know how long that's going to take to come out. I mean
it'd be interesting to just to, a lot of this is also learning how you take something
from an idea and what it takes to build a team, and even what it takes to build an
app. A lot of these is a learning curve, and getting people to involve. And you don't
even know you're going to meet in that group. So I think even, for me, I'd keep on
going anyway. I don't mean that in a bad way, just from a learning perspective.
Indeed, many questions can be raised regarding the effectiveness, comprehensiveness,
depth or efficiency of taking on board a big project by a voluntary group of interested
individuals. They might not be fully aware of the diversity of data sources, or
underestimate the time and energy required for cleaning and compiling the data before
any visualisation is possible. This is something that became evident in later projects about
the proposed dashboard. The scale of the project and the amount of resources and time it
would require, as well as the issue of duplication, steered the project in a slightly different
direction. The realisation that even the adapted proposal would require a lot of work
possibly beyond the time and skills the volunteers could contribute, have seen this project
7

decrease in momentum although there is still a belief in the value of persisting with it.
Furthermore, the issues related to social responsibilities and political complications as a
result of representing a city by its data might not be at the top of the group’s concern.
Alternatively, It may be that regular hack nights, like hackathons, produce rather ineffective
and cumbersome solutions. As Coleman notes, a hack is defined as a "clever technical
solution to arrived at through non-obvious means" (Levy 1984, Turkle 2005(1984)) but she
also highlights the definition supplied by The Hacker Jargon File, a hack "can mean the
opposite of an ingenious invention: a clunky, ugly fix, that nevertheless completes the job
at hand" (Forthcoming 2014, 1).
However, the "success" of the meetups is context dependent and goes beyond the just the
end product. The decision making processes and the social dynamics formed around the
product are an important measure of an app's success. In a conversation with one of the
organisers of Code for All Ireland, it was mentioned that the dynamic at the Ireland chapter
of the Code for All events is different from those in other countries. This conversation,
which we will discuss below, further explains why it is important to understand hackathon
in mutually shaping ways. The hackathon is a social space where apps are created
through discussion and negotiation. The social dynamics created in and through this
process are as valuable a ‘product’ as an app and encourage further participation. The
organiser had recently attended the Open Knowledge Festibal in Berlin with
representatives from international chapters of the Code for movement. He observed that
discourse in Berlin was strongly centered around transparency and measuring the
outcome of projects and whether they could influence government. This is something he
felt was slightly different to the approach at Code for Ireland where he thought their
approach to project management was less controlling in that the focus was not to make it
have ‘tasks’ as such. Instead, it is the enjoyable bit of coding, coding as a social and
leisure activity, that is an incentive for people to come and which in some part drives the
project. Here the focus was less on influencing government and more on enabling change
at a community level and in people’s lives. For example, with the immigration queuing app
that was being developed through Code for Ireland, the measure of success in his eyes
would be no longer needing the app at all because the app had enabled change at
management level, therefore reducing queues and the need for an app to estimate the
approximate waiting time. This is something he phrased ‘hacking the system with the app’.
The app becomes a means to the mission but is not the mission itself.
In other words, the belief being shaped here in Dublin is that the meetups are methods of
connecting communities, developing relationships between communities, governments
and tech people for creating a better city for all. It is reflective of the ideal of letting “the
collective energy of the people in the room come together and really take that data and
solve things in creative and imaginative ways” (Llewellyn 2012). The framing of
hackathons in this way also reframes negative connotations of hacking highlighting
"instead the original connotation of hacking as inquisitive tinkering (Levy, 1984; Turkle
2005(1984)), highlighting the hacker's ethics ability to emancipate its practitioners from the
iron cage of late modernity and capitalism and otherwise recuperating hacking's tarnished
8

reputation" (Coleman and Golub 2008, 256). It is this encouraging connotation of hacking
as tinkering and the opportunity to make things better through this that drives the current
wave of city and government endorsed hackathons.

The individual
The hackathon could not exist without those who participate. Although there is much
discussion pertaining to what hackathons can do for the city and communities, less
emphasis is placed on what hackathons can do for those who participate. As Coleman
(2013, 45) notes much of the research on hacking and F/OSS development focuses on the
more intangible spaces of bits and bytes but although such contributions are undoubtedly
worthy, it often neglects the existence of "face-to-face interactions among these geeks,
hackers, and developers". The reason she poses for this lack, is the fact that much of this
communication and interaction is "unremarkable - the ordinary stuff of work and
friendships" (2013, 45). Indeed, the social element was a strong influence and this is
certainly something we have observed in the coding events at which we have been
attending including Code for Ireland, Pyladies, a Python programmer meetup, and Coding
Grace, a female friendly gathering for learning to code.
Participants mentioned it was a way to meet people, and indeed with Pyladies and Coding
Grace, the programs were designed to encourage females to participate and engage with
technology in a supportive environment. As for Code for Ireland, while there may be some
spectacle lent to the Code for All Ireland by virtue of the venues, the googleness of
Google, and the emphasis on the project's PR, the majority of the interpersonal
communications reflect those of normal interactions and decision making processes:
discussing ideas, suggesting ways to approach the topics, somebody always typing and
ideas boards or sheets being added too.
There is often fluidity between the groups, encouraged by the organisers and enacted by
participants. The organisers promote the moving around between groups as a way of
sharing experiences and ideas:
And you get a sense of actually I like that one, I am going to join that group and see
what they are doing. And then it's all about sharing stuff, so if anybody else's got a
new app idea, you know, just feel free to come up and go. It's only for about 30
seconds or a minute, say hey this is what I am thinking of. And you'll be surprised,
people just go actually I am very really interested in getting involved in that.
Allowing participants to move freely between groups can be an effective way of sustaining
their interests in the event. For the participants, even if they are not ‘affiliated’ to a
particular group, they can still show up and provide their thoughts and experiences to
various groups just in one evening. Even when some people attach themselves to one
project one week, at the next meeting they may join another more "interesting-at-that9

moment project", or a project they feel has more potential to be followed through on or
contribute. However, group members may also not show up at all - emails being sent to
the online project groups about work commitments keeping them away being the most
common. Indeed at one event we went to, there was only one representative from the two
groups we had attended in the previous meeting. This stalled the process and made
decision-making hard. In one case, the project idea was changed quite substantially with
only one key member of the group there making decisions on behalf of the larger group in
consultation with a government representative who was persuading him to follow his idea
and reframe the project along new lines. This has considerable impact on the ability of a
project to be followed through to completion and to be the best and most effective solution
to that. What counts as a successful project or even a successful outcome of the
hackathon in general is debatable and varies dependent on the major discourses of
individual events.
Furthermore, while there was a general acknowledgement that the projects were not
operating in isolation and that the ideas were intended to benefit the community, often the
main driver for people to attend was some type of self gain. In our case, we were obviously
motivated by research and the need to study the field, but talking to other participants
brought up other reasons. As a result, practices of sharing and individual gains are both
pursued and cannot be separated from each other. By virtue of Dublin promoting itself as a
tech hub and attracting international companies such as Google and Facebook, we
observed that there were people involved from such organisations. Importantly, such
companies often import part of the workforce with them. One participant revealed that he
had moved to Dublin for work from San Francisco and that he was attending the event, not
just to donate his skills but to meet new people. For others it's a way to develop skills, to
engage with a broader community of programmers and developers and a social occasion,
with the free pizza and beer being an added bonus. As one participant observed, pizza
and beer is one way to get the techies in. The way hackathons can serve the individual is
described in a post in the KCITP website which highlights "7 reasons why you need to
attend hackathons" (Gelphman, 2011). These being:
1. Connect with passionate developers
2. Demonstrate your skills
3. Push yourself
4. Get feedback
5. Learn and grow
6. Become part of the community.
7. Change your life.
There is an individual element then, that is often overlooked in the hackathon and the
smart city discourse. Even when suggesting that hackathons are a way to become part of
a community, the emphasis is on what the community can do for the individual,

10

Community engaged professionals make great engaged employees.. Unfortunately,
many still think that staying "heads down" in their cube is a career strategy. It isn't.
Attending a hackathon like Hack Midwest is one of the best things you can do for
yourself. When you become part of the community, you'll meet/collaborate with
people who solve different problems & who have different experiences. These
connections and friendships can last a lifetime. ...and someday might lead to new
career opportunities! (Gelphman, 2011)
It is not just what people can do for the hackathon but also what the hackathon can do for
the people involved and we need to understand what that might mean for what is driving
the apps developed in such contexts. Mattern (2014) alludes to this sense of indvidualism
when she discusses what she terms the "widgetization" of urban resources. Many city
governments have developed web portals to showcase their open data, and they host
hackathons and competitions, usually resulting in apps that serve a single function —
finding farmer’s markets, for instance, or measuring air quality — and that rarely survive
without sufficient institutional support... Almost always, they frame their users as sources
of data that feed the urban algorithmic machines, and as consumers of data concerned
primarily with their own efficient navigation and consumption of the city. These interfaces to
the smart city suggest that we’ve traded in our environmental wisdom, political agency and
social responsibility for corporately-managed situational information, instrumental
rationality and personal consumption and convenience. We seem ready to translate our
messy city into my efficient city.
Mattern's critique of what kind of city is produced through the hackathon and who it is
envisioned by is shared by Porway (2013). Porway critiques the usefulness of just
"throwing data" at hackers and expecting something good and useful to come out of it,
"Most companies think that if you can just get hackers, pizza, and data together in a room,
magic will happen" (Porway 2013). He does not dismiss hackathons per se, but he does
emphasise the need to start with a clear question and definition of the problem, and make
use of subject matter experts to articulate the problems to which the data is related to the
hackers and to assess the results so that the process not only addresses the "what" of the
data but also the "why" the data is showing this - what are the plausible reasons for it and
how does this feed in to a solution (Porway 2013). Like Mattern, he sees the individuality
of many of the apps problematic. Using the example of NYC Reinvent Green Hackathon,
he demonstrates how the winning apps, including a "bikepoo" app and a farmer's market
inventory app, reflect the participant's problems and do not solve the greater sustainability
problems of the city. As Mattern indicates, this reflects the transformation from "our" city, to
"my" city, producing an individualized civics.

11

A continuing process and a conclusion
However, this is not to say that there is no reflection from the participants on the process of
pursuing individual interests under the name of citizen collaboration. As one of the Code
for Ireland participants questioned:
Just a situation, that thing is not really clear to me. Are we working on, was
government on one way data exchange? So basically government gives us the data
and we are not sending anything back to them.
At this point, the organiser responded with some thoughts about how then the
collaborative exercises pursued in Code for Ireland can hopefully create a working solution
and enough momentum to put pressure back on the government to reduce the queue in
government offices as a way of improving their performance:
Well I wouldn't say it that way. If you look at, Mark is doing the queueing app. If they
are not able to get the data from the government, they are crowdsourcing it. But
they can also feed that back to building something that is collaborative. So, while in
the first case, let's get data in, and let's get it frequently, like near real-time data,
that's one of its value. And then if you've got a product, or something that's built, if
you want to feed it back into them.
This reflects the conversation we introduced earlier in the paper on thinking of the
hackathon as enhancing the opportunity of change from a community level. There is no
doubt that the role of the government and the change it is willing to make (and actually
makes) should be included when considering the social life and consequence of
hackathon or other civic hacking events. The approach that Code for Ireland takes is not
without its internal tension and concerns. As we said in the beginning, what is introduced in
the paper is an opening scene for our research and certainly for a civic hacking event that
aims to take a long-term approach. There is space and need for making the plurality of
code and coders more explicit, so as to understand who and what kind of activities are still
missing in this approach. In doing so we also expand the discourse on the smart city, by
focusing on the people and the relationships they establish in proactively creating ‘smart
city’ spaces and tools. In this way we put people back into the smart city, addressing the
critique that much of the smart city discourse forgets about the actual people by focusing
predominantly on technology, in the process.

12

Works cited
Coleman, G. 2013 Coding Freedom: The Ethics and Aesthetics of Hacking. Princeton:
Princeton University Press.
Coleman, G. (forthcoming 2014) Hackers: The Johns Hopkins Encyclopedia of Digital
Textuality. Available at http://gabriellacoleman.org/wpcontent/uploads/2013/04/Coleman-Hacker-John-Hopkins-2013-Final.pdf [Accessed 3
July 2014]
Coleman, G. and A. Golub 2008. Hacker practice: moral genres and the cultural
articulation of liberalism. Anthropological Theory 8(3): 255-277
Gelphman, M. 2011. 7 reasons why KCITP’s upcoming Mentorship Kickoff Happy Hour is
the place for you! Available at http://www.kcitp.com/2014/07/01/hack-midwest-kansascity-hackathon/ [Accessed 15 July 2014]
Levy, S. 1984. Hackers: Heroes of the Computer Revolution. New York: Delta.
Llewellyn, A. (2012, June 29). The power of hackathons in government. (S. Herron, Editor,
& NASA). open.NASA. Available at http://open.nasa.gov/blog/2012/06/29/the-powerof- hackathons-in-government/ [Accessed 2 May 2014]
Mattern, S. (2013). Methodolatry and the art of measure. Design Observer. Available at
http://designobserver.com/places/feature/0/38174/ [Accessed 17 June 2014]
Mattern, S. 2014. Interfacing Urban Intelligence. Design Observer. Available at
http://places.designobserver.com/feature/how-do-we-interface-with-smart-cities/38443/
[Accessed 17 June 2014]
Meyer, M. and K. Ermoshina. 2013. Bricolage as collaborative exploration: transforming
matter, citizens and politics. Draft paper for the i3 Conference Cooperating for
innovation: devices for collective exploration, Telecom: ParisTech, 12 Feburary 2013.
Available at http://www.i-3.fr/wpcontent/uploads/2013/04/Meyer_conferenceI32013.pdf [Accessed 15 July 2014]
Porway, J. 2013. You can't just hack your way to social change. Harvard Business Review
Blog, 7 March 2013. Available at http://blogs.hbr.org/2013/03/you-cant-just-hack-yourway-to/ [Accessed 15 July 2014]
Turkle, S. 2005(1984). The Second Self: Computers and the Human Spirit, Twentieth
Anniversary Edition. Cambridge: MIT Press.

13

Interfacing Urban Intelligence
Shannon Mattern
School of Media Studies at The New School in New York

Rio Ops Center, designed by IBM. [Photo by the City of Rio de Janeiro]

Kicked a smart city lately?
By now you’ve heard the “smart cities” pitch. Our streets will be embedded with sensors, our
buildings plugged into the internet of things, our commons monitored by cameras and drones, our
urban systems recalibrated by real-time data on energy, water, climate, transportation, waste and
crime. Any day now, our cities will be marvelously transformed into efficient machines. But it’s not
so easy to see where you and I fit in. Most discourse on “smart” and “sentient” cities, if it addresses
people at all, focuses on them as sources of data feeding the algorithms. Rarely do we consider the
point of engagement — how people interface with, and experience, the city’s operating system.
As Ada Louise Huxtable might put it: Kicked a city lately?
Typically the urban interface is imagined as a screen. A 2011 report by the Institute for the Future
predicted displays “embedded in buildings, kiosks and furnishings,” delivering “‘supercharged’
interactions that combine speech and gestural inputs with immersive, high-definition graphics,”
while “ambient interfaces, which boil down complex streams of data to one or two simple
indicators, will lurk in the background of everyday urban life, quietly signaling in our periphery.”
[1]

1

And behind all those screens is a flood of data. The designers and engineers at Arup, consulting for
the city of Melbourne in 2010, proposed that so-called “smart cities” manage their informational
riches in centralized “clearing houses,” where analysts can consolidate and compare data from
disparate sources. A “real-time city model,” they wrote, “can enable an interface with citizens — a
form of ‘my city,’ which also enables feedback loops from people themselves. As well as an
interface onto the city, it also forms a kind of interface for the organization, possibly even indicating
how to change the organization itself.” [2] Thus, personalized streams of city data are rendered into
“actionable” information that makes our cities more legible, efficient and livable. [3]

Dashboard proposed by Arup for Melbourne city staff. [From Melbourne Smart City]

As more cities adopt these technologies, we are beginning to see the political and epistemological
contradictions of the smart city writ large, in steel and silicon. Underlying these personalized data
streams and opportunities for public engagement is still, almost always, a “black box” control
system. We’re empowered to report failed trash pick-ups or rank our favorite hospitals, but not
entitled to know what happens to our personal data each time we pass through a toll booth, or how
the doctor we rarely see knows our cholesterol is up. We often have little understanding of how and
where the mediation of urban systems takes place within the city itself. Nor do we know how our
intelligence translates into urban “sentience,” and what is gained or lost in the conversion.
City governments, technology companies and design firms — the entities teaming up to construct
these highly-networked future-cities — have prototyped various interfaces through which citizens
can engage with the smart city. But those prototypes embody institutional values that aren’t always
aligned with the values of citizens who have a “right to the city.” Judging from the promotional
materials released by Cisco, Siemens, IBM, Microsoft, and the other corporate smart-city-makers,
you’d think that one of the chief preoccupations of the smart city is reflecting its own data
consumption and hyper-efficient activity back to itself. At its heart is a “control center” lined with
screens that serves in part to visualize, and celebrate, the city’s supposedly hyper-rational operation.
Rio’s Ops Center, designed by IBM, integrates data from 30 city agencies; its layered screens
feature transit video feeds, weather information and maps of crime statistics and power failures and
2

other snafus. The city is thus partitioned into atomized projects, services and flows, each competing
for technicians’ attention. We see a similar “widgetization” in Arup’s proposed dashboard for
Melbourne staff: “This is Your City In Real Time.”
Governments and their citizens need to think more deeply about these designs. What does it mean
to “modularize” urban services? To offer a map-based snapshot of something as complicated as
“public health”? To permit users to filter data streams of interest? To dedicate prime screen space to
“fast-moving” data while pushing relatively static urban dimensions to the bottom of the screen?
What kind of intelligence do these windowed screens manifest?
If the ops-center dashboard has received too little critical analysis, the public interface has received
almost none at all. Some smart-city proposals represent the public interface as a schematic mockup,
with apparently little regard for interaction design. Others proffer a completely blank slate. (Intel
renders its Sustainable Connected Cities interfaces as tiny, benevolent explosions.) The range of
imagined programs and services is shockingly narrow: typically the street interface is little more
than a conduit of transit information, commercial locations and reviews, and information about
tourist attractions and cultural resources.

Tiny, benevolent explosions. Promotional image for Intel’s Sustainable Connected Cities program.

Many city governments have developed web portals to showcase their open data, and they host
hackathons and competitions, usually resulting in apps that serve a single function — finding
farmer’s markets, for instance, or measuring air quality — and that rarely survive without sufficient
institutional support. (Again, the “widgetization” of urban resources.) Almost always, they frame
their users as sources of data that feed the urban algorithmic machines, and as consumers of data
concerned primarily with their own efficient navigation and consumption of the city. These
interfaces to the smart city suggest that we’ve traded in our environmental wisdom, political agency
and social responsibility for corporately-managed situational information, instrumental rationality
and personal consumption and convenience. We seem ready to translate our messy city into my
efficient city.

3

Is that the city — or the urban interface — we want? Of course there will be people who opt out of
urban “smartness” altogether and move off the grid. But assuming that greater populations will find
themselves residing in networked, intelligent megalopolises, we need to give more serious
consideration to designing urban interfaces for urban citizens, who have a right to know what’s
going on inside those black boxes — a right to engage with the operating system as more than mere
reporters-of-potholes-and-power-outages. We need to focus attention on the “bleed points” between
the concrete and digital and social city, those zones where citizens can investigate the entwinement
of various infrastructures and publics. [4] And we need to examine the platforms that are already in
existence, and those that are proposed for future cities. Even the purely hypothetical, the speculative
— the “design fiction,” or what Bruce Sterling calls the “diegetic prototype” — can illuminate
what’s possible, technologically, aesthetically and ideologically; and can allow us to ask ourselves
what kind of a “public face” we want to front our cities, and, even more important, what kinds of
intelligence and agency — technological and human — we want our cities to embody.
We’ll need to consider how these interfaces structure their inputs and outputs, how they illuminate
and obfuscate various dimensions of the city, how they frame interaction, how that interaction both
reflects and informs the relationship between citizens and cities, and ultimately how these interfaces
shape people’s identities as urban subjects. We’ll need to challenge the common equation of
“interface” with “screen,” and the implications of reducing urban complexity to a two-dimensional
visualization. Can we — and I do believe this must be a collaborative, interdisciplinary enterprise
— envision interfaces that honor the multidimensionality and collectivity of the city, the many
kinds of intelligence it encompasses, and the diverse ways in which people can enact their agency
as urban subjects?

Pothole reporting as envisioned by the app Improve My City.
The Urban Stack
In his 1997 book Interface Culture, Steven Johnson defines the interface as “software that shapes
the interaction between user and computer. The interface serves as a kind of translator, mediating
between the two parties, making one sensible to the other.” [5] It is thus more semantic than
concretely technological. Branden Hookway, whose own book on the subject will be published next
month, agrees that the interface does its work “not as a technology in itself but as the zone or
4

threshold that must be worked through in order [for the user] to be able to relate to technology.” [6]
In that working-through, the interface structures the user’s agency and identity and constructs him
or her as a “subject,” which is different from a mere “user,” in that the subject’s identity shifts in
response to contextual variations and is informed by historical, cultural and political forces.
But the zone between person and machine is only the most visible type of interface. Computer
systems are commonly modeled as a “stack” of protocols of varying degrees of concreteness or
abstraction — from the physical Ethernet hardware to the abstract application interface — with
interfaces between every layer of this stack. [7] Alexander Galloway defines “interface” broadly, as
“a general technique of mediation evident at all levels.” At the user level — where we kick the city
— the technique might be graphical, sonic, motion-tracking, gestural (using hands or mice),
tangible/embodied (involving the physical embodiment of data and the bodily interaction of users),
or of another variety. [8]
Thus, we might think of future-city technologies as an “urban stack.” At the highest level, we find
all those zoomable maps and apps that translate urban data into something useful. Today, the most
ubiquitous vehicle for this digested and visualized data is the cell phone. [9] The widespread
availability of open data via smartphone apps (and globally via text message) has inspired many
urban residents to explore “deeper” down the stack, to understand how local systems work behind
the scenes: how their water arrives at their homes, for example, or where their garbage goes when
disposed. Previously in this journal, I’ve profiled “infrastructural tourism” and DIY data-science
projects that connect citizens with those often-obfuscated networks. [10]

The urban stack. Promotional image for Living PlanIT’s Urban Operating System.
Yet much of what’s “beneath” or “behind” the user interface remains inaccessible and unintelligible.
Powering these public-facing interfaces are highly sophisticated technical and administrative
networks that integrate urban services and infrastructures — water, power, police and fire services,
snow removal, etc. — with computer operating systems. [11] Living PlanIT, for instance, “owns
and monetizes” the Urban Operating System (UOS™) — with projects in London; Almere, the
5

Netherlands; and Paredes, Portugal — which “extracts, aggregates, analyses and manages sensor
data” in urban environments, thereby “harvesting useful intelligence and also enabling
management, control and greater efficiency for many city services.” [12] Control and efficiency:
these are the values — and the ends of intelligence — built into this system. Yet citizens don’t come
into contact with the Operating System; they merely reap its efficient rewards. The obfuscation of
the OS — largely intentional and perhaps even necessary, to the extent that it enables us to focus
attention on the data most immediately relevant to our urban experiences — is also risky. We forget
just how extensively these layered interfaces structure our communication and sociality, how they
delimit our agency, and how they are defining the terrain we’re interfacing with.
Futurist and urban theorist Anthony Townsend acknowledges, “It is difficult to see the
consequences of decisions about smart cities. The stuff of the smart city is literally invisible and
usually illegible to the layperson. It is hidden and privately-held. It is unimaginably complex, and
its impacts are often subtle, indirect and dynamic.” [13] Where’s the citizens’ “Lookout Tower,” he
wonders? How might we conceive of interfaces that allow us to monitor those aggregators and
protocols, and even deeper levels of the urban stack — the code, the hardware, etc. — that
undergird integrated (and often proprietary) urban operating systems? Below the human-computer
level of the urban stack, we have the wireless networks that transport the data from and to us, and
the application programming interfaces (APIs) that allow various entities — including third-party
companies, non-profits or individuals — to build apps that tap into our cities’ open data. [14]
Particularly given the complexity of these networks, and the profound implications their algorithms
can have for urban politics and our identities as urban “subjects,” we should have a means of
looking inside the box, if not tinkering with the code.

Indianapolis, 1914. [Courtesy of the Library of Congress]
Observers have long sought to wrap their heads around complex urban operations and to picture the
totality of the urban domain. The rise of print in the 15th century brought new maps and guidebooks
and public posters that shaped residents’ comprehension of and interaction with their cities. The
explosion of newspapers in the late 19th century likewise offered a new means of “overviewing”
the expanding, increasingly diverse, polyglot metropolis. The inventions of panoramic and aerial
photography and, eventually, satellite imagery offered ever-more comprehensive, scalable
representations of cities — and our places within them. [16] Today, media facades, public screens,
ambient interfaces, responsive architectures, and other forms of “public interactives” are
transforming our physical environments into interfaces in their own right. [17] In the Melbourne
proposal, Arup envisioned screens embedded in architectural facades, at transit stations, on the side
of trams, and hanging from posts on every block. Even local waterways, the designers suggested,
could become “ambient” conduits for visually (and perhaps sonically and haptically) sharing
information about their own workings.
Yet I have to wonder: interfaces to what? What is the “city” they propose to put us in relation with,
and how deep into the stack does that relation go? In too many cases the “city on the screen” is little
more than a set of measureable events, trackable movements, and rate-able services. Could we
develop urban interfaces that actually help us wade through, make sense of — and critically engage
6

with — the oceans of data generated by our cities and presented to us in edited form? Could
alternative modes of presentation encourage us to think about the biases, affordances and limitations
built into our tools and techniques of data representation? Could we “read” our urban interfaces —
our windows into the urban operating system — as a means of assessing the ethos of urban
development, ensuring that our cities’ operations are upholding an open, democratic ethic? [18]
Arup expressed a lofty vision:
A smart city is one in which the seams and structures of the various urban systems are
made clear, simple, responsive and even malleable via contemporary technology and
design. Citizens are not only engaged and informed in the relationship between their
activities, their neighborhoods, and the wider urban ecosystems, but are actively
encouraged to see the city itself as something they can collectively tune, such that it is
efficient, interactive, engaging, adaptive and flexible, as opposed to the inflexible,
mono-functional and monolithic structures of many 20th century cities. [19]
But we should push this even farther: the city should be not only tune-able, but also intelligible,
tinker-able and hack-able. The future-cities we’re developing should position themselves in
opposition not only to the inflexibility and mono-functionality of 20th century cities, but also to the
proprietary, trademarked “smartness” that is the dominant model for 21st-century cities. Rather than
making the city’s services and networks appear seamlessly integrated, rather than disappearing the
interfaces between the deep levels of the urban protocol stack, our interfaces could highlight the
seams — in our infrastructural networks, between various layers of the urban stack, and even within
the social fabric — thereby helping us to better understand how our cities function, and how we can
develop the necessary tools to monitor and modify their operation.

7

Renderings from Arup’s Smart City Melbourne.

Interface Critique
The most prevalent ways of thinking about human-computer interaction (HCI) are framed by values
central to engineering. According to media scholar Johanna Drucker, the evaluation of interfaces
typically involves “scenarios that chunk tasks and behaviors into carefully segmented decision
trees” and “endlessly iterative cycles of ‘task specification’ and ‘deliverables.’” [20] Such thinking
tends to equate the “human” in HCI with an efficiency-minded “user.” This is of course how much
smart-cities discourse frames inhabitants, too — as efficiency-minded, affect-less consumers of
8

urban resources. But if we want our cities to embrace a wider set of experiences and values —
serendipity, ambiguity, even productive, “seamful” inefficiency — and to facilitate more diverse
forms of human agency, what should we be looking for in those interfaces between the city and its
inhabitants? [21]
I offer elsewhere a more thorough discussion of a methodology for interface critique that draws
from the humanities and social sciences as well as engineering. Here, I’ll simply offer a rubric for
how we might evaluate our urban interfaces. We should consider:















The materiality, scale, location, and orientation of the interface. If it’s a screen: where
is it sited, how big is it, is it oriented in landscape or portrait or another mode, does it
move, what kinds of viewing practices does it promote? If there is audio: where are the
speakers, what is their reach, and what kind of listening practices do they foster?
The modalities of interaction with the interface. Do we merely look at dynamically
presented data? Can we touch the screen and make things happen? Can we speak into the
air and expect it to hear us, or do we have to press a button to awaken Siri? Can we
gesticulate naturally, or do we have to wear a special glove, or carry a special wand, in
order for it to recognize our movements?
The basic composition of elements on the screen — or in the soundtrack or object — and
how they work together across time and space.
How the interface provides a sense of orientation. How do we understand where we are
within the “grand scheme” of the interface — how closely we’re “zoomed in” and how
much context the interface is providing — or the landscape or timeframe it’s
representing?
How the interface “frames” its content: how it chunks and segments — via boxes and
buttons and borders, both graphic and conceptual — various data streams and activities.
The modalities of presentation — audio, visual, textual, etc. — the interface affords.
What visual, verbal, sonic languages does the interface use to frame content into
fundamental categories?
The data models that undergird the interface’s content and structure our interaction with
it: how sliders, dialogue boxes, drop-down menus, and other GUI elements organize
content — as a qualitative or quantitative value, as a set of discrete entities or a
continuum, as an open field or a set of controlled choices, etc. — and thereby embody an
epistemology and a method of interpretation.
The acts of interpretive translation that take place at the hinges and portals between
layers of interfaces: how we use allegories or metaphors — the desktop, the file folder,
or even our mental image of the city-as-network — to “translate,” imperfectly, between
different layers of the stack.
To whom the interface speaks, whom it excludes, and how. Who are the intended and
actual audiences? How does the underlying database categorize user-types and shape how
we understand our social roles and expected behavior? This issue is of particular concern,
given the striking lack of racial, gender and socioeconomic diversity in much “smart
cities” discourse and development.

And finally, what kinds of information or experience are simply not representable through a
graphic or gestural user interface, on a zoomable map, via data visualization or sonification? While
some content or levels of the protocol stack may be intentionally hidden — for the sake of “public”
security, for instance, or to protect Cisco’s and IBM’s intellectual property — Galloway argues that
some things are plainly unrepresentable, in large part because we have yet to create “adequate
9

visualizations” of our network culture and control society. [22] Urbanist and designer Adam
Greenfield proposes that some aspects of the city need simply to be made recognizable to the
machine, translatable through the interface:
As yet, the majority of urban places and things appear to the network only via passive
representations. The networked city cannot come into its own until these are
reconceived as a framework of active resources, each endowed with some manner of
structured, machine-readable presence, and the possibilities for interaction such
provisions give rise to.
Yet we should also consider — as Greenfield does in his larger body of work — the possibility that
some aspects of our cities are not, and will never be, machine-readable. [23] Affect, for example. Or
beauty. In our interface critique, then, we might imagine what dimensions of human experience and
the world we inhabit cannot or should not be translated or interfaced.

10

Stills from a promotional video for Urbanflow Helsinki.

Slabs and Clouds
We examined several real and hypothetical urban interfaces in the examples above. Let’s now
consider, in a bit more depth, two speculative projects that raise further questions about how
interfaces function, and how they inform our relationships with our data and our cities.
Urbanscale, an “urban systems design practice” — once a team, but now Greenfield’s solo practice
— lamented the way most cities make use of their digital surfaces and “situated screens” [24]:
We don’t believe that any particularly noteworthy progress will be made by dumping
data on a screen and calling it a day, let alone transposing an utterly inappropriate “app”
model from smartphones to large, situated displays. Urbanflow (Urbanscale’s urban
communication system) supports our contention that whether municipal, commercial or
citizen-generated, data only becomes understandable and usefully actionable when it’s
been designed: when it’s been couched in carefully-considered cartography,
iconography, typography and language.
Greenfield’s team proposed an “urban operating system” that would facilitate journey planning and
wayfinding (privileging pedestrian travel), service discovery (including locations, reviews, open
hours, etc.), access to ambient data (including information on all the signature “urban informatics”
concerns, like air quality and noise pollution) and “citizen responsiveness” (i.e., encouraging
citizens to report problems and make requests for public services). Urbanflow, they claimed, would
offer a “dedicated platform where the city and its citizens can meet.”
Their detailed proposal for the city of Helsinki envisioned larger-than-human-scale slabs positioned
throughout the city. These screens would detect motion, “wake up” when you walk by and “hail”
you to interact, and they would immediately place you in the middle of a map — “You Are Here”
— situated at your current coordinates, oriented to reflect the cardinal direction you’re facing.
Unfortunately, these mini-monoliths would obstruct your view of the real city; when you were
interacting with the screen, you’d have no choice but to be immersed in it. Yet the interactive
11

elements would help orient you spatially and temporally. The map’s night and day modes would
reflect the time of day. You’d also see, by default, a ring indicating how far you could walk in 5
minutes; zooming out would bring into view 10-, 15-, and 30-minute walkable areas. The preferred
subject position here, obviously, is that of the pedestrian. [25] Whether that’s your mode of transit
or not, Urbanflow suggests that “the city is here for you to use” (to quote the title of Greenfield’s
planned series of ebooks). [26] The interface thus reinforces a primarily egocentric position and an
instrumental approach to the city.

Printing out a route map with Urbanscale Helsinki.

Urbanscale and their partners, Nordkapp, paid more attention than most smart-city developers to
interface design and HCI-driven understandings of user experience, while also allowing for
serendipitous discovery and evincing a keen aesthetic sensibility. When you touched anywhere on
the map — crisply rendered in light-on-dark-grey at night, and lime-green-on-white during the day
— a “ripple effect” would register your touch and offer a peek at the available information. You’d
thus immediately recognize the map’s stack of data, and the city’s parallel stack of services. You
could toggle those layers — represented by flat, highly abstract icons in Marimekko colors — on
and off, allowing for focused navigation or comparison of disparate data sets. While working with
any particular layer(s) of data, the others would be dimmed or hidden. You could also pan and zoom
via familiar swipe and pinch gestures; thus the same screen could display “contextual, hyperlocal
information as well as broader, citywide content.” [27] Urbanflow would also allow you to search
for streets, places and things with an on-screen keyboard, and to print travel routes and transit
tickets from an embedded printer, translating the digital interface into a physical one. [28]
The design team claimed that, with Urbanflow, “the city itself becomes ... easier to navigate for
visitors, and more serendipitous for locals. City officials and municipal governments would be
provided with a completely new way to connect with citizens and visitors.” Still, we must wonder
about the politics of the interface’s egocentric framing: the fact that you, the user, are always at the
12

center. What urban imaginaries and realities are “toggled off” when your own navigational and
informational and service needs are always front and center? In addition, we should consider what it
means to represent highly processed data as flat, abstract icons. Much nuance is lost when complex
information, generated via unintelligible methodologies by invisible entities, is collapsed into
festively-colored 2D boxes. Finally, we should consider the implications of the screen’s monolithic
stature. The swipe gestures and ocularcentric presentation suggest that the city, like your
smartphone, is a place for casual visuality and “like”-based politics, where you can simply filter out
that which doesn’t interest you and route yourself around inconveniences. After all, the city is here
for you to use.

13

Renderings for The Cloud.

Our second example, “The Cloud,” is an interfacial monolith at superscale. Bringing together a
massive global team of designers and engineers and artists and organizations (including Arup,
Google and MIT), the Cloud was to be an observation deck for the 2012 Olympic Games. Yet just
as Nest’s thermostat isn’t your everyday widget, the Cloud wasn’t your everyday tower. Its tall,
spiral ramp would carry pedestrians and cyclists high up to a cluster of transparent inflatable
spheres and observation decks, where visitors could walk “among the clouds.” It was a rather highconcept project — the team’s 2009 proposal (never realized) was rich with allusions to poetry, art,
architectural history and meteorology — but we’ll focus here on the Cloud as an interface. [29]
First, the Cloud would provide points of view and visceral experiences not typically accessible to
the street-level Everyman, particularly not in mountain-less London. There is of course an ideology,
and a history, to this privileged perspective — that of the deity, the satellite and other militaristic
“visioning machines,” the CEO in the executive suite. Second, the inflatable structure was to be
itself a substrate for data visualization; it would allow for the geo-location of information about
medal winners and attendance at the Olympic events, energy use, transportation patterns, mobile
phone activity, even historical information about the region. And it would display some of that data
via augmented-reality interfaces, which would “layer” information on top of the landscape visible
below. But the Cloud would also generate data — this is my third point — by collecting rainwater,
harnessing wind and providing a unique sensory experience for visitors to be in the weather — in
the ubiquitous London clouds while in the Cloud. As explained by Dan Hill, then an Arup
representative on the design team, the Cloud would “take aggregate individual patterns and reveal
them at civic scale, thus binding the city’s activity together via a gentle ambient drizzle of data.”
[30]
Continuing the meteorological metaphor:
Like all tell-tale signs of brooding weather, the Cloud is a display system. It is both
screen and barometer, archive and sensor, past and future. The patterns of its animated
skins offer a civic-scale smart meter for the Olympic Park and for London as a whole,
sign-posting particular events, transport patterns, weather forecasts, timetables and
14

footage which can be real-time or decades old. Its movements can reveal the movement
of people below, or even within its structure, detected by hidden sensors — a space
alive to the touch, an aerial ecology.
It implements a radically new non-Cartesian method of spatial display (a suspended
ﬁeld of distributed LED signage) that enables it to be seen from all directions, including
from within. It destroys the antique divide between audience and spectacle; the people
become the project & projection, watching and learning from themselves, transmuted
into light. [31]
Pie-in-the-sky it may have been, but the embodied interactive experience is worth considering as a
model for urban interfaces. The Cloud proposed a macro-scale view that approximated the scale of
modern information networks, literalizing the metaphor of the data cloud. Participants would have
assumed the position of “aggregators” by walking around the space and kinesthetically,
choreographically, tying together various threads of data. [32] Its primary publics would have been
the visitors to Olympic Park — but because the monumental structure would be widely publicized
on television and the internet, its “audience” would have been global. That audience could have
posted their own relevant content on social media, which might have then made its way to one of
the screens inside the Cloud, for folks on-scene to see.
But we don’t know how that data would have been made perceptible. We see no representation of
the embedded screens or their interfaces in the team’s renderings, and we have no indication of
what other sensory outputs might have been engaged. The renderings emphasize visitors’ elevated
point of view and kinesthetic experience, which do indeed allow for a novel “embodiment” of urban
data. But I wonder: by transforming surveillance and aggregation into an immersive display, a fair
attraction, without addressing the power and privilege associated with those perspectives and roles,
would the Cloud have “destroy[ed] the ... divide between audience and spectacle,” or would it have
turned its subjects, and their data, into spectacle?

15

The Cloud.

Breaking the Frame
In his critique of financial interfaces, economist and philosopher Georgios Papadopoulos
acknowledges the potential of the interface to function disruptively (such a shame that this term has
been spoiled by Silicon Valley!), unmasking the norms and limitations of the financial system it
models, and offering a “transparent” look at its underlying ideologies. [33] Galloway similarly calls
for a “counter-cartography” — which might be realized through the urban interface — that reveals
and tests the protocols of our “informatic imagination.” It’s not enough merely to “intervene at the
level of ‘content’” — for instance, to use a flow chart or PowerPoint or Google Map to trace
networks of power. We have to test the “prohibitions” of our platforms’ forms and materialities and
affordances, too; we need to experiment with “new data types, new ‘if-then’ statements, new
network diagrams, new syllogisms.” [34]
Can we create a formal or structural parallel between the urban structures we desire and the
interfaces we create to mediate those cities? Are we sure, Hill wonders, that core civic values —
serendipity and productive inefficiency, personal and civic responsibility, “meaningful activity from
citizens and government, the city as public good, and ... diversity and regard for the affective
dimensions of urban experience — are part of the smart city vision?” Furthermore, he asks, “are our
governance cultures and tools in the right shape to genuinely react to the promise of The Network?”
[35] Are these same values embodied formally in our smart city interfaces? Could governments use
these tools to “boldly prototyp[e] new versions” of themselves? Could citizens use these same tools
to investigate urban power structures and access to resources? We should be using our urban
interfaces to afford our publics a peek “down the urban stack,” to the invisible infrastructures that
make the city work; to call attention to the unrepresented populations and urban problems that are
filtered out of our whitewashed and abstracted city renderings; to highlight opportunities for
improvement, and the roles everyday people could potentially play in effecting that change. We
could be using our urban interfaces to educate our publics about the nature of government and the
expanding “science” of urban management — about the methodologies of data gathering and
16

analysis, the politics of visualization, the algorithms behind the “urban operating system,” and the
servers and wires and waves that make it all possible.
Our urban interfaces could compel us to ask questions about what kind of cities we want, and what
kind of citizens we want to be. The creation of a better interface — an interface that reflects the
ethics and politics that we want our cities to embody — is necessarily a collaborative process, one
drawing on the skills of designers of all stripes, technicians, engineers, logisticians, cultural critics
and theorists, artists, bus drivers and sanitation workers, politicians and political scientists,
economists, policymakers and myriad others (including women and people of color, who have been
egregiously underrepresented in relevant debates). If our interfaces are to reflect and embody the
values of our city, the conception and creation of those interfaces should be ours, too — not Cisco’s,
not the administrators’, certainly not mine or yours. But ours.

Acknowledgments
I’d like to thank Josie Holtzman, my research assistant, for helping me to locate various examples
of urban interfaces; Eli Kuslansky from Unified Field, for generously sharing his firm’s work; Julia
Foulkes and Aleksandra Wagner, for providing feedback on earlier versions of this piece; and last,
but certainly not least, Rory Solomon, for guiding me through “the stack” for the past five years.
Notes
1. Anthony Townsend, Rachel Maguire, Mike Liebhold, Mathias Crawford, A Planet Of Civic
Laboratories: The Future Of Cities, Information, and Inclusion (Institute For The Future +
Rockefeller Foundation, 2010).
2. See Arup, Melbourne Smart City (2010), 24.
3. Unified Field, a New York-based design firm, proposes a similar infrastructure, but an alternative
nomenclature and ideology. They have called their urban model “Legible Cities,” as opposed to
the more common “smart,” “intelligent,” or “digital” cities, because, they argue, those terms
reflect government and corporate perspectives and prioritize “software services and urban
management and design.” Legible cities, by contrast, privilege “the end users’ point of view” —
their participation in and understanding of the city. See Unified Field, “Legible Cities” (May 30,
2012). Managing partner Eli Kuslansky told me that his firm has partnered with the
NewKnowledge Foundation to organize workshops in Kansas City that will consider how the city
might integrate “the hard infrastructure of [Google-supported] network operations, citywide
sensors, and open data with the soft infrastructure of knowledge sharing and community
resources.” Unified Field regards cultural institutions, schools and green initiatives as integral
parts of any “smart” infrastructure. See also the 2013 Ubicomp workshop, “Human Interfaces for
Civic and Urban Engagement,” which explored how public human interfaces in urban
environments could be used to engage “users in authentic settings for civic purposes.”
4. Consider the workshop “Interfacing with the City” at the 2011 FutureEverything festival in
Manchester; participants explored the city and documented the “bleed points” where the physical
and virtual world connected: CCTV cameras, WiFi routers, digital art, etc. They used this
documentation to discuss “how digital layers are visible or hidden and how their presence is
mediated through the city” See Erik Strutz, “FutureEverything 2011,” YOUrban (May 25, 2011).
5. Steven Johnson, Interface Culture: How New Technology Transforms the Way We Create and
Communicate (New York: Harper Edge, 1997), 14. On my website I offer a more thorough
discussion of the various ways of theorizing interfaces.
17

6. Branden Hookway, The Interface, Dissertation (Princeton University, 2011), 14.
7. Rory Solomon, one of my advisees at The New School, wrote a brilliant thesis — The Stack: A
Media Archaeology of the Computer Program — on the history of the stack metaphor. Part of his
work appears in “Last In, First Out: Network Archaeology of the Stack,” Amodern 2 (October
2013). See also Benjamin Bratton’s forthcoming The Stack: On Software and Sovereignty (MIT
Press).
8. Alexander R. Galloway, The Interface Effect (Malden, MA: Polity, 2012), 54. See also Paul
Dourish, Where the Action Is: The Foundations of Embodied Interaction (Cambridge, MIT Press,
2001); Eva Hornecker & Jacob Buur, “Getting a Grip on Tangible Interaction: A Framework on
Physical Space and Social Interaction,” Proceedings of ACM CHI 2006 Conference on Human
Factors in Computing Systems (2006), 437-446.
9. Of course some cities of the world are more concerned with providing basic urban services —
like adequate housing — rather than designing flashy interactive facades. In most of these
developing areas, according to Anthony Townsend, despite all the attention paid over the past
decade to cheap laptops, smartphones are “destined to be the true face of ubiquitous computing,”
a model of “everyware” computing that’s central to visions of the smart city, on the global scale.
See Townsend, Smart Cities: Big Data,Civic Hackers, and the Quest for a New Utopia (New
York: Norton, 2013). Cell phones “have spread the fastest and have become the single most
transformative tool for development” — and via SMS, they can deliver text-based data to
residents in less-richly wired parts of the globe (Christine Zhen-Wei Qiang, quoted in Townsend,
178). Some international development organizations have designed rugged public kiosks to
deliver urban informatics in these regions, too. See Lea Rekow, “Including Informality in the
Smart Citizens Conversation,” In Drew Hemment and Anthony Townsend, Eds., Smart Citizens
(Future Everything Publications, 2013), 35-38. She also addresses the widespread use of SMS
messaging systems.
10. See also Martin Tironi, Tomás Sánchez Criado, and Francesca Musiani’s proposed session —
“Opening Up the Urban Interface: The Smart City and Other Experimental Forms of
‘Infrastructural Politics’” — for the 2014 4S conference in Buenos Aires.
11. In an earlier article for Places, “Methodolatry and the Art of Measure,” I discuss the long history
of the “city-as-machine” metaphor, and of conceptualizing the city through computational
models.
12. “What Is Living PlanIT.” Other metropolitan areas are creating a “city protocol,” an “urban
innovation model” dedicated to the creation of “reports, standards, certification systems, services
definition, best practices and recommendations to turn cities into more innovative and sustainable
environments.” See “Barcelona, GDF SUEZ and Cisco Announce the Launch of the City
Protocol,” Cisco [Press Release] (August 28, 2012). “In the same way as the Internet Protocol
shaped the original development of the Internet, the City Protocol will be discussed and
developed internationally, setting up an evaluative protocol based on the agreement of a global
community. It will deliver benefits within and between cities, by addressing urban development
in an integrated systemic way.” Such projects are predicated on the assumption that cities from
Kenya to Canada to Cambodia operate on a standardized system of rules, regardless of local
history, culture, geography, climate, etc.
13. Townsend, “To Know Thy City, Know Thyself,” In Hemment and Townsend, 24.
14. Townsend argues “community-owned broadband is one of the best investments a smart city can
make”; which not only allows citizens ready access to web-based content, but also “puts the city
in control of its own nervous system, giving it tremendous bargaining power over any private
company that wants to sell smart services to the city government or its businesses or residents”
(Smart Cities, 288).
15. Rose Marie San Juan, Rome: A City Out of Print (Minneapolis: University of Minnesota Press,
2001); Bronwen Wilson, The World in Venice: Print, the City, and Early Modern Identity
1

(Buffalo: University of Toronto Press, 2005).
16. Giuliana Bruno, Atlas of Emotions: Journeys in Art, Architecture and Film (New York: Verso,
2002); Erkki Huhtamo, Illusions in Motion: Media Archaeology of the Moving Panorama and
Related Spectacles (Cambridge, MA: MIT Press, 2013); Jeanne Haffner, The View from Above:
The Science of Scoial Space (Cambridge, MA: MIT Press, 2013); Anthony Vidler,
“Photourbanism: Planning the City from Above and from Below,” The Scenes of the Street and
Other Essays (NY: Monacelli, 2011), 317-28; Laura Kurgan, Close Up at a Distance:
Mapping,Technology, and Politics (Brooklyn: Zone Books, 2013); Lisa Parks, “Zeroing In:
Overhead Imagery, Infrastructure Ruins and Datalands in Afghanistan and Iraq,” In Jeremy
Packer & Stephen B. Crofts Wiley, Eds., Communication Matters: Materialist Approaches to
Media, Mobility and Networks (New York: Routledge 2012), 78-92.
17. Arup, 16. For more on ambient interfaces, see Malcolm McCullough, Ambient Commons:
Attention in the Age of Embodied Information (Cambridge, MA: MIT Press, 2013).
18. Townsend, Smart Cities. Townsend suggests that we need “a new social code to bring meaning
to and exert control over the technological code of urban operating systems.” Part of that social
code is an ethic of technical development — a commitment to creating “simple, modular, and
open source” urban software and an “organically evolved set of open standards”; to documenting
and archiving our data streams; and to “modeling transparently” — to “exposing the algorithms
of smart-city software,” most of which are guarded by government and industry (Townsend 2013:
284, 287, 290, 295).
19. Arup, 8.
20. Johanna Drucker, “Humanities Approaches to Interface Theory,” Culture Machine 12 (2011), 1.
See also Drucker, “Performative Materiality and Theoretical Approaches to Interface,” Digital
Humanities Quarterly 7:1 (2013).
21. Anthropologist Dorien Zandbergen writes about her involvement in an interdisciplinary team
that designed an air-quality reading device. She found that compromises and contradictions in the
design pointed to “different types of futures, and, by extension, to different ways in which the
ideal of this alleged smart city can be realized.” While the device’s hardware was open-source, its
software was commercial, which meant that its full features were available only to paying
customers. Furthermore, when the device was ultimately enclosed in a shiny, user-friendly casing
— thus black-boxing the critical issues debated throughout the design process — the device
“stopped facilitating discussions about the actual meaning and reliability of the data, and instead
adopted marketing language, selling ‘transparency,’ ‘efficiency,’ and above all, a Plus account
with helpdesk facility.” She suggests that, in smart cities, “user-friendliness” should apply not to
its “flashy interfaces and shiny casings,” but to “discussions of power and value that go into the
production of our everyday technologies.”
22. Galloway, 91.
23. See Adam Greenfield, “The City Is Here For You To Use: 100 Easy Pieces,” (December 3,
2012). This sentence was edited shortly after publication to acknowledge Greenfield’s larger body
of work.
24. This sentence was corrected after publication. It previously stated that Urbanscale’s practice was
defunct. We apologize for the error.
25. Contrast with Pentagram’s WalkNYC maps, which give equal emphasis to pedestrian, bike and
mass transit routes.
26. This sentence was edited after publication to correct a production error; “the city is here to use”
is not the subtitle of Greenfield’s ebook Against the Smart City but rather the series title.
27. The platform’s aesthetics are contextual, too. Urbanflow Helinski’s type is rendered in Proxima
Nova, described as possessing a mix of humanistic proportions and geometric style — a
description that fits the work of Alvar Aalto, Finnish hero, equally well. The softly modern type,
combined with the Marimekko color scheme, make this particular mockup’s aesthetics highly
2

contextual. Urbanscale’s documentation explains that the map’s design “takes inspiration from
design-conscious Helsinki” — and, I would add, from Finnish modernism at large. Other cities
can layer their own customized icons and typography atop the platform’s stable “behavioral and
perceptual functionality.” Urbanflow thus aims to reflect its rootedness and relate to its publics,
which, according to Urbanflow, ideally include both national and international visitors and locals.
The feedback functionality in particular would appeal to locals, who might not otherwise want to
be seen interacting with an informational kiosk — often a clear indicator of one’s “outsider”
status.
28. We might find additional applications for the physical print interface by examining Mayo
Nissen’s City Tickets project.
29. Rather than attempting to describe the project in all its structural and symbolic complexity, I’ll
instead direct you to the online documentation.
30. Dan Hill, “Sketchbook: The Cloud,” City of Sound (November 11, 2009).
31. Brochure for The Cloud (pdf).
32. The potentially global nature of these data streams raise another important concern regarding
urban interfaces: the need for federated data hubs, which allow various systems to interlink and
ensure their sustainability. Eli Kuslansky, from Unified Field, is particularly adamant that cities
address these concerns.
33. Georgios Papadopoulos, “Digital Money, the End of Privacy, and the Preconditions of PostDigital Resistance,” Post-Digital-Research (December 9, 2013).
34. Galloway, 94, 97.
35. Dan Hill, “On the Smart City; Or, a ‘Manifesto’ for Smart Citizens Instead,” City Of Sound
(February 1, 2013).

3

Moving applications: A multilayered approach
to mobile computing!
Jim Merricks White!
Introduction!
Smart phone applications (or apps) are a relatively recent but already nearubiquitous way of engaging with the city in the global north. A search for ‘Dublin’ on Apple’s
App Store and Google Play reveals a rich marketplace of apps for: catching up on local
news, monitoring flight arrivals, navigating tourist attractions, negotiating bus timetables,
finding bike or car hire services, paying for parking, discovering events and finding the
right restaurant. Smart phone applications are a common, everyday way of exploring the
city.!
As a geographer interested in the intersection of code and the city, the smart phone
application presents a rich site of research, but one that is not without its challenge. On the
surface applications offer a quite simple representation of information about a particular
subject. But in order to perform this task they must recruit a vast and complex network of
interlocking technologies.!
This chapter offers a multilayered model to help researchers open the black box of
mobile applications. The hope is that this model is clear enough to be readily graspable,
but not so reductive as to set a horizon on theoretical engagement, or fall into a trap of a
technological or sociological determinism.!
The chapter is organised in three parts. I begin by looking at different approaches to
computational technology in the city from within the discipline of geography. I make the
argument that previous research has tended to focus on one particular layer of what I am
calling the socio-technical stack and so fetishise that layer at the expense of others. In the
second section I present the multilayered model and its origin between media studies, and
science and technology studies. This is then used to inspect two apps, Hailo and Moves,
with particular attention given to their points of intersection with urban politics. This
discussion is based on my own experience with the applications, on informal discussions
with friends and colleagues, and on encounters with people using the applications in
Dublin. I will – not unproblematically – refer to a ‘normal use’ of Hailo and Moves. I
conclude by touching on what a multilayered approach may mean for geographical enquiry
into code and the city, and by highlighting some of the literatures which may prove useful
in developing a more fully conceived ontology.!
1

The geography of mobile computing!
While geographers have theorised the spatial effects of hardware (Graham and
Marvin 2001), software (Kinsley 2014) and data (Wilson 2011), there remains little
concerted effort within the discipline to explore mobile computing as a socio-technical
system which incorporates all of these components.!
In their development of the concept of splintering urbanism, Graham and Marvin
(2001) emphasise the control which private and publicly listed companies increasingly
have over networked infrastructure. They contend that the liberalisation and privatisation of
the welfare state has lead to a stratification of utility provision and an elision of its
fundamental necessity to everyday life. While their revealing of the politics of infrastructure
has motivated proper attention to the materialities of technology in the city, Graham and
Marvin’s focus is on large scale, structural forces. As a result they leave unexplored two
important questions for a study of mobile computing: how do networked devices move?
and, how can computationally enabled agency be properly accounted for?!
The geography of software offers some ways to begin to address these questions.!
For Thrift and French (2002) software is both a hybrid human-object network and a
performative textuality. In the first instance, the modelling of algorithms after biological
systems has imbued in software a semi-artificial life. Software is understood as a
nonhuman actor, capable of its own agency but contingent upon its contextual relations. In
the second instance, software is presented as a way of doing by writing; “a new kind of
cultural memory” (Thrift and French 2002, 310). Code is thus able to write new
geographies, of which Thrift and French draw attention to geographies of software
production, geographies of power and geographies of play. While an important theoretical
contribution, Thrift and French overlook the very real spatial inequalities within which
software is produced and in turn reproduces.!
Stephen Graham (2005) addresses the politics of computation in the city by
introducing the concept of software-sorted geographies. A software-sorted geography is
any space that has been produced through automated analysis and regulation. Graham
focuses on three kinds of software-sorted geography: (1) urban access and mobility
controlled by automated traffic and transportation systems; (2) planning and construction
mediated through the use of geographical information and geodemographic systems; and
(3) the use of algorithmic closed circuit television systems to record, and then sort, order
and classify people and objects in the city. The concealment of decision-making processes

2

which produce such geographies leads Graham to argue that software must be
understood as thoroughly political.!
Through the introduction of the concept of code/space, Kitchin and Dodge (2011)
have endeavoured to show how software and space are mutually constituted. A code/
space is a processual tranduction of space produced to solve a specific problem – one
example they give is of the code/space produced at a bank machine when a person
attempts to obtain money. Code/spaces owe their existence to correctly functioning
software. Were the software program to crash or encounter fatal errors, the code/space
could not be formed or sustained. This intuitive idea allows them to illustrate that the
experience of everyday life in the city is determined by software (which is itself dependent
on an assemblage of contested technologies, subjectivities and embedded practices)
acting in a range of capacities and across a variety of scales.!
Taking up the theoretical work of Kitchin and Dodge (2011), Wilson (2011) argues
that data, through processes of standardisation and objectification, has both material form
and significance. Data, metadata and its storage in databases are standardised methods
of organising, storing, transporting and retrieving information. Held together by
geographically situated practices, data should then be understood as an assemblage of
different actors and institutions distinct from software: a data infrastructure (Lauriault 2012;
and, Kitchin 2014b).!
While geographies of software and more recent work on data infrastructures help
account for the mobility and secondary agency of mobile computing, these approaches
often downplay the contested materialities of computer hardware. There is, in effect, a
collapsing of the actual into the virtual (Kinsley 2014). If researchers are to properly
examine the ways in which computation is articulated through its normal use, it will be
necessary, as Gabrys has argued (2014, 39), to consider the way in which software is
interwoven with other material aspects of the computational apparatus. To this end, I will
now offer a readily graspable model of interdependent assemblages, a socio-technical
stack, for the examination of mobile computing. By placing hardware, data(bases) and
media interfaces on an equivalent ontological footing to that of software, I hope to reveal
previously unaccounted for intersections of computation and the city. I will now move on to
presenting the multilayered approach, and giving two examples of how it might be used.
These are the taxi service application, Hailo, and the personal life logging application,
Moves.!

3

The hardware—code—data(base)—interface stack!
I propose to explore mobile computing through four interlocking and hierarchically
organised components: hardware, code, data(base) and media interfaces1 (see Image 1c).
This is not asserted as a true, realist model of smart phone applications, but rather is
presented in the hope that it might serve as a useful heuristic in critical examinations of
mobile computing systems. Before applying these concepts to the apps Hailo and Moves, I
will outline its origin between media studies and science and technology studies.!
Legal scholar Yochai Benkler offers a model of the internet (see Image 1a) which is
composed of three discrete layers (2006, 391-392): physical, logical and content. The
physical layer consists of the material infrastructure which connects people together. The
content layer includes both the meaningful representations which people use to
communicate as well as the mechanisms by which people filter, accredit and interpret that
content. Finally, the logical layer connects the physical and content layers through codified
algorithms, standards and protocols of interaction. All three layers are necessary for
communication and all three layers form the locus of distinct policy debate.!
Jonathan Zittrain (2008) adapts Benkler’s model in order to explore the generative
nature of communicative computational technologies. His model (see Image 1b) is best
represented as a technological layer (which is itself composed of physical (material) and
protocol (translative) layers), an application layer, and then more tentatively asserted
content and social layers (Zittrain 2008, 67). The physical layer includes the wires or
airwaves through which data moves. Above that is the application layer which
encompasses all of the various and multifaceted work performed by people through
computation. Between these two layers is a mediating protocol layer. Zittrain likens the
protocol to the neck of an hourglass through which everything flows. As counterpoint to the
poorly developed content and social layers (which consist of the information exchanged in
a network and the embodied practices enabled by the model respectively), I propose that
the technological and the application layers might better be understood as embedded
socio-technical assemblages which are continually being produced in a citational manner
by human and non-human actors operating at diverse capacities and scales. Such a
framing repositions the protocol as open to contestation, but also acknowledges the role it
plays as a governmentality within a larger computational apparatus.!
1

By media interfaces I mean, following Manovich (2013), graphical, audial and haptic feedback mechanisms
which convey information through normal use. I do not wish to mean graphical user interfaces exclusively,
nor interfaces more broadly. For an exploration of interface theory see Galloway (2012), Farman (2012) and
de Souza e Silva and Frith (2012).
4

While the models developed by Zittrain and Benkler suitably emphasise the fixing of
mobile computing’s various components into hierarchies of technological interdependence,
their concepts fail to align with those experienced by, and co-productive of, normal use.!
social
content

media interface

content
application

data(base)

logical
protocol

physical

physical

}

code
technological
hardware

Image 1. From left to right: (a) Benkler’s model, (b) Zittrain’s model, and (c) the proposed model.

!

In her deconstruction of popular social media platforms, media and communications
scholar José Van Dijck (2013) weds science and technology studies with a critical
approach to political economy. Drawing on the aims of actor-network theory to “to map
relations between technologies and people and… to explain how these relations are both
material and semiotic” (2013, 26) Van Dijk proposes five concepts to trace the sociotechnological relations of online social networking platforms. These are: meta(data),
algorithms, protocols, interfaces and defaults. Data are the quantitative and qualitative
information used for computation and metadata the information used to order and
understand that data. An algorithm is a list of instructions a computer undertakes to
produce a certain output from a specific input. Protocols are codified behaviours and
norms of computational interaction. Interfaces, both internal and customer-facing, mediate
interaction, effectively translating the desires of the user to code and vice versa. Finally,
defaults are settings which are automatically assigned within a piece of software. This
framework is specific enough to examine the materialities and power networks of mobile
computing, and it refrains from reducing the social to an effect of the technological. In not
focusing on hardware however it effectively despatialises computational technology. While
this may allow Van Dijck to examine social media as a globalising technology, it renders
the model unsuitable for analyses where the local is significant.!
By focusing on hardware and restricting interfaces to media interfaces (see Image
1c), I am attempting to allow for the way in which the flows of code and data are in the first
instance reliant upon geographically distributed technology and in the second,
5

reterritorialised at the point of their consumption. Rather than include all of Van Dijk’s
concepts, I reposition protocol and default as governmentalities which intertwine with the
four layers of the model. It is my hope that the hardware—code—data(base)—interface
model allows for the mobility of mobile computing, but also the way in which it is
processually articulated in specific and situated ways.!
Hailo and the externalisation of fixed capital!
Hailo is the market-leading smart phone taxi app in Ireland. Launched in July 2012,
the service is currently used by around 5,000 of Dublin’s 12,000 taxi drivers. In this section
I use the proposed socio-technical stack to explore how Hailo does work in the world and
argue that its business model is dependent upon infrastructure which is external to its
operating costs.!
When using the Hailo app (Image 2), the immediate and most obvious hardware that
a person is interacting with is the piece of it in their hand. The smart phone is an instantly
recognisable artefact, at once a cohesive, singular object and an assemblage of specific
(and often rare) materials and digital components. Just as the smart phone black boxes its
workings from a user, so too does its consumable form alienate them from the labour
which contributes to its design, sourcing and production.

Image 2. From left to right: (a) Hailo tour feature (location refinement), (b) taxis nearby 12 Muckross
Parade, (c) tracking the driver in real time, and (d) automatic card payment.

!

While the compact form of the smart phone is fundamental to its mobility, the
arrangement of hardware, code and data transmission protocols recruited by Hailo far
exceed the media interface manipulated by its user.!
When a user orders a taxi using Hailo, their phone transmits data to a nearby cell
tower, which then routes this data on to the internet and on towards Hailo’s servers. If the
6

user then phones the driver to confirm their location, instead of routing data on to the
internet, the cell tower instead passes it to the fixed-line telecommunications infrastructure.
In Ireland, these networks are largely operated by Eircom, a formally state-owned
monopoly which was floated on the Irish and New York stock exchanges in 1999.
Individual carriers lease access to this infrastructure at a cost which is ostensibly passed
on to the user through fees and contracts.!
Both code and (meta)data are crucial in allowing this exchange of information to
occur.!
While the interface is the most visible layer to the users, many of the communicative
actions initiated through normal use are carried out by the architecture upon which the
application operates. For reasons of security, third party access to a smart phone’s
underlying hardware is strictly mediated by both the phone’s operating system and the
firmware running on its baseband processor. A smart phone’s functionality is controlled
through code libraries and frameworks used in the development of an application. The
Hailo application reveals itself as a cohesive whole but is in fact interwoven with the code
—hardware of the phone.!
This permeability goes further. Transmitted data is bundled-up with specific
information about that data to ensure that it is correctly received and processed by
telecommunications infrastructure. So-called metadata, found in the header of a data
packet, includes a protocol version number as well as the data’s source and its
destination. This information is of crucial importance to data transference – without it,
communication could not occur. Transmission protocols are not a form of control directed
by any one actor, but rather a commonly adopted standard. Control becomes endogenous
to the technological system itself (Galloway, 2004).!
The layered assemblages which determine Hailo are simultaneously recruited by the
application and hidden by the interface at the moment of normal use (Chun, 2004). This
network-in-the-pocket capacity of mobile computing is generative of Hailo’s business
model.!
Taxi hire companies in Dublin operate in a market of individualised licensing. In
addition to plying for hire (being in motion and available for hire) and standing for hire
(being stationary and available for hire), taxi drivers can increase their number of fares by
enrolling the services of a taxi hire company. When a customer phones a taxi hire
company, its radio-enabled network is then leveraged to source an available driver. This
model is dependent upon the installation of a communications unit in driver’s vehicle. The
hire of this is incorporated into the cost of the service – in Dublin, around €100 a week.!
7

Hailo does not need to install any of its own radio communication equipment, instead
relying upon external telecommunications infrastructure. In comparison to traditional taxi
hire companies, Hailo has low fixed capital costs and low associated installation and
maintenance costs. Where code performs the role of the radio operator, there are also
presumably fewer attendant labour costs. This leads to a considerably different pricing
model. Rather than charge a subscription fee, Hailo extracts a 12% commission – minus
VAT and card processing costs – on every fare sourced through the app. This flexibility
lowers the threshold on driver uptake and constitutes a significant threat to existing taxi
hire companies.!
There is however an important geographical caveat to be made. In cities such as
Dublin – where there is a confluence of high population density, a high number of taxis per
head and a high usage of smart phones – the benefits of Hailo to both drivers and
passengers outweigh those offered by the radio network of taxi hire companies. In a
geographical location where taxi or smart phone use is more sparsely distributed, Hailo
has less opportunity to draw upon existing infrastructure. Where I work in Maynooth – a
small university town 25 kilometres west of Dublin – it is very difficult to find a taxi using
Hailo. In such locations both spatial scarcity and community loyalty lead to less
competition between Hailo and existing taxi hire services. In these instances, the volume
of jobs rather than rate of commission is the dictating competitive factor.!
On the whole, it is the geographically dispersed hardware external to Hailo which
allow it to compete favourably with existing taxi services. The ability to leverage an already
existing general purpose hardware—code stack, rather than design, implement and install
a bespoke infrastructural architecture, allows smart phone applications to grow quickly and
flexibly. This mechanism underlies many of the disruptive economics of apps, and poses a
challenge to the necessarily slow moving regulatory frameworks at both local and national
scales.!
Moves and automatic value extraction!
Moves was launched on the Apple App Store in January 2013 by Finish developer
ProtoGeo Oy. The app is a kind life logger which collects personal information for the
analysis of physical exercise and daily activities. Rather than depend upon a device worn
on the user’s wrist (as in other commercial solutions such as Nike’s FuelBand or Sony’s
SmartBand), Moves runs in the background during everyday smart phone use, collecting
information available to it from the phone’s hardware (the GPS receiver, the GSM and wi-fi
modules, and the accelerometer) to determine how a user moves in and through space.
8

This information is then represented in a visually accessible way. In this section I draw on
the hardware—code—data(base)—interface model to emphasise the importance of the
graphical user interface to the familiarity of the application and then the extensibility of its
data to its longevity. I argue that its acquisition by Facebook for an undisclosed sum in
April 2014 was predicated upon the perceived value of this granular user information.!
There are essentially two modes to Moves’ user interface. The first shows periods of
low or no movement as oval nodes and periods of movement between them as
multicoloured lines (see Image 3a). Nodes are initially represented by the app as a small
map; a spatial region. These can be designated as a place by the user (using
Foursquare’s open database of user generated locations) and will subsequently be shown
using an icon intended to symbolise that place’s associated activity. The colours of
connecting lines represent the activity estimated to have been undertaken between
locations: green showing walking; pink, running; grey, some other form of transportation.
While surely unintentional, this linear conceptualisation of movement through time is for
me, evocative of the work of geographer Torsten Hägerstrand. By touching on any node or
line, the user enters the second interface mode (see Image 3b & 3c). Here, temporal
representation is sacrificed to a clear representation of spatial information by way of a
map. In this mode moving through time is achieved with the arrow buttons at the bottom of
the screen. Moves’ modal interface is simple to use and intuitive to a regular smart phone
user. There is an important sense then in which the cultural capacity of interfaces exceed
specific applications.!

9

Image 3. Clockwise: (a) Moves interface mode: temporal representation, (b) & (c) Moves interface mode:
spatial representation, (d) third party services built using the Moves API.

!

Visual and gestural cues accrete into norms of interactive behaviour. These are builton by daily use with an application. Consider one of the most persistent visual devices
drawn upon by Moves: the map. Maps are produced in-the-moment for a specific purpose;
brought into being through their reading (Kitchin and Dodge 2007). In the mobile
10

computing map, there is a tension between the general and the specific. On the one hand
the map is a visual representation produced by the Moves code, which in turn – in my use
of the application on an iPhone – draws on iOS's Map Kit Framework. This architecture
allows maps to be easily embedded within iOS applications and facilitates the translation
of pinching and panning gestures between mobile applications and across Apple devices.
On the other hand the map is specifically produced by the code—data—interface stack for
an individual user. Prior to its visualisation on the screen, the information collected by
Moves must be processed and reformatted. Data gathered about location (from the GPS
receiver) and movement (from the accelerometer) are sent to Moves’ servers where the
various activities undertaken during a specific time are calculated. This is rearranged to a
data format (a JSON array) which can act as input to the app’s code—interface, and then
sent back to the phone. Moves’ map interface is both general in the conventions of its use
and specific in the data which it renders on the screen. The visual device of the map
enacts a form of knowledge which moves through space and time, between users and
across devices, but is sufficiently mutable to accommodate their particular needs.!
While Moves draws upon an aesthetic of visual interface design, it refuses to lock the
user into its particular media interface. The data collected by the application has been
made potentially accessible and manipulable through an application programming
interface (API), such that Moves itself offers its own architecture for third-party software
(Image 3d shows some of the services using data collected by Moves). By way of
example, MMapper is a Processing sketch offering simple filters for visualisations of
Moves data (see Image 4a), and Move-O-Scope is a web application allowing the data to
be collated and compared across longer periods of time (see Image 4b). These
applications leverage different hardware—code stacks and represent data to the user
through a graphical interfaces which have different properties to the Moves app. The
capacity of the data to be open and fluid re-inscribes Moves as a platform for life logging
more generally, but begs the question: what is it about data in this instance that is of value
over and above the other components of the mobile computing stack?!

11

Image 4. From left to right: (a) MMapper Processing sketch, (b) Move-O-Scope web application.

!

Drawing on Marx’s notion of the formal and real subsumption of labour to the
capitalist economy (1976), Hardt and Negri (2000) describe processes by which life is itself
subsumed to the capitalist social factory. Life logging can be understood as one such
process of subsumption: the automatic capture of data being the formal subsumption of
life, the ordering of our lives to its representations its real subsumption. Crucial to this is an
interpretation of data as, in the first instance, representational of life and in the second,
materiality in itself which becomes real through a performative response to its analysis.
Data in effect become ordering agents of life. While such a framing begins to draw out
some of the political ramifications of life logging, we still have not properly addressed the
question of value.!
Following Federici’s (2004) insight that capital must reproduce itself through the
ongoing accumulation of previously unexploited domains, the subsumption of life becomes
a crucial front for the expansion of capitalism. Capitalists compete to collect data – to
accumulate life. As such the acquisition of Moves by Facebook represents an effort not
only to obtain a platform for the automatic extraction of value, but also to perpetuate its
growth through the enclosure of the body. Understood through its value, data become a
deeply political issue closely entwined with the perpetual unfolding of contemporary
capitalism.!

Politics beyond software assemblages!
Within media and communications studies (such as in Galloway 2004, and Van Dijck
2013), geographies of software (Thrift and French 2002, Graham 2005, and Kitchin and
12

Dodge 2011), and in the emerging area of software studies (Fuller 2011, and Manovich
2013), software, what I have been treating here as an assemblage of code and media
interface, is often given ontological precedence over hardware and data. This is for two
reasons. Firstly, the decentralised execution of algorithms and protocols affords digital
computation much of its agentive capacity. Secondly, code itself does work as a new kind
of commodity entangled with, and co-productive of, the forces of globalisation. Increasingly
to understand global capital, labour markets, production and everyday economic practices
it is crucial that researchers have a solid grasp of software. While it is not my intention to
deny the need for such engagement, I feel that it is important to acknowledge that the
flows of software are predicated upon networked hardware and data infrastructures. To
give ontological priority to software de-emphasises this stack of interdependence and the
politics by which it is given context.!
By considering the significance of hardware, the spatial is reintroduced and with it the
local materialities with which software interacts. Hailo shows why this is crucial to an
understanding of mobile computing. Hardware is fixed capital where software is fluid.
Where network infrastructure permeates the city, external to but spatially co-located with
everyday life, potentially disruptive business models can emerge and with them a suite of
situated legal and regulatory issues.!
By considering the significance of data as a dynamic running transverse to software,
the politics of computation can be freshly conceptualised. Moves is a good example of how
data can exceed the software configurations in which it is represented. Data are more than
just a representation of reality however. Data can also become life to those who analyse it
and value to those seeking to acquire it. Just as software is significant to an understanding
of the fluxes and flows of globalisation, so too are data.!
As a methodological tool, the multilayered hardware—code—data(base)—interface
model is able to express these political and economic entanglements in a way that
research prioritising software is not always able to. It is only through proper examination of
the ways in which these various assemblages are hierarchically arranged that we might
properly appreciate how computation and the city are mutually constituted (Kitchin and
Lauriault 2014, Kitchin 2014a).!
In this examination of mobile computing I have drawn loosely on theorisations of
actor-networks and assemblages without trying to fit the proposed model within a
theoretically fleshed-out ontology. In the space that remains in this chapter I want to briefly
touch on what an engagement with these literatures might offer the proposed model.!
13

The target of Bruno Latour’s actor-network theory is no less than the social itself – or,
at the very least, the way in which sociality and social bonds are fetishised for their
explanatory power within Durkheimian analyses (Latour, 2005). Rather than understand
phenomena through these top-down forces, Latour urges the social scientist to slowly
follow the connections between human and non-human actors, “redefining sociology not
as the ‘science of the social’, but as the tracing of associations” (Latour 2005, 5). By
providing a rich, descriptive exploration of the ways in which local phenomena assemble,
the social might begin to be rebuilt from the bottom-up, taking proper account of the
agency of things. In his determination to reboot the project of social enquiry I worry that
Latour leaves too little room for the systemic political and economic forces which I have
drawn on in relation to Hailo and Moves.!
By contrast, Foucault (1980) uses the idea of the dispositif, or apparatus, to draw
attention to the complex arrangement of discourses and institutions which enable the
formation and maintenance of knowledge in service to a strategic political function. Here
the social solidifies into expressions of power/knowledge which are in the first instance
political. Similarly, Deleuze and Guattari (1987) employ the notion of the assemblage in an
effort to open up new forms of political engagement (Tampio 2009). Of importance in their
use of the concept is externality – “relations are external to their terms” (Deleuze and
Parnet 1977, 41) – by which they mean that any actor in an assemblage has the potential
to exceed that particular arrangement of its relations. This is in keeping with my
exploration of Hailo and Moves where hardware and data do considerable work beyond
their configuration within the mobile application assemblage under review.!
McFarlane (2011) and Anderson et al (2012) have respectively explored what
assemblage theory might mean for urban theory and social-spatial theory more broadly.
Through an engagement with the materialist and realist philosophy of Manuel DeLanda
(2006), they propose four areas which might be fruitful for geography: an experimental
realism; an emphasis on relations within and beyond assemblages; a rethinking of agency
and causality in distributed terms; and, an awareness of shifting capacities as
assemblages mutate and stabilise. These have informed my approach even in my
reluctance to assert the realism of the hardware—code—data(base)—interface stack.!
While these approaches have their various strengths and weaknesses, there seems
to remain an issue of ontological disconnect between empirical tracings of socio-technical
systems on the one hand, and the political and economic forces at play in the city on the
other. Perhaps, as Kitchin suggests, there is an opportunity “to scale the socio-technical
perspective up, and drill the urban studies focus down so that they overlap in view and
14

epistemology” (2014a). As a geographer thinking about the relationship between code and
the city, my interest is in placing urban research in dialogue with philosophy. While I have
presented some literature to this effect, I remain cognisant of the need to further develop
the ontological frame of this methodological approach.!

Conclusion!
In this chapter I have explored the mobile applications Hailo and Moves through the
proposed socio-technical stack: hardware—code—data(base)—interface. This
multilayered model is able to account for the way which networked devices move through
space and for nonhuman as well as human agency, without reifying one concept at the
expense of the others. While I have argued for a flattening of the ontological relationship
between software and its supporting infrastructures, I have tried to remain aware of two
tensions which undermine such an approach. Firstly, that mobile computing is stabilised in
hierarchical relationships, such that the capacity for each layer to access the one below it
is tightly controlled. And secondly, that each of these layers is itself transduced in a
citational and performative manner by human and non-human actors. These layers are
hidden at the moment of their recruitment – obscured by the cohesiveness of a seamless,
well-engineered user experience – but they inform the economics and politics of everyday
smart phone use in the city, and so deserve proper critical attention. 

15

References!
Anderson, B., Kearnes, M., McFarlane, C., & Swanton, D. (2012). On assemblages and
geography. Dialogues in Human Geography, 2(2), 171–189.!
Benkler, Y. (2006). The Wealth of Networks: How Social Production Transforms Markets
and Freedom. New Haven and London: Yale University Press.!
Chun, W. H. K. (2004). On Software, or the Persistence of Visual Knowledge. Grey Room,
18(Winter), 26–51.!
De Souza e Silva, A., & Frith, J. (2012). Mobile Interfaces in Public Spaces: Locational
Privacy, Control and Urban Sociability. New York and London: Routledge.!
DeLanda, M. (2006). A New Philosophy of Society: Assemblage Theory and Social
Complexity. London: Continuum.!
Deleuze, G., & Guattari, F. (1987). A Thousand Plateaus: Capitalism and Schizophrenia.
(B. Massumi, Trans.). London: Continuum.!
Deleuze, G., & Parnet, C. (1977). Dialogues. New York: Columbia University Press.!
Farman, J. (2012). Mobile Interface Theory: Embodied Space and Locative Media. New
York and London: Routledge.!
Federici, S. (2004). Caliban and the Witch: Women, the body and primitive accumulation.
Brooklyn: Autonomedia.!
Foucault, M. (1980). The Confession of the Flesh. In C. Gordon (Ed.), Power/Knowledge:
Selected Interviews and Other Writings 1972-1977. New York: Pantheon Books. pp.
194–228.!
Fuller, M. (Ed.). (2008). Software Studies, A Lexicon. Cambridge and London: The MIT
Press.!
Gabrys, J. (2014). Programming environments: Environmentality and citizen sensing in the
smart city. Environment and Planning D: Society and Space, 32, 30–48.!
Galloway, A. R. (2004). Protocol: How control exists after decentralization. Cambridge and
London: The MIT Press.!
Galloway, A. R. (2012). The Interface Effect. Cambridge: Polity.!
Graham, S. (2005). Software-sorted geographies. Progress in Human Geography, 29(5),
562–580.!
Graham, S., & Marvin, S. (2001). Splintering Urbanism: Networked Infrastructures,
Technological Mobilities and the Urban Condition. London: Routledge.!
Hardt, M., & Negri, A. (2000). Empire. Cambridge and London: Harvard University Press.!
Kinsley, S. (2014). The matter of “virtual” geographies. Progress in Human Geography,
38(3), 364–383.!
Kitchin, R. (2014a). Code and the City: Reframing the conceptual terrain. This volume.!
Kitchin, R. (2014b). The Data Revolution: Big Data, Open Data, Data Infrastructures and
Their Consequences. London: Sage Publications.!
Kitchin, R., & Dodge, M. (2007). Rethinking maps. Progress in Human Geography, 31(3),
331–344.!
Kitchin, R., & Dodge, M. (2011). Code/Space: Software and everyday life. Cambridge, MA:
The MIT Press.!
16

Kitchin, R., & Lauriault, T. P. (2014). Towards critical data studies: Charting and unpacking
data assemblages and their work. The Programmable City Working Paper, No. 2.
Maynooth: National University of Ireland, Maynooth.!
Latour, B. (2005). Reassembling the Social: An Introduction to Actor-Network-Theory.
Oxford: Oxford University Press.!
Lauriault, T. P. (2012). Data, Infrastructures and Geographical Imaginations: Mapping Data
Access Discourses in Canada. Unpublished Doctoral Thesis, Carleton University,
Ottawa, Canada.!
Manovich, L. (2013). Software Takes Command. New York and London: Bloomsbury.!
Marx, K. (1976). Results of the Immediate Process of Production. In B. Fowkes (Trans.),
Capital: Volume 1: A Critique of Political Economy. London: Penguin Books.!
McFarlane, C. (2011). Assemblage and critical urbanism. City, 15(2), 204–224.!
Tampio, N. (2009). Assemblages and the Multitude: Deleuze, Hardt, Negri, and the
Postmodern Left. European Journal of Political Theory, 8(3), 383–400.!
Thrift, N., & French, S. (2002). The automatic production of space. Transactions of the
Institute of British Geographers, 27(3), 309–335.!
Van Dijck, J. (2013). The Culture of Connectivity: A Critical History of Social Media. Oxford:
Oxford University Press.!
Wilson, M. W. (2011). Data matter(s): legitimacy, coding, and qualifications-of-life.
Environment and Planning D: Society and Space, 29(5), 857–872.!
Zittrain, J. (2008). The Future of the Internet: And How to Stop It. New Haven and London:
Yale University Press.

17

Digital Urbanism in Crises

Work in

Progress

A hopeful monster?
Monika Buscher, Michael Liegl and Katrina Petersen
Mobilities.Lab, Centre for Mobilities Research, Department of Sociology,
Lancaster University, UK
Email: m.buscher@lancaster.ac.uk; m.liegl@lancaster.ac.uk;

k.petersen@lancaster.ac.uk
Keywords: disaster mobilitites, relational ethics, posthuman sociality

Introduction
The 21st Century has been called the ‘century of disasters’ (eScience, 2012).
Population growth, urbanization, ageing infrastructures, and public service
cuts create greater vulnerabilities at a time when extreme weather events
and political conflicts are increasing in frequency and severity. At the same
time, software has become ‘everyware’, embedded in devices, public and
private code/spaces, ‘smart cities’, movement and stillness (Greenfield, 2006;
Kitchin & Dodge, 2011). With 6.8 billion mobile subscribers worldwide and
double-digit growth (Vinck, 2013), people have become generators of Big
data, documenting their lives in intimate detail. Many of the technologies and
practices involved have become an integral part of a new digital urbanism,
and nowhere is this more visible than in crises. Mumbai, Port au Prince, Tokyo,
Oslo, New York, Boston, Tacloban, Gaza are recent sites of crisis where
individuals and communities, emergency agencies, the media and
governments have used digital technologies to connect locally and globally,
to seek information, provide reports, images and stories, exchange
information, organize and coordinate collaboration. These practices and
appropriations of collaborative technologies could be part of a ‘hopeful
monster’ (Richards, 1994) – a socio-technical assemblage that performs a
jump in the ‘evolution’ of posthuman phenomenology, community, ethics
and governance. They challenge traditional trajectories of crisis
management, hybridize the social and the technical, and reveal that ‘we have
never been [just] human’ (Haraway, 2008; Hayles, 1999) nor singular (Nancy,
2000) in new ways. In this paper we explore emergent practices of relational
ethics and posthuman sociality in digital crisis response.

Why Crisis?
Crises are a perspicuous setting for the study of disruptive innovation in
digital urbanism (Chesbrough, 2003). Digital urbanists, who inhabit the city
‘as a shared nervous system’, learning ‘to modulate bodily gestures with
1

environmental spaces, to control nearness and remoteness at once, both as
individual passengers of the city and as social groups in emergence’ (Bratton,
2008), encounter crises with creativity. Necessity becomes ‘the mother of
invention’ as new skills come together in new ways and people re-appropriate
technologies to deal with the uncertainties and strains of disasters. Port au
Prince, for example, was the birthplace of ‘digital humanitarianism’ (Meier,
2012). But the terrorist attacks in Mumbai (Oh et al 2010), the online
witchhunt after the Boston bombings (Starbird et al, 2014; Tapia et al 2014),
and the NSA surveillance scandal (Harding, 2014) show that there are many
different kinds of digital urbanists, operating at different levels, with
conflicting intentions. Crises allow observations of emerging forms of digital
urbanism and pan-urbanism, reaching from studies of organized crime (304th
OSINT Team, 2008), to analyses of securitization and militarization of urban
living and implications for citizens and non-citizens (e.g. illegals, tourists,
migrants) (Aradau & Munster, 2011; Graham, 2008), to research on collective
intelligence and virtual operations support teams in disaster response
(Buscher et al 2014; Hughes et al 2008; St. Denis et al 2012). Crises reveal
technological accentuations of social inequalities and are a perspicuous site
for the study of dispositifs of power(lessness) in the face of disaster. Further,
crises are simultaneiously exceptional while emerging from the everyday.
They engender (a culture of) fear (Furedi, 2006), and demands for
unprecedented use of digital technologies. This can disclose the sometimes
fearsome capabilities of IT, the ideologies that underpin their mobilization as
well as unintended consequences of their integration into the very fabric of
urban living. The use of cloud computing to connect local authority,
commercial and government information systems in the aftermath of the
2011 triple disaster in Japan, for example, has sparked widespread concerns
over privacy (Katsumi, 2013), fears echoed around smart city integration with
crisis management systems in Rio de Janeiro (Naphade et al 2011) and the
use of drones in fighting wildfires in California (Back Country Voices, 2013;
Halverstadt, 2014).
The epistemologically generative momentum of research on disaster
mobilities and digital urbanism resonates with critiques of smart city and big
data innovation, where an uncritical belief in data as evidential fuel for realtime control is shown to override a need to understand cities as complex
lifeworlds. Treating data in this way fosters technocratically ‘solutionist’ and
neoliberal approaches to policy, lock-in to commercial platforms, vulnerability
to urban operating system failures, and panoptic surveillance (Greenfield,
2013; Kitchin, 2013). However, crises also suggest that digital urbanisms
might be ‘hopeful monsters’, experiments with relational posthuman
phenomenology, sociality, ethics and governance. Such experiments disclose
problematic and positive dimensions, and a focus on relational and
posthuman aspects of emergent practices and affordances can make a useful
contribution to more circumspect analysis and enactment of digital urbanism,
everyware, code/space, smart city, big data and the intersecting mobilities
they entail.
In the next section, we provide an account of the use of digital technologies
in the local and international response to the Haiti earthquake in 2010. This is
necessarily abridged, but draws on semi-auto-ethnographic reports by digital

2

volunteers, scholarly empirical research as well as media reports. Analysis of
this concrete case shows that while technocratic and panoptic metaphors
abound and indeed shape innovation, we can also observe different,
complexly hybrid, embodied, emplaced, and mobilized actors, modes of
sociality and ethics (Whatmore, 1997).

Haiti: Mobilising IT for Crisis Response
With the Haiti earthquake two important things changed in disaster response:
self-organised mass-reporting with digital media took place in unprecedented
numbers and at the same time ‘online communication enabled a kind of
[global] collective intelligence to emerge’. Thousands of volunteers from all
over the world:
aggregated, analyzed, and mapped the flow of messages coming from Haiti. Using Internet
collaboration tools and modern practices, they wrote software, processed satellite imagery,
built maps, and translated reports between the three languages of the operation [...]’
(OCHA, 2013)
Volunteers coordinated some of these efforts via formalised crowdsourcing
tools, including OpenStreetMap and Ushahidi, an open source data
processing, mapping, and visualization platform (Okolloh, 2009). Shortly after
the Haiti earthquake on 12 th January 2010, a group of ‘digital humanitarians’
decided to deploy these tools for the disaster, and 40,000 to 60,000 reports
were processed, including many from globally dispersed members of the
Haitian diaspora as well as many spontaneous volunteers in the Ushahidi
Haiti Project (UHP) (Figure 1) (Meier, 2012, 2013; Morrow et al 2011). Their
work provided invaluable support to a number of in-the-field organisations,
including the US Marines and the United Nations Disaster Assessment Search
and Rescue teams (Morrow et al 2011).

3

Figure 1 Ushahidi Haiti Project (UHP) Map (Source:
http://newswatch.nationalgeographic.com/2012/07/02/crisis-mapping-haiti/)

The UHP map supported the task of deploying resources to people in need.
Morrow et al describe how the Department of State Analysts for the US
government interagency task force and US marines used UHP information to
enhance situation awareness and identify ‘centers of gravity’ for the
deployment of field teams. Innovations like Project Epic’s ‘Tweak the Tweet’
(TtT, Starbird & Palen, 2011), a standard which employs a uniform format for
reports through hashtagging needs, locations and contact details, promoted a
shared ‘grammar’ that facilitated computational parsing and mapping of
tweeted information. Starbird & Palen observe how volunteer translators or
‘voluntweeters’ translated reports from different sources, such as text
messages or tweets, using the TtT syntax in response to the Haiti crisis, and
worked as ‘remote operators’ to facilitate assistance, resource coordination
and collaboration from a distance. Amongst other things, they promoted the
international transfer of small funds via Paypal to many Haitians’ pay-as-yougo mobile phones, and even coordinated the provision of trucks to specific
locations and local volunteers, with messages sent back and forth, including
confirmation of resolution of resource coordination challenges.

Ambiguous
Opportunities

Outcomes:

Challenges,

Questions,

In this first large scale mobilization of digital disaster response volunteers, a
‘crowd’ of distributed individuals were able to map affected areas and provide
a baseline for translating and mapping needs. A lesson from this effort was

4

however, that there are challenges, especially for collaboration between
digital volunteers and official responder agencies. Once the official response
got under way, the traditional agencies more or less took over, which led to
some alienation on the volunteers’ side. Conflicts arose in relation to a series
of questions. We derived the list below from lessons-learnt reports formulated
from different perspectives, including the crisismappers, the formal response
agencies, and policy agencies involved in shaping social media use for crisis
response, such as FEMA, the UN and the Woodrow Wilson Centre, as well as
other academic analyses:













How can official response agencies like FEMA change the way they
communicate to fit the way the people affected communicate? (Fugate,
2011)
How can organisations like UN OCHA systematically integrate
evidence-based data and social media contributions? (Bhattacharjee &
Lossio, 2011)
How can volunteer services, such as the UHP, ensure the accuracy and
reliability of the information they provide? (Morrow et al., 2011)
Is the assumption of ‘implied consent’ a sufficiently sound basis for
processing personal data from contributors in a crisis? (Meier, 2012)
What happens to information and protocols of responding as they
change hands from crisis mappers to formal responders? (Starbird &
Palen, 2011)
What are legal responsibilities and how can those participating as
volunteers as well as formally responsible parties ensure that legal
responsibilities in relation to the information can be and are met?
(Shanley et al 2013)
Who analyses needs and determines what is to be addressed (first)?
Whose responsibility is it to address the needs that are made visible
and mapped? Is there sufficient capacity? On what basis are they
prioritized?
How does greater visibility affect expectations – for aid, inclusion in the
response efforts, and long term recovery and preventative planning –
amongst affected populations, local and global publics and the media?
What counts as damaged and in need of (urgent) rebuilding?
What does relying on technology to produce and map situation reports
do to those affected but not connected?

While on the one hand making more of the affected people and places and
their needs visible is a pathway to more efficient, effective, and inclusive
disaster response, on the other, locating and making more needs visible may
seriously exceed the capacity of formal response organizations, interfere with
traditional, ethically proofed systematic search and rescue procedures, and
make self-help a necessity. It can also open up more long term and political
questions regarding the resourcing and organization of crisis management
and emergency response.
Moreover, the geographic and economic background of digital volunteers and
international relief actors raises challenges. Many are from the global (urban)
North, physically or virtually transported to incidents in developing countries

5

of the South. In her analysis of the aftermath of the Haiti earthquake, Mimi
Sheller shows that disaster response logistics amplified North/South
inequalities through measures ‘in which the outsider has the power to move,
to bring in supplies, to access information, or to come and go at will, while
the local victim experiences ... decreasing access to mobility, and high levels
of random and turbulent serial displacement’ (Sheller, 2013:6). She describes
the physical and digital influx of highly mobile international responders with
their ability to conduct aerial surveys of damage as well as GPS-enabled
satellite data collection systems that coincided with a local population which
at large had neither the means nor the right to move outside the danger
zone. Information about people was free to move, but people were not. Part
of this unequal mobility manifested in the ability of foreigners such as the
World Bank, but also crisis mappers, to use aerial images and satellite data to
assess the damage and ultimately (help) decide what needed addressing
(first). They based this on ‘an aerial view that few Haitians had due to lack of
internet access and (because they usually are not in a position to fly) will ever
have of their own city’, translating ‘visual power through the aerial gaze’ into
material socio-economic and political decisions on the ground (p.11).
Informational mobilities are not innocent (p.15).
But connecting affected local populations more richly with digital volunteers
and the other agencies involved in disaster response also provides
opportunity to counteract the perpetuation of neo-colonial unequal
(im)mobility regimes and exploitation (with extremes documented in Naomi
Klein’s analysis of ‘disaster capitalism’ (2008). Integrating local communities
could not only make emergency response literally more informed, since locals
possess knowledge, skills and resourced necessary for sensibly interpreting
information, such as aerial images of damage, it could also make the
response fairer and more democratic, and help the response focus on local
issues of concern rather than standard practices (Henderson, 2011).
Integration between public and official informational and communicative
flows will be easier where affected local communities and digital volunteers
have access to compatible technologies, adequate economic means and
rights, as well as to each other, and addressing poverty, access to forums
where decisions are made and technology are necessary to address as part of
disaster management. Clearly the perceived responsibilities of digital
volunteers and many digital humanitarian organizations currently stop short
of addressing such questions head on. Four years after the earthquake, the
United Nations found that 817,000 Haitians still needed humanitarian
assistance (Oxfam, 2014), yet most digital humanitarians have moved on to
the next crisis. following media trends that always chase the new and
immediate rather than the long term. Action among these distributed groups,
it seems, is mobilized when effects are most visible, moving on when the
impacts of their work are less visible (Moeller, 2006; Sachsman, 1996). This
prompts some analysts to criticize activities like digital humanitarianism as
‘clicktivism’ (c.f. Raftree, 2010), a politics of pity (Boltanski, 1999; Sontag,
2002) or even ‘communicative capitalism’, more concerned with the
circulation of messages than with listening and entering into genuine
cooperation (Dean, 2005).

6

In the same four years since the Haiti disaster, the Network Centric
Operations Industries Consortium (NCOIC) leveraged $ 1.2 million of
industrial funding to develop cloud-based interoperability between
information systems to support international, especially US/NATO capability of
mobilizing and visualizing data from a disaster site. A demonstration of the
results organized in collaboration with the National Geospatial-Intelligence
Agency replayed the Haiti response with cloud computing and prided itself to
have speeded up the processes of disaster response and ‘development of a
federated cloud system [to a degree that] can be measured in hours instead
of months’. This apparent efficiency gain is said to simultaneously reduce the
cost of IT for emergency agencies by between 10-80% (much of it due to the
fact that IT services can be hired on a temporary basis rather than requiring
permanent investment) (NCOIC Rapid Response, 2013). Many of the
demonstration scenarios re-enact an aerial perspective of asymmetric power
(Figure 2).

Figure 2 NCOIC Haiti Demonstration Source: http://www.ncoic.org/aboutus/interoperability-projects/nga-demonstration/nga-demonstration-videos Video 6

The systems uncritically presume the possibility of an objective common
operational picture composed of information ‘extracted’ from the ground,
inscribe a hierarchical mode of command and control – led by international
responders, and assume a technocratic stance where information and
interoperability between information systems are seen as pivotal for
successful coordination. Yet, they also describe how through the parametric
data approaches (Parisi, 2012) the whole can become greater than the sum of
its parts and enhance the ability to have sustained dialog and interactions
between diverse actors (NCOIC, 2013). Indeed, all the examples we discuss
above have such ambiguities and we now conclude with a brief review of
more hopeful aspects that can also be observed in the above examples, often
operating quietly alongside the more dominant panoptic, technocratic and
cognitivist paradigm.

7

Relational Ethics & Posthuman Sociality in
Crises
In his reflections on the emergence of digital humanitarianism during the first
two months after the Haiti earthquake, one of the pioneers in the field states:
To map the world, is to know it. To map the world live is to
change it before it’s too late. (Patrick Meier, 2012)
This way of thinking about information and maps, as well as concepts of
surveillance, sousveillance, and veillance (Ali & Mann, 2013) and the concept
of common operational pictures, assume predominantly individual sequential
processes of perception and reasoning, where visibility enables diagnosis and
makes information ‘actionable’. It assumes that more and live evidence can
place crisis situations (perhaps the whole planet?) on the operating table in a
way that large, distributed collectives can ‘operate’ on its problems in a
manner superior to individual nations’ or traditional international multiagency response. However to map the world is also a political process that
makes worlds (Carroll, 2006; Monmonier, 1996, 1997; Wood & Fels, 2008).
Map-making is performative, it standardizes and codifies social rules and
practices, reflecting and reinforcing unequal power relations, claims to
authority and rights (Harley, 1989, 2001). Moreover, seeing data and maps as
a route to objective knowledge that overrides subjective experience, values
and judgements, does not acknowledge the diversity of constructions of
objectivity over time and place (Daston & Galison, 2007). To overcome some
of these shortfalls, we propose four concepts that consider more carefully the
actual lived production of knowledge about an emergent reality, a reality that
is enacted in and through practices of knowing, which reflect the relational
and posthuman aspects of the activities involved in the digital urbanisms of
the Haiti response.
Corporeality and materiality – Using IT does not remove the corporeal or
the material from the information being shared. In her critique of ideas of the
autonomous self in traditional ethical discourses and her tracing of the
contours of a relational ethics, Whatmore (1997) identifies re-specifications of
embodiment in feminist theory and environmentalist thinking as highly
productive. Translated to the context of digital urbanism in crisis, the idea of
materially situated and embodied actors embedded in hybrid networks and
dynamically constituted in and through specific practices and discourses
sensitizes analysts to the complexities of social and material practices of
responding to crises. The information is never completely isolatable from
these actors, even as it moves. The idea of the cyborg (Haraway, 1990)
highlights how crises strip some humans of the technical and non-human
elements that allow them to be human, while others can ‘strap into’ a vast
technological apparatus to assist (and/or dominate, exploit). Further,
concepts of embodiment, cyborg hybridity and materiality emphasize how big
data is produced in and through embodied action, and is itself material, while
current IT design philosophies make this virtually imperceptible. Treating data
as though it merely floats above all bodies and space removes from it the
need to ask the important questions of ‘why it exists’ rather than simply just

8

‘what exists’. IT could be otherwise, and a focus on corporeality and
materiality as a feature of a relational ethics suggests that probably it should.
Addressability – The convergence of Cartesian calculation and mobile
technology has resulted in a reconfiguration of how humans can be
addressed. There are two dimensions to this. On the one hand digital
surveillance and search and rescue tools allow persons to pinpoint, track,
trace and interrogate others without their noticing. These innovations can be
understood as an extension to the human sensorium and ‘a new
“technological unconscious” whose content is the bending of bodies-withenvironments to a specific set of addresses … a pre-personal substrate of
guaranteed correlations’ (Thrift, 2004). There are multiple ways in which this
dimension of addressability manifested during the Haiti response: 1) for
responders and digital volunteers how to give an address (geo-code) to
persons and information was a key issue; 2) questions over whether
information accurately addressed damage and supported action that, in turn,
could address the damage were important; and 3) there are question of how
adequately specific modes of data processing and visualization address or fit
with the information practices of those in need. From this perspective, an
individual’s uses of technology, is thereby implicated in the larger society’s
ability to respond and even see the damage at hand. On the other hand,
addressability opens up opportunities for dialog. In Haiti it sometimes was
reciprocal. The negotiation and confirmation of trucks coordinated via social
media is one example, the alienation of digital humanitarians in relation to
the official response another (Starbird & Palen, 2011). Such bi-directional
addressability facilitated through social media and the immediacy of local
evidence documentation - supported, mapped and amplified by a globally
distributed crowd - opens up opportunities for a more agonistic form of
democracy (Jasanoff and Di Salvo, quoted in Storni, 2013) and resistance to
visual power through an aerial gaze. Digital crisis response should pay
attention to what it means to both pinpoint a person and dialogue with that
person, not just collect data about that person.
Co-mobility – Jen Southern’s concept of a new sense of comobility, of being
mobile with others at a distance vicariously and by being tenuously
connected (e.g. through GPS or twitter) broadens Haraway’s cyborg notion in
a very useful way (Southern, 2012). It moves the idea of a cyborg beyond
individual bio-medical or technological extensions towards conceptualising
new senses, practices, discourses and ethics of posthuman sociality. She
shows that ‘views from above’ are ‘embodied and necessarily partial views
(incomplete and open) rather than views from everywhere or nowhere’
(Southern, 2013). She also reveals that contrary to assumption, a view from
above depends on a view from on the ground, citing a passage from a flight
report by St. Exupery, where he describes how knowledge of a little stream
cutting across a field that otherwise looked safe to land on saved his life. Had
he attempted to land, the plane’s wheel’s would have caught and overturned
the aircraft. Thus comobility of aerial and ground perspectives can be a
powerful component of knowledge.. The convergent mobilities in the
production of the Haiti OpenStreetMap of Port Au Prince and the UHP provide
a glimpse of this (Meier, 2012).

9

Command and control – the Haiti example highlights that there are two
aspects to practices of command and control (Harrald, 2006). One dimension
entails hierarchical, structured and planned modes of cooperation, which in
traditional conceptions often assume a sequential epistemic trajectory from
perception to data to diagnosis to action, where communication is seen as a
matter of transmission, and control as a matter of expressing orders, with the
recipients of these orders merely executing an action and following rules. The
other aspect of command and control entails complex multi-channels
sociality, perception and perceptiveness, as well as dynamic configuring of
awareness (Heath et al 2002) and improvisation. It is more akin to the way a
troupe of streetdancers has command over their bodies, their shared
choreography, and the environment; it involves rich, relevant communication
in situ. These two forms of command and control are not mutually exclusive,
indeed, they are interdependent. They are like plans and situated action
(Suchman, 2007). However, the second form of command and control is often
denied. Our analysis begins to make it more visible and draw out the
posthuman aspects to its performance. For example, the work required to
make UHP information actionable during the response to the Haiti disaster
was often complex. To geolocate messages in Creole, local knowledge was
often needed, requiring a search for capable translators, it could involve
finding intersections that were perhaps not yet mapped, and to transfer
information between different technologies often required an intricate dance
to align many human and non-human actors' moves onto the same page.

Acknowledgements
The work presented in this paper is supported by the BRIDGE Project
http://www.bridgeproject.eu/en,
the
SecInCoRe
project
and
the
Catalyst
project
http://www.secincore.eu,
http://www.catalystproject.org.uk. We would also like to thank Vanessa
Thomas, Sarah Becklake and Catherine Easton for comments.

References
304th BI OSINT Team. (2008). Sample Overview: Al Qaida-Like Mobile
Discussions & Potential Creative Uses. Retrieved August 13, 2014, from
http://fas.org/irp/eprint/mobile.pdf
Ali, M. A., & Mann, S. (2013). The inevitability of the transition from a
surveillance-society to a veillance-society: Moral and economic grounding
for sousveillance. In 2013 IEEE International Symposium on Technology
and Society (ISTAS): Social Implications of Wearable Computing and
Augmediated Reality in Everyday Life (pp. 243–254). IEEE.
Aradau, C., & Munster, R. Van. (2011). Politics of Catastrophe: Genealogies of
the Unknown (p. 176). Routledge.

10

Back Country Voices. (2013). Bill to Regulate Drones, Protect Privacy
Introduced. Back Country Voices. Retrieved August 13, 2014, from
http://backcountryvoices.wordpress.com/2013/12/13/bill-to-regulatedrones-protect-privacy-introduced/
Bhattacharjee, A., & Lossio, R. (2011). Evaluation of OCHA Response to the
Haiti Earthquake. OCHA. Retrieved August 15, 2014, from
http://hhi.harvard.edu/sites/default/files/In Line Images/programs - hum
effectiveness - earthquake - evaluation.pdf
Boltanski, L. (1999). Distant Suffering: Morality, Media and Politics (p. 268).
Cambridge University Press.
Bratton, B. H. (2008). iPhone City. Retrieved August 11, 2014, from
http://www.bratton.info/projects/texts/iphone-city/pf/
Buscher, M., Liegl, M., & Thomas, V. (2014). Collective Intelligence in Crises.
In J. Stewart (Ed.), Social collective intelligence: combining the powers of
humans and machines. Springer.
Carroll, P. (2006). Science, Culture, and Modern State Formation. Berkeley,
CA: University of California Press.
Chesbrough, H. W. (2003). Open Innovation: The New Imperative for Creating
and Profiting from Technology (p. 227). Harvard Business Press.
Daston, L., & Galison, P. (2007). Objectivity (p. 501). Zone Books.
Dean, J. (2005). Communicative Capitalism: Circulation and the Foreclosure of
Politics. Cultural Politics: An International Journal, 1(1), 51–74.
eScience. (2012). Earth faces a century of disasters, report warns. Retrieved
November 04, 2012, from
http://esciencenews.com/sources/the.guardian.science/2012/04/26/earth.
faces.a.century.disasters.report.warns
Fugate, C. (2011). Haiti: the Importance of Social Media Use During a
Disaster. 2011 Federal User Conference. Retrieved August 14, 2014, from
http://video.esri.com/watch/163/haiti-the-importance-of-social-media-useduring-a-disaster
Furedi, F. (2006). Culture of Fear (p. 212). Continuum International Publishing
Group Ltd. R
Graham, S. (2008). Cities Under Siege: The New Military Urbanism, 1–555.
Greenfield, A. (2006). Everyware: The Dawning Age of Ubiquitous Computing
(p. 272). Peachpit Press.

11

Greenfield, A. (2013). Against the smart city. Do projects; 1.3 edition.
Halverstadt, L. (2014). Why Firefighters Aren’t Using Drones to View the
Blazes — Yet. Voices of San Diego. Retrieved August 13, 2014, from
http://voiceofsandiego.org/2014/05/15/why-firefighters-arent-usingdrones-to-view-the-blazes-yet/
Haraway, D. J. (1990). A Cyborg Manifesto. In Simians, Cyborgs, and Women:
The Reinvention of Nature (p. 312). Routledge.
Haraway, D. J. (2008). When Species Meet (p. 423). University of Minnesota
Press.
Harding, L. (2014). The Snowden Files: The Inside Story of the World’s Most
Wanted Man (p. 352). London: Guardian Faber Publishing.
Harley, J. B. (1989). Deconstructing the Map. Cartographica, 26, 1–20.
Harley, J. B. (2001). The New Nature of Maps: Essays in the History of
Cartography (p. 352). JHU Press.
Harrald, J. R. (2006). Agility and Discipline: Critical Success Factors for
Disaster Response. The ANNALS of the American Academy of Political
and Social Science, 604(1), 256–272.
Hayles, N. K. (1999). How We Became Posthuman: Virtual Bodies in
Cybernetics, Literature, and Informatics (p. 364). University Of Chicago
Press.
Heath, C., Svensson, M. S., Hindmarsh, J., Luff, P., & vom Lehn, D. (2002).
Configuring Awareness. Computer Supported Cooperative Work (CSCW),
11(3), 317–347.
Henderson, K. (2011). Mind Maps, Memory and Relocation after Hurricane
Katrina. In R. Dowty & B. Allen (Eds.), Dynamics of Disaster: Lessons on
Risk, Response, and Recovery (pp. 77–97). New York: Earthscan.
Hughes, A. L., Palen, L., Sutton, J. J., Liu, S. B., & Vieweg, S. (2008). Collective
Intelligence in Disaster : Examination of the Phenomenon in the
Aftermath of the 2007 Virginia Tech Shooting. Intelligence, (May), 44–54.
Katsumi, B. T. (2013). The Resiliency, Dependability and “Survivability” of
Cloud Computing. CloudScape V. Retrieved from
http://www.cloudscapeseries.eu/Content/Agenda.aspx?
id=264&Page=1&Cat=0!2!1
Kitchin, R. (2013). The real-time city? Big data and smart urbanism.
GeoJournal, 79(1), 1–14.

12

Kitchin, R., & Dodge, M. (2011). Code/Space: Software and Everyday Life (p.
320). MIT Press.
Klein, N. (2008). The Shock Doctrine: The Rise of Disaster Capitalism (p. 576).
Penguin.
Meier, P. (2012). How Crisis Mapping Saved Lives in Haiti – News Watch.
National Geographic Explorers Journal. Retrieved from
http://newswatch.nationalgeographic.com/2012/07/02/crisis-mappinghaiti/
Meier, P. (2013). Digital Humanitarians: From Haiti Earthquake to Typhoon
Yolanda | iRevolution on WordPress.com. irevolution. Retrieved August 15,
2014, from http://irevolution.net/2013/11/11/humanitarian-technologyhaiti-to-yolanda/
Moeller, S. D. (2006). “REGARDING THE PAIN OF OTHERS”: MEDIA, BIAS AND
THE COVERAGE OF INTERNATIONAL DISASTERS. Journal of International
Affairs, 59, 173–XVI.
Monmonier, M. (1996). How to lie with maps. Chicago: Chicago Press.
Monmonier, M. (1997). Cartographies of Danger. Chicago: University of
Chicago Press.
Morrow, N., Mock, N., Papendieck, A., & Kocmich, N. (2011). Independent
Evaluation of the Ushahidi Haiti Project. Program, (4). Retrieved from
http://sites.google.com/site/haitiushahidieval/documents/Ushahidi_Haiti_E
val_final.pdf?attredirects=0
Nancy, J.-L. (2000). Being Singular Plural (p. 207). Stanford University Press.
Naphade, M., Banavar, G., Harrison, C., Paraszczak, J., & Morris, R. Smarter
Cities and Their Innovation Challenges. , 44 Computer 32–39 (2011).
IEEE.
NCOIC. (2013). NCOIC Rapid Response Capability Demonstration. Retrieved
August 15, 2014, from http://www.slideshare.net/kvjacksn/ncoic-gccowsows-10-presentation-10-7-2013
NCOIC Rapid Response. (2013). NCOIC Rapid Response Capability Process NCOIC. Retrieved August 14, 2014, from http://www.ncoic.org/10technology/41-tech-prod-process-nrrc
OCHA. (2013). Disaster Relief 2.0: The Future of Information Sharing in
Humanitarian Emergencies. Retrieved from http://www.unocha.org/topstories/all-stories/disaster-relief-20-future-information-sharinghumanitarian-emergencies

13

Oh, O., Agrawal, M., & Rao, H. R. (2010). Information control and terrorism:
Tracking the Mumbai terrorist attack through twitter. Information
Systems Frontiers, 13(1), 1–11–11.
Okolloh, O. (2009). Ushahidi, or “testimony”: Web 2.0 tools for crowdsourcing
crisis information. Participatory Learning and Action, 59(1), 6.
Oxfam. (2014). Haiti earthquake: 4 years later | Oxfam International.
Retrieved March 02, 2014, from http://www.oxfam.org/en/haitiquake
Parisi, L. (2012). Digital Design and Topological Control. Theory, Culture &
Society, 29(4-5), 165–192.
Raftree, L. (2010). Activism vs slacktivism: it’s about context not tools |
Wait... What? on WordPress.com. Retrieved August 14, 2014, from
http://lindaraftree.com/2010/09/28/activism-vs-slacktivism-its-aboutcontext-not-tools/
Richards, E. (1994). A Political Anatomy of Monsters, Hopeful and Otherwise:
Teratogeny, Transcendentalism, and Evolutionary Theorizing. Isis, 85(3),
377–411.
Sachsman, D. (1996). The Mass Media “Discover” the Environment:
Influences on Environmental Reporting in the First Twenty Years. In J.
Cantrill & C. Oravec (Eds.), The Symbolic Earth: Discourse and Our
Creation of the Environment (pp. 241–256). Lexington, KY: University
Press of Kentucky.
Shanley, L., Burns, R., Bastian, Z., & Robson, E. (2013). Tweeting up a Storm.
The Promise and Perils of Crisis Mapping. Retrieved from
http://www.wilsoncenter.org/sites/default/files/October_Highlight_865879.pdf
Sheller, M. (2013). The islanding effect: post-disaster mobility systems and
humanitarian logistics in Haiti. Cultural Geographies, 20(2), 185–204.
Sontag, S. (2002). Regarding the Pain of Others (p. 144). Farrar, Straus and
Giroux.
Southern, J. (2012, April 13). Comobility: How Proximity and Distance Travel
Together in Locative Media. Canadian Journal of Communication.
Southern, J. (2013). Comobility: Distance and Proximity on the Move in
Locative Art Practice. (TBA, Ed.)TBA. Lancaster University: TBA.
St. Denis, L. A., Hughes, A. L., & Palen, L. (2012). Trial by Fire: The
Deployment of Trusted Digital Volunteers in the 2011 Shadow Lake Fire.
In Proceedings of the 9th International ISCRAM Conference – Vancouver,
Canada, April 2012 (pp. 1–10).

14

Starbird, K., Maddock, J., Orand, M., & Achterman, P. (2014). Rumors, False
Flags, and Digital Vigilantes: Misinformation on Twitter after the 2013
Boston Marathon Bombing. In iConference 2014.
Starbird, K., & Palen, L. (2011). “Voluntweeters”: Self-Organizing by Digital
Volunteers in Times of Crisis. In CHI 2011, May 7–12, 2011, Vancouver,
BC, Canada.
Storni, C. (2013, June 9). Design for future uses: Pluralism, fetishism and
ignorance. Nordes. Retrieved from
http://www.nordes.org/opj/index.php/n13/article/view/276
Suchman, L. (2007). Human-Machine Reconfigurations (p. 314). Cambridge
University Press.
Tapia, A. H., LaLone, N., & Kim, H.-W. (2014). Run Amok: Group Crowd
Participation in Identifying the Bomb and Bomber from the Boston
Marathon Bombing. In S. R. Hiltz, M. S. Pfaff, L. Plotnick, & P. C. Shih
(Eds.), Proceedings of the 11th International ISCRAM Conference –
University Park, Pennsylvania, USA, May 2014. University Park,
Pennsylvania, USA,.
Thrift, N. (2004). Movement-space: The changing domain of thinking resulting
from the development of new kinds of spatial awareness. Economy and
Society, 33(4), 582–604.
Vinck, P. (2013). World Disasters Report: Focus on technology and the future
of humanitarian action. Retrieved from
http://www.ifrc.org/PageFiles/134658/WDR 2013 complete.pdf
Whatmore, S. (1997). Dissecting the Autonomous Self: Hybrid Cartographies
for a Relational EThics. Environment and Planning D: Society and Spaceg.
Wood, D., & Fels, J. (2008). The Natures of Maps: Cartographic Constructions
of the Natural World. Cartographica: The International Journal for
Geographic Information and Geovisualization. doi:10.3138/carto.43.3.189
15

15

Abstract Urbanism
Matthew Fuller and Graham Harwood
(Digital Culture Unit, Centre for Cultural Studies, Goldsmiths, University of London)

One of the first computational models of cities was Thomas Schelling’s “Models of
Segregation” in this, and related papers of around the same period (1969-71), he
attempted to provide a logical model for understanding the dynamics of racial
segregation in north American cities and laid much of the groundwork for what later
became agent-based modeling.1 Such work is expressed contemporarily for instance
in the work of J.M. Epstein and others in the area of computational social modeling.2
Although Models of Segregation did not at first use a computer, it sets up some of the
basic characteristics of the field. We use this work as a starting point to think about
the relationship between urban morphologies and the politics of models on the one
hand and the way in which, with the increasing and multiform kinds of merger
between computational systems, models, and city forms, what it means to live in a
model.
The history of computing, from G.W. Leibniz onwards, tangles with the
problematic of developing rational approaches to complex, multi-dimensional
problems with a high-degree of what John Law describes as “messiness”.3 This paper
will examine the ways in which logical forms are positioned in relation to urban life
as a means of discussing the relations between the city and software. The paper will
develop a discussion of such logics in relation to questions of abstraction, reduction
and empiricism. By working with the materiality of computational systems,
especially as they unfold into the urban – and the urban in a full sense, as something
involving complex comings into being of desire, imagination, technologies, forms of
power and so on - we can at the same time recognise and perhaps an art of working
with the tendency to reductionism through which modes of abstraction may operate
and also work with the highly and complexly empirical. As social simulations are
increasingly embedded in or cleave close to lived social forms, the texture and realityforming capacities of these logics and the fantasies they inspire and live by needs to
be examined.
Development of simulation as a scientific practice
One of the attractive aspects of modeling as a means of experimental understanding is
that it offers a science of behaviours rather than of essences. It is peculiar therefore
that one of the earliest examples of social simulation derives from a highly essentialist
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
Thomas Schelling, “Models of Segregation”, The American Economic Review, vol. 59. no 2, Papers and Proceedings of the Eighty-first
Annual Meeting of the American Economic Association (May 1969) pp.488-493.
2 J. Epstein, “Modeling civil violence: An agent-based computational approach”, Proceedings of the National Academy of Sciences, Vol.
99, Supplement 3, May 14, 2002, p.7243-7250. More recent work building on Epstein’s model is, Antonio A. Casilli, Paola
2Tubaro,
J. Epstein,
“Modeling
civil violence:
computational
approach”,
ProceedingsAofsocial
the National
Academy
of Sciences,onVol.
“Why
net censorship
in timesAn
of agent-based
political unrest
results in more
violent uprisings:
simulation
experiment
the
99, Supplement 3, May 14, 2002, p.7243-7250. More recent work building on Epstein’s model is, Antonio A. Casilli, Paola
Tubaro, “Why net censorship in times of political unrest results in more violent uprisings: A social simulation experiment on the
UK riots”, Social Science Research Network Working Paper, August 14, 2011; and, Toby P. Davies, Hannah M. Fry, Alan G. Wilson &
Steven R. Bishop, “A mathematical model of the London riots and their policing”, Nature Scientific Reports no.3, Article number:
1303, 21 February, 2013.
3 John Law, After Method, mess in social science research, Routledge, London, 2004.
1

ontology. Perhaps this can be seen as an example of a new epistemic form emerging
out of a prior set of commitments that it has yet to break.
Models of Segregation builds on the game theory established in 1947 by Oscar
Morgenstern and John von Neumann and provides and early formation what would
later become the wide field of agent-based modeling.4 Schelling’s earlier work in The
Strategy of Conflict of 1960 can be seen as a presiding spirit in its attempt to map and
rationalize options in the decisions around actions in the space of conflict. What is
particularly innovative here is the schematization of non-zero sum conflicts.5 The
paper later becomes material for Schelling’s book of social modelling, “Micromotives
and Macrobehaviour.”6 In the opening stages of his paper Schelling sets up
segregation as a fundamental axiom of great applicability, he mentions men and
women, Catholics and Protestants, boys and girls, officers and enlisted men in an
army. Not all of them necessarily tend towards dichotomous formation. People are
sorted by, “sex, age, income, language, colour, taste, comparative advantage and the
accidents of historical location” amongst other factors. It is assumed that the sorting
behaviour for each of these is the same.
A two dimensional line is drawn (It is important that this is a line, not a grid)
with equal representations of space along its axis. It is populated with an equal
number of blacks and whites.7 Whilst the distribution looks even on the macro level
at the micro level they are uneven. Maybe three blacks are conjunct with one white
then a black and then three whites. If the whites and blacks are content with a 50%
split between the colour of there neighbours then those who have a white neighbour
on one side and black neighbour on the other reach the contentment threshold and
stand still if the neighbourhood to be considered has a radius of one. Those with too
many black neighbours or white neighbours will move in order to achieve
contentment. In a neighbourhood with a radius of one, the line BBBWBWWW
several iterations later would become BWBWBWBW. If the neighbourhood extends
to two houses then the B and W coloured red in the following example
BBBWBWWW would be looking for a new neighbourhood. Shelling takes this basic
model changing the variables Contentment and Neighbourhood and plays out various
scenarios. In Schelling's original paper agents move directly across populations to
find contentment in more recent computational interpretations the application
determine whether or not the agent is content or discontent. If the agent is unhappy,
the algorithm will select an adjacent square. If the square is empty then the agent will
move to it. If it is occupied, then stay where you are.
To summarise, in Schelling’s model, each agent belongs to black or whites
and aims to reside in a neighbourhood where the fraction of blacks/whites is above a
predefined tolerance. Schelling's pattern of residence either creates a complete
integration or segregation.
Curiously, there is no reflection on the constitution of racial sorting even in
excusatory fig-leaf terms of politics, ethics, or even morality. Like the amusing
stories of house-hunting amongst “professors and their wives”8 that he also describes
the specific categories upon and through which segregation operates are described as
if natural, not even worthy of equivocation as to their relation to social structure. The
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
Oscar Morgenstern and John von Neumann, A Theory of Games and Economic Behaviour, 2nd ed. Princeton University Press,
Princeton, 1947.
5 Thomas Schelling, The Strategy of Conflict, Harvard University Press, Cambridge, 1960, 2nd ed., 1980.
6 Thomas Schelling, Micromotives and Macrobehaviour, W.W. Norton and Company, New York, 1978.
7 A Perl program to generate the Schelling Model is online at,
http://faculty.ucr.edu/~hanneman/spatial/schelling/schelling2.pl
8 In Dynamic Models of Segregation and the sorting and mixing chapter of Micromotives and Macrobehaviour.
4

racism of the work is both that it operates by means of racial demarcation as an
autocatalytic ideological given and secondly that it provides a means of organising
racial division at a higher level of abstraction. To say that Schelling operates within
an ideologically racialised frame is not to aver either way as to whether Schelling as a
person is consciously racist, but that, in these papers, racial division is an uncontested,
“obvious” social phenomena that can be reduced in terms of its operation to a precise
set of identifiers and operations. David Theo Goldberg’s formulation of the problem
is useful here:
“The mark of racist expression or belief, then, is not simply the claim of
inferiority of the racially different. It is more broadly that racial difference warrants
exclusion of those so characterized from elevation into the realm of protection,
privilege, property, or profit. Racism, in short, is about exclusion through
depreciation, intrinsic or instrumental, timeless or time-bound.”9
Describing such a situation in a fragment from his diary written during an
extended visit to the USA in 1959-60, the novelist Italo Calvino notes the ways in
which urban form in the city of Cleveland is produced by the intersection of the
cycling of consumption in neighbourhood level zones, where middle class white
families buy cars, clothes, vacations in a pulsed frequency that synchronises identity
and occupation with space and subjectivation. The poor areas are variations on this,
with a hierarchy of racial types, Middle Class Blacks, Jews, Hungarians, Puerto
Ricans, Mexicans, white Virginians, moving through cities as they degrade, stabilise
or otherwise change.10 The story is familiar, as are the many richly deserved parodies
of it.
The naturalization of such a situation of depreciation by at a distance means in
which entities kindly self-organise into ghettos out of their own otherwise unlimited
choice must have been a marvelous boon to someone. What these papers offer is the
construction of a machine for the operation of binary categorization that in turn
becomes an engine for spatial organisation, of preference based segregation, as if the
provision of housing in the form of a market is entirely smooth and demand driven, as
if there are no variations in housing kinds and qualities, geographic features, cultural
variations in population and so on. In the urban space described by this work it is as
if the model were describing a landscape in part shaped by the car that makes every
address as seemingly randomly accessible as a memory register on a hard-drive. A
few years later, the architectural group Archizoom indeed produces an amplified
representation of a city reduced to the most minimal form of grid, in No Stop City
(1968-70) the city becomes a dromescape.11 What better future can we imagine than a
state of permanent white flight, with computing cycles speeding up, populations
moving into mobile homes and urban planning becoming solely devoted to traffic
massaging of a population fuelled on angst and cheap petroleum?
What Schelling’s work allows for is for an operation of governance that works
by a means beyond that of direct sorting and selection, the direct command and
control of populations, but rather by eliciting and installing an action grammar in
which people “spontaneously” recognise, in the words of Nina Simone’s song,
Mississippi Goddamn, “I don’t belong here, I don’t belong there”, moving on to make
the proposition: “You don’t have to live next to me, just give me my equality.”12 It is
indeed the terms by which such an ostensive equality, once it has been given, sets to
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
David Theo Goldberg, The Threat of Race, reflections on neoliberal racism, Wiley Blackwell, 2009.
Italo Calvino, “American Diary, 1959-60”, in, Hermit in Paris, Penguin, London, 2003, p.60.
11 Pier Vittorio Aureli, The Project of Autonomy, politics and architecture within and against capitalism, Princeton University Press,
Princeton, 2008.
12 Nina Simone, “Mississippi Goddamn”, in, Nina Simone in Concert, Philips, Eindhoven, 1964.
9

10

work that is of interest here: all those pennies on the board, looking so equal.
This form of equality, its seeming universality is a driving motivator in the
transition in the work of William Bunge, initially a quantitative geographer and
spatial theorist whose Theoretical Geography13 and related work attempts to discern
universal geometrical laws for spatial development, but who later coupled such an
approach with a deep empirical and activist engagement with a particular square mile
of Detroit, Fitzgerald. 14 Although in both cases Bunge consistently argued that
geometrical patterns and morphological laws express disadvantage and injustice under
contemporary capitalism, and that identified patterns could be remedied by rational
methods there is a transition from the equality of uniformity, of what Sartre and
Guattari call seriality, to the equality of the singular.15 Schelling’s “Models of
Segregation” and Bunge’s “Fitzgerald, geography of a revolution” are separated by
less then three years both respond to questions of racialization and class in the United
States of America and both use constructs drawn from mathematical logic as means to
work into and sort social dynamics. Both have an enthusiasm for experimental forms.
Both use relatively plain speech, and are praised in both cases for making
contributions to fundamental problems and eschewing jargon. One of them ends up
losing his job and working as a taxi driver, the other wins the Nobel Prize for
Economics.
Schelling specifically offers the image of urban form being operated upon by
an “invisible hand”, emerging at a higher level in social and material creodisation or
channeling.16 There is a tension then between the figure of this invisible hand and the
view of the agent. The hand operates in an ostensibly emergent natural way, arising
out of the conditions of the situation as they are, beyond how they are seen by
individual actants. In this, the work affiliates itself with the long term questions of
social physics of August Comte and subsequent workers in this vein, and the
formulations of right and proper order emerging at a macro scale out of the
interactions of entities at a micro scale familiar from liberal economic thought.
Although Jean-Pierre Dupuy calls the potential liaison between cybernetics and game
theory a “missed rendezvous”17 the work also has certain conceptual resonances with
aspects of accounts of self-organisation achieved by logical forms coming into the
discourse of second wave cybernetics a little earlier.18
Abstraction as Urbanism
Schelling’s abstract machine is a machine for the bipolar reduction of variation. The
urban grid becomes equivalent to that of a truth table, but one of the advantages of
such an abstraction is that it requires no specific material form simply logical
equivalence. As recounted in a rather glowing chapter in a festschrift, Schelling used
pennies, heads or tails up, on a draughts board to simulate, “what sort of segregation
patterns develop given various types of preferences and alterative definitions of
neighbourhood”.19 The scale of the board becomes the limit-factor of the diagrams
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
William Bunge, Theoretical Geography, Lund Studies in Geography, Gleerup, Lund, 1962.
William Bunge, Fitzgerald: Geography of a Revolution, Schenkman Press, Cambridge, Massachusetts, 1971; reprint University of
Georgia Press, (Geographies of Justice and Social Transformation), 2011.
15
Jean Paul Sartre, Critique of Dialectical Reason, Routledge, London, and Félix Guattari, The Three Ecologies, Continuum, London,
2008.
16
Christopher H. Waddington, Tools for Thought, Paladin, St. Albans, 1977.
17
Jean-Pierre Dupuy, The Mechanization of the Mind, on the origins of cognitive science, Princeton University Press, Princeton, 2000.
p.126
18
Willard Ross Ashby, “Principles of the self-organizing system,” in, Principles of Self-Organization: Transactions of the University of
Illinois Symposium, Heinz Von Foerster and G. W. Zopf, Jr. eds., Pergamon Press, London, pp. 255-27.
19
Richard Zeckhauser, “Thomas Schelling, Ricochet Thinker”, in, Robert Dodge, ed., The Strategist, the life and times of Thomas
Schelling, Hollis Publishing, New Hampshire, 2006. p.x.
13
14

published in a later paper, “Dynamic Models of Segregation.”20 One can certainly
imagine a media-archaeological analysis of the history of simulation starting with
checkers or draughts boards. John Conway, in developing the game of life, famously
extended his to cover most surfaces of his office.21 Only having four significant
neighbours, termed Neumann neighbours22, adds a certain simplifying factor to the
board, the constraints of which in order to get certain kinds of effects need to be
surpassed by the kinds of scale more recently offered by electronic computing.
In later work by Epstein, marking a fundamental shift in agent-based
modeling, the environment was considered as a partially ordered list where each
element on that list is a scalar of a fixed range of values to be thought of as resource
bearing sites. Unlike living organisms, in ABM the medium (environment) is fully
separate from the agent on which they operate and with which they interact. Indeed,
a media analysis of the field would tend to divulge a number of aspects of its material
practice that are rendered conceptually and procedurally invisible. One of these
would be the way in which models tend to be bound by the temporal constraints of
“turns” in which all agents shift at the same time. Most computer science models
need to have all variables change at the same time – but models of sociality need to
vary the time in which all variables change. Equally, the model’s interaction with
hardware, and the need to represent data to human users also renders the use of CPU
cycles for drawing graphical representations as something of an interference, when
compared with how many agents could be processed instead.
A few years after Schelling’s work was published, and amidst the rise of the
counterculture, Ted Nelson stated in Computer Lib that, “Simulation is always
political”.23 Computers as an abstract machine for the integration of all symbol
systems, that is to say of all systems operated upon by discrete values, or that can be
rendered as digital provide in a certain sense a great degree of plasticity in the social
forms they might generate: hence the significance of Nelson’s formulation. The
specific kind of politics simulated is also articulated by the specific qualities of the
mathematical structures that comes into composition with them. (For instance,
systems of four or eight neighbours; bounded, unlimited or wrapping grids and so on.)
It is a very rare case in which there is a direct correlation between the various scales
of model, media, mathematics, the social form modeled, the ideological commitments
specified as politics in such simulations, and the actual politics of the material
operations of such systems in use.
Diagram City
Joshua Epstein and Robert Axtell’s book Growing Artificial Societies, Social Science
from the Bottom Up was based on "Models of Segregation" and refined and developed
using concepts drawn from the Game of Life developed in 1970 by John Horton
Conway.24 In Conway's cellular automata and Schelling’s space of segregation the
environment has no proprieties other then to be bounded or not, something that has
consequences for the way in which these models carry over into urban planning and
the modelling of cityscapes. Epstein and Axtell’s innovation was to place agents in
an active environment in which the agents were pre-programed to explore the
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
Thomas Schelling, “Dynamic Models of Segregation”, in, Journal of Mathematical Sociology, 1971, vol.1, pp.143-186.
Martin Gardner, “The fantastic combinations of John Conway's new solitaire game "life"”, Scientific American, no.223, October
1970, pp.120-123.
22 Edward F. Moore gives his name to systems of eight neighbours in a rectilinear grid.
23 Ted Nelson, Computer Lib, 1974 “All simulation is political. Every simulation program, and thus every simulation, has a point of
view. Just like a statement in words about the world, it is a model of how things are, with its own implicit emphases: it highlights
some things, omits others and always simplifies”
24 Joshua Epstein, Robert Axtell, Growing Artificial Societies, social science from the bottom-up, The MIT Press, Cambridge, 1996.
20
21

environment to find a simple codification of some basic property such as sugar to
keep their metabolism alive. Agents have internal states and behavioural rules that
are fixed at the start or that can inherit change in interaction with environment or
other agents. This is a model as a form of regression analysis, or rather of using
regression as a form of proposition, where the relations between entities are fixed but
variable. The environment is a lattice of resource bearing sites in a medium that is
separate from the agents, but on which they operate and with which they interact.
Both agents and the environment have rules. This innovation adds another level of
complexity to the ecology of agents, developing newer models working with forms of
emergence.25
Joshua Epstein has produced a body of work discussing the ethics around
agent based modelling that seek to affect US governmental policy by creating explicit
models that can be used to create an explanation of social phenomena that he is very
careful to distinguish prediction from explanation. In his article Why Model? Epstein
challenges the assumption that scientific theories are created from the study of data.26
He asserts that without a good theory, it is not clear what data should be collected.
The model requires theorisation; his main assertion is that modelling creates habits of
mind essential to what he calls freedom and to enquiry.27
Agent-based models have been eagerly taken up as objective explanations of
conflictual social forms. The capacity to express forms of emergence, with the
invisible hand effectively rationalizing commonsensical observations of the
inevitability of racial segregation exciting dreams of implementation. As such, this
work evinces a fascination with finding fundamental laws of social aggregation,
rhetorically building on those found in natural sciences, in turn triggered by those
historically associated with mathematics. At this stage we can say that the model and
the discourse around it still act in a representational mode.
Simulations now operate for an enormous range of activity. They act as a
form of prognosis and forecasting, of pre-emption and the maintenance of
irresolvability as well as the ability to formulate an explanation with empirical
traction without having to be true. Simulations also develop specific kinds of
techniques and vocabularies, as well as the software to handle and interpret them –
object orientation being one such example.28 OOP is fundamental to how agent based
modelling conceives of itself in that it allows objects to hold data and functions – data
fields hold the object’s instance variables – in internal states. The object exports a
limited set of methods with which to interact with the object – and generally the data
is held private to the object. It is not globally addressable. This is why the behaviour
of objects comes to the surface – rather then the data that underlies them. Functions
or methods are the agents’ rules of behaviour. Equally, we can say that simulations
may act as a kind of theory of mind for the state and other institutional and
organisational forms. Jean Baudrillard’s surprisingly notorious formulation about the
first gulf war not happening should be remembered in this sense, in that it was an
event that rolled out after having been pre-effectuated by models, plans and fantasies
of action.29 Political elections, car interiors, football stadia, economic plans, the
design of traffic systems, not to mention the psychic life of persons, are all deeply
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
Along with Robert Axtell, Epstein created Sugarscape, a software system for agent based modelling.
Joshua Epstein, “Why Model?” Journal of Artificial Societies and Social Simulation vol. 11, no. 4 12
27 Joshua Epstein, Advances in Agent-Based Computational Modelling, Lecture at Johns Hopkins Global Centre on Obesity,
11th November, 2013, online at: https://www.youtube.com/watch?v=DAAvrfzJ0Ec/
28 See, Matthew Fuller and Andrew Goffey, “The Unknown Objects of Object Orientation”, in Penny Harvey et al. eds., Objects
and Materials, Routledge, London 2014.
29 Jean Baudrillard, The Gulf War did not Take Place, The Power Institute, Sydney, 1995.
25
26

interwoven with and activated through modelling and anticipatory axiomatisation.
What we see as a novelty in this kind of work is the way in which particular
forms of computational abstractions themselves become operative elements in social
and urban formations. Computation becomes folded into the operations of societies,
and social forms become computational problems. As the programmable city begins
to incorporate models such systems cease being merely representational.
Here we can see that there is a correlation between formulations such as those
of Epstein and Schelling, (and those that followed in developing simulated societies)
and the social sorting by software described by Steven Graham in his Software Sorted
Geographies.30 Where there is a difference however is that Graham describes a
disciplinary sorting on the social. In agent based modeling by contrast, there is an
interplay between the schema of sorting and the actions of individuals and social
formations without engaging with the level of implementation. There are kinds of
sorting occurring, but more adequately expressed as a multi-scalar, multi-variable
sorting enacted by agents bearing seemingly lucid, seemingly operable, preference
lists arrayed in relation to the behaviour and imagined preferences of others and
seemingly reducible to hard and fast dualistic organisation. A particularly interesting
moment to anticipate and to watch for is that when the two merge to some extent or
other, either in actual implementation, or in the seductive idea that such reductions are
fully adequate explanations of specific slices of reality.
In the case of the racism of Schelling’s Models of Segregation the categories
pre-exist the machine, the machine is there to sort them, to anticipate their
actualization, to provide a degree of abstraction in which they can be reckoned, but by
which the abstraction too can be worked up into an actor of a kind in itself. This
operation of abstraction is crucial to understand software as a cultural, city-making
force. Computational systems and urban situations fundamentally mix in the present,
but with vast and multiform differentiation of intensity and kind.
Media theorist Claus Pias specifies the way in which simulations act as a
means of arranging governmentality in a manner that corresponds to Foucault’s
discussions of biopolitics. Speaking of an agent based modeling system for
epidemiology, he specifies that, “This ‘intervention in the environment’, this ‘playing
with the rules of the game’, this ‘optimisation of systems’ and this ‘free play’ of
individuals and their practices – all of this is precisely what is subjected to
experimentation in simulations.” 31 There is a generalization of strategy that
temporally accompanies, coevolves with, but is distinct from, moves towards the
generality of computation. Simulation allows for a pre-emptive action on action and
it is a way of applying logics to territories, spatial forms of any scale understood in
relation to Deleuze and Guattari’s formulation of territorialisation and
deterritorialisation.32
Logics
Programming and the use of computers implies the inter-relation of different forms of
logic, both at the level of programming the machine to perform calculations and
regulating the behaviour of users in pushing around mice and navigating menu
systems to produce desired results. One way to think about how the mass adoption of
these forms of logic effects the broad reach of society is in the mode Foucault
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
Steven Graham, “Software-sorted geographies”, Progress in Human Geography, vol.29, no.5, pp.562-580.
Claus Pias, C 2011, “On the Epistemology of Computer Simulation”, Zeitschrift für Medien- und Kulturforschung, Nr. 1, S. pp.2954.
32 Gilles Deleuze and Félix Guattari, A Thousand Plateaus, capitalism and schizophrenia volume two, trans. Brian Massumi, Athlone,
London 1988.
30
31

described as discipline, one that analyses and breaks down a phenomena through
modeling it to produce a kind of remote control. Computation, disciplines the way a
phenomena is approached and analysed, so that when it becomes visible again from
within the computer, it makes the phenomena materially available for comparison and
modification. As users participate in the flows of power created by comparing
information they become normalised to its process and themselves entailed into the
inter-relation of logics at different scales.33
Expressing this differently, computational forms of normalization establish the
configuration of logics needed to make the materiality of the phenomena available for
modification in a scalar of abstraction, verification and reward. The repeated
construction and use of these forms of logic fixes what Foucault would call
“progressive training”34 for those that model, feed, collect, process and react to the
logics, as well as those objects that are the subject of its calculations. Logics
decompose processes and the entities, including people, that are aggregate with such
process and the routine processing/interaction with such models set a stage, a
collective logic to be applied to all areas of society and the natural world. The move
beyond discipline is characterised by the absence, further withdrawal or multiplicity
and duplicity of the, ultimately reliable, central control discipline implies as a
structuring principle.
Promissory inputs
Contemporary to Archizoom, another architectural practice Archigram, building on
the work of Cedric Price, proposes a model of a Computer City which saw the urban
fabric as a nomadic, energy and activity saturated conglomeration of interactive parts
in which “First the computer processed the desires of its inhabitants as data; then,
depending on the sensorial input, structure adapted to create and environment
conducive to the required activity or state.”35 There is an assumption here that each of
these stages correlate to each other either directly, or by means of a mutual figuring
out. Seductive as a model, this is also an image of the city as fantasy a key mode of
which in turn is that desire is itself computable.
Importantly, one of the key factors of these technologies is that they don’t
have to get reality right, at the level of representation or understanding, but solely to
intervene and shape realities at multiple scales in some way that is directly or
indirectly conducive to sustention of the model. One of the key lessons of
information theory is that to start processes of control and communication, one has to
start first entraining the subject or social, feeding it information, around which process
a new formation can crystallise. Feed logics into social formations and see what
congeals around them: this is what is known as policy, or fantasmatic experiment.
Ashby specifies in his work on self-organisation that communication requires
constraint, with organisation - and a self, a system - arising out of this consistency. In
her work on modelling in Cosmopolitics, Isabelle Stengers reversions this notion of
constraint as the quality of a system or a phenomenon being “promising”, a quality
that consists of the interplay between an obligation and a certain possible likelihood.36
Probing the interaction between these two qualities of constraint, indeed setting up, or
tendentially amplifying, the terms of their interaction, is key to experimental practice,
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
In creating a database, normalization is the process of organizing it into tables in such a way that the results of using the
database are always unambiguous and as intended.
34 Michel Foucault, Security, Territory, Population, lectures at the College de France, trans. Graham Burchell, Palgrave Macmillan,
London, 2009.
35 Hadas A. Steiner, Beyond Archigram, the structure of circulation, Routledge, London, 2009, p.205.
36 Isabelle Stengers, Cosmopolitics 2, University of Minnesota Press, Minneapolis, 2011, p.143.
33

but also to modes of governance in the present. This nature of the promising qualities
of experiment also makes such work one also of the imagination of what such a
promise consists and the exertions and operations of powers in relation to the
exploitation of such a quality.
Logic Gates
Part of the legacy of Schelling’s and Epstein’s work is in the various police, academic
and intelligence projects that aim to predict riots via sentiment analysis aimed at
identifying tipping points. “Negative words”, “hate-speech”, “positivity” and
expressions of anger stand in for a population of shifting emotional registers, moving
from stable states to those that can be used to require the maintenance of policing
budgets, harsher policy and sudden rashes of inflamed and excited research budgets.
In such cases, the scale of imaginary analysis moves ever more to the macro-scale.
The operators of such machines imagine that their technical fix provides a neutral
oversight, in which the free expression of populations and individuals can be neutrally
mapped and cross-checked for naughtiness and appropriate measures deployed. What
happens is rather more complex, social forms are flooded with those of the state,
which itself attempts to follow too many filiations and clusterings. In the meantime,
academic chancers position themselves as dubious mediators, by being able to appear
to delve into the firehouse of text produced by a population mapped according to
strings of characters. We enter into a condition of a generalised politics of
experiment. What is rather lacking are the means to conceptualise and actualize such
experiments from the position of anything other than increasingly narrowly defined
bands of social and economic interest.
Pias suggests that recent theories such as actor network theory and radical
constructivism come form the same stock of ideas as simulation, since for both:
“Their knowledge is consciously – and as a matter of course – furnished with a
hypothetical index, they admit to their fictional components, they position themselves
within their conceptual frame of reference, they thematize their performance, they are
aware of their problematic genesis, and they specify their limited application.”37 A
useful provocation following such a proposition is to be found in Latour and
Lépinay’s reading of Tarde: “If you really want to quantify – which is after all the
foundation of all sciences – you should try to find all the available types of quantum,
instead of just using one to analyse all the others.”38 This premise underlies some of
the enthusiasm for big data analysis at present. It also perhaps implies that social
reality is a simplified model of more adequately complex modeling schema. But we
can also suggest that William Bunge’s later mode of maximalist empiricism coupled
with high degrees of statistical abstraction is of great relevance here. The proposition
that to study is to become actively involved, to observe is to change, but also to
recognise, that though such change may be reciprocal, it may not be symmetrical and
equivalent. These are the stakes now of watching and participating, since in the city
understood as a platform for self-organisation, algorithms, rule sets, data-structures
and procedures have highly and perhaps questionably promising agency.39 The recent
scandal of researchers from Facebook and the Universities of California and Cornell
using Facebook’s news feed to operate an experiment on whether people responded to
the filtering of what appeared in their news feed on the basis of whether it was
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
Pias, op cit
Bruno Latour and Lépinay, The Science of Passionate Interests, an introduction to Gabriel Tarde’s economic anthropology, Prickly Paradigm
Press, Chicago, 2009, p.19.
39 Samir Chopra, “Computer Programs are People Too”, The Nation, May 29, 2014.
37
38

associated with emotional “negativity” or “positivity” should be seen as a part of this
tendency. The researchers note that Facebook constantly experiments with the
algorithm to fine-tune this aspect of their “product”.40 It is this state of perpetual
experiment, linking different scales of realities that is characteristic of the condition of
abstract urbanism and the kinds of operations that the integration of modeling with
cities encourages.
This operation of the city as an open experiment is of course one subject to the
analysis of power. For Epstein and Axtell, agent-based modeling enforces habits of
mind that are essential to intellectual and democratic freedom. An agent-based model
must be explicit and open (in a certain way, FLOSS-like) and be able to be examined
and doubted, reconfigured and rerun. Epstein aligns agent-based modeling to
scientific modes of inquiry that he sees as antithetical to established discursive
intellectual systems.41 Agent-based modeling is the freedom to doubt large
monolithic systems of knowledge that he characterises as being based on deductivelyestablished theorems. Epstein and Axtell propose that we are on the edge of a new
enlightenment based on the ubiquity of computing in which, “Intellectuals have a
solemn duty to doubt, and to teach doubt. Education, in its truest sense, is not about ‘a
saleable skill set.’ It's about freedom, from inherited prejudice and argument by
authority.”42 The question of whether the enlightenment can be fully and
undiffentiatedly called upon in this way is in turn open to doubt, but there is
something here that suggests some possibilities in that it is a science that explicitly
calls subjects into being.
This proposed new mode of science of active abstractions involves cities and
social forms in what Stuart Kauffman calls “the physics of semantics”, logics that
have effects in the organisation of conjunction, calculation, control and
communication of the kind that also create cities.43 Such a physics of semantics can
be seen, at other scales, in the way that the agent-based model is involved in the
specific forms of hardware and software development that conjoin both meaningmaking scaffolds and physical properties. Object-orientation in programming is seen
as a cogent worldview capable of answering difficult questions about behaviour that
emerges from complex subjects in the social or in economics, where, “It facilitates
essentially any interaction structure (social network) and activation regime.”44 In
contemporary accounts, Agent-based modeling also links its ambition to the growth of
CPU processing and the availability of hard disk space and network processors
assumed under Moore’s Law.45 The “promising” nature of abstract cities is thus also
instantiated into multiple scales of their materiality.
This suggests that there is the possibility for a mode of experimentation, and
of experimental politics and urban living that moves from the logics of theorems or
axioms to an abstract empiricism. Throughout this text we have contextualized the
development of agent-based modeling and social simulations through reference to
historical material in cybernetics and self-organisation; to literature, music and
architecture as well as to changes in the practice of geography.46 Software based
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
Adam D. I. Kramer, Jamie E. Guillory, and Jeffrey T. Hancock, “Experimental evidence of massive-scale emotional contagion
through social networks”, Proceedings of the National Academy of Sciences of the United States of America, June 17, 2014, vol. 111, no. 24,
pp. 8788–8790.
41 See, Epstein, Advances in Agent-based Computational Modelling.
42 Epstein, “Why Model”.
43 Stuart Kauffman, Investigations, Oxford University Press, Oxford, 2000.
44 Robert Axtell, “Economics as Distributed Computation”, Post-Proceedings of the Second International Workshop on Agent-Based
Approaches in Economic and Social Complex Systems, Springer, Heidelberg, 2003, pp.3-23, p.10
45 See the attention given to the “Prospective growth of agent capabilities on single workstations” & “ Growth of agent
capabilities on single workstations, native source code in C++” in Axtell’s, Economics as Distributed Computation.
46 There has also been something of a historical leapfrogging of systems implementations such as those of Jay Forrester and the
40

simulations essentially replaced the kinds of hardware based simulations or analogues
of biological, cognitive and social systems being developed in places such as Heinz
von Foerster’s Biological Computer Laboratory in Illinois.47 The questions they pose,
change in this transition, and they become allied less with the philosophical concerns
of the lab, with its great emphasis on epistemology, into those of other conditions.
One of these is the question of abstraction and reduction from material empirical
conditions. We are now well into another similar transition, where instead of moving
from hardware to software (with hardware concomitantly becoming less experimental
and idiosyncratic in the form of commodity electronics) social and urban forms
become places of computational inter-operation and experiment.
Urban space is increasingly produced in the production, circulation and
analysis of large volumes of structured and unstructured data. Models and
modelisations are being integrated into the design of spatial forms at conceptual, preemptive and in certain cases, agents become active as urban entities installed and
active in symbolic and materials orders of the city.48
Here it is worth thinking back to William Bunge’s work in Fitzgerald,
geography of a revolution. This work combines knowledge extracted by verifiable
methods, abstracted into quantified information with other forms of situated
knowledge that come about through more informal processes of observation and
action of the people of Fitzgerald. Quantification is seen as a revolutionary tool in
which people compute information from their lives and environment to put forward
logical arguments about injustice. Pedagogy about research methods becomes
important in this context, and is developed by expeditions and community alliances
with universities. Key too to this research is the way in which the environment, from
the geology up, through history and social and technical formations shape its
development. As such it poses another mode of the relation between synthesis and
analysis. What might be a form of research about abstract urbanism that took into
account some of the lessons of Bunge’s Fitzgerald, in the wider context of
computational transformation?
Just as computational forms structure reality, so do other kinds of model.
Abstract urbanism is hypothetical, fictional, maximally empirical, and of course
abstract. This means that the way in which abstractions become materially operative
have to operate through these conditions, and also - under certain regimes of rhetoric to shield them, as simply fact-based extrapolations. To recognise that they are
imaginary, as models, without being merely false, or simple reifications is part of the
art of abstract urbanism. To recognise agent-based modeling in such as way is to
recognise that models are also partial cities operating like partial objects, formalised
slivers of an urban configuration taken for a whole and working drives into active
diagrams. Such a condition, in which the possibilities of social fractures being
triggered in the models and then implemented are manifest, cannot but add an
ambiguous potency to the operations such an art promises. To work abstract
urbanism then in the condition of models becoming cities is also to open the
possibility to operate, like Bunge, with a maximalist empiricism, of the abstract as
	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
System Dynamics Group of the 1970s embodied later in software systems such as Dynamo and Stella or the history of modeling
in climate such as that discussed by Paul Edwards, in, A Vast Machine, Computer Models, Climate Data, and the Politics of Global Warming,
The MIT Press, Cambridge, 2010.
47 Albert Müller and Karl H. Müller, eds., An Unfinished Revolution, Heinz von Foerster and the Biological Computer Laboratory, BCL 19581976, edition echoraum, Vienna, 2007.
48 There is a growing market of more or less convincing companies offering services, consultancy and software for market
analysis; traffic and pedestrian behaviour and other phenomena. Aimsun road traffic analysis software for instance provides real
time forecasts of road activity that can be directly integrated into traffic management processes. In these cases, there is a
tendency towards integrating models and what they model with potentially novel behaviours arising as a result.

much as of the street or the experience of concrete social relations. It is to operate
with delicacy and attentiveness in the design of models, but also to the arguments,
spaces and politics that they bear, that they determine and into which they are
smuggled, driven and suffused, and which in turn they rely on to sustain themselves.
It is to saturate models with variables, and to open abstraction to social disruption
rather than to prepare the abstract retrenchment of urban injustice.
But to recognise abstract urbanism is not solely to postulate an interesting set
of potential political practice, but more, to come to terms with a fundamental change
in the consistency of cities today, that they are suffused with logics. This is not
simply to say that streets are data structures, people are variables and that the city is a
grid, laced with numerical nutrients, in which in their interaction produce an adequate
if simplified mimicry of urban life; but that the city, the exemplary space of
modernity in all its complexity of desire, violence, multi-scalar layering, imagination,
invention and struggle is also a place of experiment with its modes of composition of
self-emergence at multiple scales of abstraction. Such a space is one where fantasies
of control, of understanding, of ordering, of establishing implicit and explicit coordination and pre-emption co-exist with their enactment, their failure, their use as
excuse, and as a space where reason co-exists with the surprise of the unpreforeseen.
Agent based modelling provides a means for the fantasmatic appearance of reason as
an always present compliment of reason itself in that it mobilises means by which
things occur in and for themselves in the mode of emergence, and for a space for
arranging the coming into being of ideas of the city that are beyond the habitual
means of interrogating existing co-ordinates. Here, in the state of being promising,
reason both pre-empts surprise and relies upon it for its prowess in providing a
gateway to emergence understood as the self-constitution of reality; a reality that is on
the one hand seemingly unblemished by mess, or on the other, one forged in the full
ongoing complications of the city-scape in which it becomes manifest and which by
positing a modelisations it becomes manifest. This is a deeply ambivalent position.
The physics of semantics in which such emergence is made is therefore worthy of
attending to with all the precision and inventiveness that can be mustered, as it too
becomes a space in which the city occurs.

Digital social interactions in the city: Reflecting on location based
social media.
Luigina Ciolfi, Sheffield Hallam University (UK)
Gabriela Avram, University of Limerick (Ireland)
1.Introduction
In this paper we discuss how digital interactions are increasingly interwoven with
spaces and places in urban settings and how such interactions are mediated by and in
turn shape the technologies that facilitate them. We will focus on the understanding of
interactions using location based social media (particularly Foursquare) as a way to
reflect on issues of technological support to human activities, and on the relationship
between code, digital agency and the physical world.
Whether purposely built for mobile devices and with a focus on location (e.g.
Foursquare; Swarm), or simply features of other social media platforms that rely on
location data such as Facebook Places, various location based social networks
(LBSN) increasingly mediate social and interpersonal interactions in urban settings.
Essential technological infrastructure that enables such interaction is the possibility of
linking data to particular places by means of devices capable of detecting their own
location by means of Global Positioning System (GPS) or other mechanisms. On the
basis of such infrastructure, however, location based social media user activities take
different forms: from “checking-in” (e.g. users register their presence at a particular
venue), to linking location data to digital content to be then shared on social media, to
gameplay associated with occupying a location and performing certain activities
there. The form of sharing these activities socially with contacts and other fellow
users is also constrained by the platform: e.g. for example a photograph with location
information; or presence at a location with associated content; or a map of movements
and check-ins, etc.
Such practices become coded into the system, representing both the log and content of
social interactions, as well as the location to which they relate. Therefore a digital
“cloud” of social interactions becomes embedded into the physical reality of a city, of
its neighbourhoods, public places, cafés, transportation hubs and any other locations
identified by social media users (by user-initiated “check-ins” or by the content that
generated, such as photographs or textual recommendations and tips), and by the tools
they use (for example, through automatic geo-tagging). Conversely, the code
determining a platform’s interaction and functionality is continuously changed to
reflect user activities and feedback, and to implement design decisions on how
location based social media services work.
Among others, two sets of issues surrounding this topic are emerging that we wish to
investigate further: firstly, examining how such localised interactions in physical
spaces are triggering and feeding back into the algorithms and infrastructures
provided by the software - how are various location-based social media platforms
framing people's perceptions and identifications of locations? How is code both
facilitating and scaffolding a set of social interactions relating to various spatial
configurations in physical spaces?
Secondly, we are interested in the rematerialisation of such cloud of interactions in
the physical world: how are physical spaces and places affected by their digital
counterparts and by the activities that people conduct on LBSN? There are already
occurrences of the rematerialisation of digital presence and interactions in the
physical world: for example, venue owners displaying badges on the premises that tell
1

customers about their online presence (on platforms such as Tripadvisor,
Booking.com, etc.). Foursquare includes “specials” (discounts and freebies) that
business owners can use for attracting customers. In Europe, there is relatively little
awareness regarding Foursquare and few businesses engage with it (and it is not yet
clear if the latest version of the software will have replaced these with advertising).
However, these are limited representations. Could LBSN interactions in relation to a
venue be made somehow more perceivable and/or tangible in the physical world by
the way in which certain environments are designed? Could the presence and
interactions that are encoded in LBSN software shape more distinctively the
physicality and materiality of places?
Overall, it is an open question whether this would be useful or meaningful, and
whether it could have implications beyond technology design: for example, should
new approaches to urban planning and environmental design become concerned with
accommodating and facilitating these social interactions as they do so by supporting
in-presence, analogue ones?
In the following sections we will attempt to define and discuss these issues
surrounding LBSN activities, drawing both from human-computer interaction
literature on physical/digital interactions using location based social media and from
empirical studies of location based social media use that we have conducted in two
cities.
2. Location-based social media: identifying interactions
Since the introduction of LBSN commercial platforms and services in the mid-2000s,
a number of studies have been conducted within Human-Computer Interaction and
social computing examining how these are used by various groups of users (Eagle and
Pentland, 2005; Barkhuus et al., 2008). One of the main focuses of such work (and
arguably one of the most popular LBSN worldwide) has been Foursquare: a mobile
app launched to the public in 2009, Foursquare counts over 50 million registered users
worldwide, with approximately 50% of them based within the United States1.
While the core interaction offered by the service remains to this day that of linking
digital activities to a particular place or commercial venue, the Foursquare layout and
the way it operates have changed significantly since its public launch. Users can
register their presence at a venue by checking in. Photographs could also be uploaded
when doing so, and comments and tips added to a particular venue. Initially,
Foursquare incorporated a game-like element, where users would gain points
whenever they checked in at particular places and could become “mayor” of a certain
place by checking in repeatedly there over time. They could also gain “badges” by
achieving a certain number of check-ins in venues of a certain kind (e.g. airports, bars,
bookshops, etc.) or by completing particular tasks (e.g. checking in at movie
screenings). Users’ check in performance would be compared to that of their contacts,
although they could compete for a venue’s mayorship against any other Foursquare
user. Both badges and point scoring features have been phased out of the system in
2014 as part of a major re-development of the platform. The remaining activities that
the service supported have been split into two separate apps, a re-designed Foursquare
and a new app called Swarm2: Foursquare now functions as a venue-finding and
recommendation app only - e.g. it helps users locate places of interest near them in
1 https://foursquare.com/about
2 http://blog.foursquare.com/post/85232472353/mayorships-and-more-how-swarm-is-going-to-makeyour

2

various categories (food, shopping, sights, etc.), to “like” a place thus marking it as a
favourite, and to read and add tips and recommendations about a place. The platform
can also be used by owners of venues registered on Foursquare for promotions,
marketing, etc3. On the other hand, all the interactions relating to broadcasting one’s
location to contacts and gaining recognition for it are now supported by Swarm, an
app where each user interacts only with direct contacts. Swarm supports some new
activities, such as planning outings to particular venues involving contacts, and profile
personalisation by means of digital “stickers” that can be freely added. On Swarm it is
no longer possible for a user to see who else is checked in at a particular venue, unless
one of their contacts is. Activity on both Swarm and Foursquare can also be shared on
other social media platforms, such as Facebook and Twitter.
While usage of the new Foursquare/Swarm platform is yet to be studied in-depth,
human-computer interaction researchers have explored the previous incarnations of
the app for a number of years. Such studies have extended earlier work examining
practices of and motivations for social location sharing (Barkhuus et al., 2008), and
have focused on various aspects of Foursquare usage, notably the types of interactions
that people perform on the app, how users manage their visibility, reputation and
privacy, and how they explore physical spaces in connection with the app. We will
now examine such findings in greater detail.
In their empirical study of checking in behaviour, Lindquist et al. (2011) identified a
set of motivations as to why people decide not only to interact with the app at a
particular venue (e.g. finding the venue on Foursquare, reading content associated to
it), but also to broadcast their presence to their followers (e.g. checking in). First of
all, people check in not only for social motivations, but also for personal ones, such as
keeping an account of their own movements, of the places they visit and how often.
However, the social motivations are more frequent and more articulate. A set relates to
communication and coordination with friends and family: the desire to share personal
information on their life at a distance with contacts, and –in return- to see where
friends have been. Often Foursquare is used as a way to coordinate meetings and
other activities with friends. Another set of motivations relates to the wider
Foursquare community: people enjoy discovering new people frequenting similar
venues to oneself, and reading their tips and recommendations. In some cases people
check in at a venue just before they leave it for safety reasons – leaving a “false trail”
and avoiding potential stalkers. As for the decision regarding which places to check in
at, people make distinctions between routine and non-routine places: some decide not
to check in at routine places because they are seen as boring, and instead checking in
at places that are seen as “special” or “exciting” (e.g. a large event, entertainment
venues, etc.). Others check in at routine places either to gain points on Foursquare or
because they were bored and decided to check in for something to do. Other
considerations are made by users when deciding to check in at private places, such as
a private residence or their own home: there are privacy concerns regarding revealing
such locations, and people often refrain from checking in at somebody’s home in
order to keep its location private. Checking in at one’s own home is often done as a
way to tell friends that they are home safely, or available to receive calls or visits.
Interestingly, privacy concerns also come into play when deciding not to check in at
certain public venues, such as at the doctor’s, at the bank, etc. Moreover, impression
management concerns emerge in these decisions as well: for example deciding not to
check in at a fast food restaurant because it would make a bad impression on friends
and family (Lindquist et al., 2011).
3 http://business.foursquare.com/
3

The aspects of privacy, self-presentation were further explored by Cramer at al. (2011)
who particularly focused on and the performative effects of checking in. They
identified instances of purpose-driven (Tang et al., 2011) motivations (similar to those
detailed by Lindquist et al. 2011) such as obtaining discounts, discovering new places,
gaming purposes (e.g. gaining a mayorship), as a personal bookmark,
diversion/amusement when bored. Instances of Social-driven (Tang et al., 2011)
check-ins were motivated by networking with friends, endorsing/recommending a
venue to friends, but also wanting to learn about the people who frequent a venue (e.g.
the Mayor) who are unknown to them in real life.
However, Cramer et al. observe how LBSN activity goes beyond the two categories of
purpose-driven and social-driven check-ins (Tang et al., 2011). Their data shows
instances driven, for example, by self-presentation, lifestyle choices and identity. Selfpresentation requires a finer understanding of the audience that a check-in will be
shared with. Furthermore, Cramer et al. examine the perspective of the audience at the
receiving end of check-ins: people saw check-ins from friends as a way to obtain
recommendations on things to do and places to visit, or as a motivation to attend an
event or visit a venue. They were also annoyed by friends who checked in all too
frequently (thus sending repeated notifications to their contacts), and/or without a
clear motivation (Cramer et al., 2011).
Cramer et al. observe how motivations can change for every single instance of check
in (and for each venue), and that certain motivations can sometimes be in conflict
with others: for example, wanting to check in for the purpose of gaining gaming
points might contrast the motivation of not wanting to annoy others with too many
check-in notifications (Cramer et al., 2011).
Guha and Birnholtz (2013) have delved further into the ways in which people think
about location sharing and its effects on how impressions are formed and managed.
They identify a blurring between public and private sphere of life when sharing a
location and viewing a check-in: for example, one’s presence at certain places is
kept private (e.g. the gym) although such places are strictly speaking public. On the
other hand, certain places are private (e.g. a friend’s home), however people make the
decision to check in there and to reveal its location all the same (e.g. there is a party
going on). Such decisions are usually made on the basis of how visible the user thinks
the check in will be: people are careful as to how certain contacts might perceive their
behaviour, and also as to how certain check-ins might create tensions within their
friends network. An example of this is checking into a restaurant in order to claim a
discount but, at the same time, broadcasting to the social circle about being out at a
time when it could be inappropriate.
Tensions might also arise when sharing one’s location could be perceived in different
ways by different groups of contacts (e.g. a friend vs. a parent), and these are often the
reasons behind the social media “regrets” discussed by Patil et al. (2012)
Guha and Birnholtz have also detailed certain “tricks” or “cheats” that people employ
for various purposes when sharing their location through LBSN, such as checking in
at locations where someone is not in order to make a better impression. They call one
phenomenon “check-in transience” linked to the fact that Foursquare displays in its
newsfeed to users only the latest location where their contacts have checked in.
People who don’t want their “real” last check in displayed for too long on their
contacts’ newsfeed will check in somewhere else immediately so that the friends will
see that latter check in (Guha and Birnholtz, 2013).
Overall, participants in Guha and Birnholtz’s study admitted to making judgments on

4

people they do not know well in real life based on their check-ins (e.g. which coffee
shop they visit frequently, etc.), and therefore are very sensitive about how they
themselves present themselves to and are perceived by their network of contacts.
All these studies have highlighted the many privacy concerns surrounding LBSN
interactions. Users tend to be aware of them, particularly regarding residential privacy
(Jin et al., 2012), and decide to risk risky exposure only in particular circumstances.
Other work has shown how publicly available information on Foursquare such as
mayorships and tips can be enough to infer the home city of a user, despite caution in
location sharing (Pontes et al., 2012).
Foursquare public data has also been used as part of other developments, for example
recommendation systems, such as algorithms for predicting which tips will attract
more attention on Foursquare and for supporting the creation of more effective
marketing strategies on LBSN (Vasconcelos et al., 2014), and models combining
cellular data and LBSN activity to infer the types of activities in neighbourhoods and
urban centres and to aid urban planning and management (Noulas et al., 2013).
The findings of this small but in-depth set of studies reveal people’s use of LBSN and
the motivations and strategies behind it. In relation to the issues we are focusing on in
this paper, we have already seen instances of the complex relationship between the
system (its code and other components such as the database logging user-generated
content) and people’s interactions, and how the two shape one another. One example
of this is users being careful about the last location they check in at because it is the
one that the software will keep displaying until a new one is shared. Furthermore, in
our summary we have mentioned examples whereby real-world spaces and places are
physically and socially altered by virtue of LBSN interactions (for example a house
party that people join after seeing their friends’ check-ins).
However, many issues remain to be studied. The playful and game-like aspects of
LBSN platforms and their connection to real-world spaces are yet unexplored,
although other location based social gaming practices have been studied in depth
(O’Hara, 2008; Neustaedter et al. 2013). More crucial to overcome, in our opinion, is
the limited attention that has been paid to the way in which LBSN contribute to the
way places are made, lived and reconfigured. While other technological platforms
have been investigated in terms of how they mediate understanding of and attachment
to real world environments (Farnham et al., 2009; Bentley et al., 2012; Scellato et al.
2011), existing HCI work on LBSN focuses mainly on individual practices, but often
without focusing on the actual locales in relation to which they occur.
It is important to pay attention to the way venues, neighbourhoods and cities are lived
and perceived by virtue of the cloud of digital interactions and data that is tied to
them: do LBSN activities impact on place attachment? Or on the way an area is
discovered, explored and navigated?
We have attempted to address some of these issues in two small-scale studies of
LBSN interactions via Foursquare in Limerick and Sheffield. We will now describe
our empirical explorations and the main findings arising from them.
3. Studying Foursquare Use in Two Cities
The existing studies of Foursquare we have discussed in the previous section
employed a methodology consisting of surveys and interviews. For our study, we have
combined a series of interviews with online observations of social media interactions
on Foursquare.
The most extensive part of our study (comprising of online observations and

5

interviews) has been focused on Limerick, a regional city in the Mid-West of Ireland.
A second part of the study consists of online observations only, and focused on
Foursquare use in Sheffield, a regional city in South Yorkshire (UK).
We conducted on line observation of 15 Limerick venues – every month since
October 2012 and of 10 Sheffield venues every month since December 2012. We
chose similar venues for observation in both cities so that we could compare online
activity at location that held similar purposes. The venues included: public markets,
museums, train and bus stations, public parks, university buildings, cafés, shopping
malls, pubs and restaurants, cinemas, theatres and sporting venues. The observation
consisted of monitoring mayorships and check-ins and the addition of content (photos,
tips, etc.) for each venue. These data were documented through notes and screenshots.
The semi-structured interviews of the Limerick Foursquare users were conducted
between October 2012 and May 2013 and involved 12 participants: 8 interviewees
were based in Limerick, the others coming frequently to the city on business and
pleasure visits. We combined the interviews with on line observation of the accounts
of the participants for 2-week periods.
In their check-ins, our participants expressed support for a new business, shared wi-fi
access details at venues and provided information on how to find hidden gems in the
city. Check-ins also were used to signal personal availability (“I am at work”, “I am in
town”, “I am out of town”). People checked in at certain venues for one-off or
particularly significant happenings (such as performances, conferences, sport events,
etc.), similarly to what has been observed in previous work. However, many of the
users we observed checked in regularly at a familiar place, where the purpose of
checking in was not only broadcasting any exceptional or “exciting” occurrence (e.g.
an event, or an unexpected meeting) that might occur, but also for describing the day’s
mood, or ongoing activities.
Motivations for using Foursquare that emerged from our study echo to a large extent
the findings from previous studies: there are personal motivations as well as social
motivations underlying the decision to check in and provide content. As the
respondents to our interviews included business people in the 40-60 year old age
bracket (whereas the participants in previous studies were mainly university students),
we saw a number of motivations connected to professional activities and not only to
socialization and lifestyle. For example, people checked in to endorse a good venue
for business meetings, as well as for informal get-togethers. Another example is that
checking in at home signals one’s non-availability for work matters. An additional
motivation that we noted in our observations is civic activism: people check in to
broadcast that they are doing something good for their city, encouraging others to join
in.
In answer to our interview questions, participants thus explained their motivations to
check in: “going to places so that I feel I own them”; “when I do check in – I spot
people that I know”, “tell someone I’m up, tell someone I’m moving”.
Our online observations gave us insights on how spaces and places become
represented on LBSN in a way that previous work had not highlighted.
Activities associated to particular venues can be surprising, or provide insights on a
certain space that would not be obvious by looking at the venue description, nor by
visiting that location in real life. For example, in Limerick the Stella Ballroom is
classified on Foursquare as a historic site and not simply as an entertainment venue (it
is now used as bingo hall), and many check-ins refer to the fact that it is currently the
venue for an exhibition on the history of Limerick ballrooms. In Sheffield, many

6

check-ins and tips at the train station refer to socializing, as one of Sheffield’s most
popular pubs is located there and many people check-in at the station, rather than at
the pub venue.
Popular venues attract many check-ins and user-generated content. Their
representation on Foursquare depicts their busy atmosphere. For example, the Milk
Market in Limerick is a hub of LBSN activity on Saturdays (the day the full market is
held), where people check-in as it is “the place to be” on market days, and where
friends tend also to converge. In that case, checking-in is also a way to see if other
friends have arrived yet. Foursquare activity at this location peaks at weekends, thus
the venue’s “cloud” of interactions fluctuates significantly on different days. A similar
example in Sheffield, albeit within a different temporal frame, is the Crucible Theatre:
while attracting a steady flow of LBSN interactions throughout the year mainly by
theatre enthusiasts, it becomes a veritable hub during April when the World Snooker
Championship is held there. Indeed, the majority of tips left by users are updated
during that period and refer to the tournament, rather than to the regular theatrical
season.
Foursquare venues can also collect a trail of banter and “private” messages between
people in the form of a venue tip, for example between regular frequenters battling for
a mayorship. In this case, the tips are used not to provide information for the larger
Foursquare community, but as a way to foster the connection between particular users.
The gaming aspect also gave rise in a “proliferation” of Foursquare venues: as users
could create new venues, an increased granularity can be observed in places where
sub-locations can be identified (for example, a particular platform at the train station)
– created by users in order to be first to check in and obtain points.
Our online observations also gave us insights on the content that users create for
particular venues. Photos have a variety of subjects and purposes: for example, photos
uploaded to the Absolute Hotel in Limerick illustrate events taking place there (such
as conferences and business meetings), food that people recommend to order at the
hotel restaurant, or various corners of the building and the view from it. This content
represents a place from multiple points of view: its structural characteristics, but also
the activities taking place there and the people frequenting it. Photographic content
can also take up a “recommendation” function similar to that of tips (e.g. which food
is particularly good at the hotel’s restaurant).
Our study looked at two different cities and we were thus able to compare Foursquare
interactions in both settings. While there were many similarities between them, some
differences could also be noted. Probably due to the significant difference in
geographical size and size of population between the two cities, in Sheffield (the
larger of the two) the Foursquare user group is much larger than Limerick, however
there appear to be weaker ties between users overall (e.g. number of interactions
between users), with some tight “packs” of friends interacting with each other on
Foursquare but likely knowing each other well in real life. More Sheffield businesses
use LBSN, with venues offering special deals, discounts, freebies, etc. This goes
alongside a more “lifestyle” oriented use of tips, which are mainly directed to a
“general” audience with recommendations for good nights out, etc. The use of
Foursquare in this case is more similar to services such as Tripadvisor mobile and
Yelp. In Limerick, the overall smaller community of Foursquare users translates in
more frequent informal interactions between people (both real-life friends and
strangers).

7

4. Discussion
The insights on Foursquare use from both previous work and from our study that we
have presented pose a number of issues for discussion regarding the relationship
between the system, its users and the locations it connects to.
First of all, there is a complex relationship between how the system is shaped by user
interactions and user-generated content and, conversely, how people’s activities are
mediated and shaped by the system’s functionalities and architecture. When a system
like Foursquare is released, selected functionalities are included in the code and they
shape the practices of the early adopters and trendsetters. Initially, they play by the
rules to see what the new platform can do for them. As the user base diversifies, new
practices appear – not originally intended, but afforded by the code. Users exploiting
the fact that Foursquare displays only the last check-in on friends’ newsfeed by
checking-in at a “safe” venue is an example of this, either in order to emphasize their
visibility at a location that they want others to notice, or to hide their presence
somewhere else. The owners of the system can choose to close loopholes (for
example, by not allowing check-ins at faraway locations 4) or to actually support the
new practices by including them in the next version of the code. Very often,
innovations introduced top-down via new versions of the code are met with resistance
by frequent users, as their current practices are disrupted. These have to go through a
whole new sense-making cycle and appropriate the new version by altering their
practices5.
Not only the activities that the code enables, but how they are enacted is another
aspect that reciprocally shapes interactions: the code is designed for a specific context
and so are the ways that content production is enabled. For example, Foursquare
labels textual contributions as “tips”. However, as Foursquare is trying to move into
the niche market occupied by Yelp, it becomes obvious that Foursquare’s tips are not
actual reviews and couldn’t be used as such. Users leave tips such as the amount in
coins you need for parking in a specific place, menu recommendations such as “Try
the chowder”, which aren’t actual reviews. The field name “tips” instilled a specific
user behaviour – this illustrates how the design choices influence the content
contributed by users.
From a different perspective, Foursquare makes the content generated by its user base
available for new uses through the Foursquare APIs6. All kind of mash-ups have been
created to take advantage of the already generated data. They extend the Foursquare
code and extend the opportunities for interaction. Therefore, there is an interesting
tension between the possibilities and the constraints offered by the platform, from the
point of view of “regulated” use and of appropriation.
As well as the relationship between the users and the platform, there are important
issues to flag regarding the relationship between people and specific places that is
now mediated by LBSN. LBSN such as Foursquare extend some of the possibilities
that real-world locations offer people to link to others, to take advantage of what a
place offers, or to find privacy and quiet. The relationship between a person and a
specific place is made more visible by the encoding of LBSN interaction on a
4 See the practice of “jumping”, where users check in at locations without being physically present, in
order to gain badges that are only available at distant locales (Halegoua et al., 2014).

5 See instances of negative reactions to the Foursquare/Swarm innovation here:
https://www.facebook.com/foursquare/posts/10152042714611073

6 https://developer.foursquare.com/overview/
8

platform such as Foursquare. Furthermore, such relationship is also extended by the
possibility of novel forms of digital interactions, such as sharing recommendations
among strangers. The platform also makes visible a community relationship to a
place, and its importance in an urban environment: examples of this are the Milk
Market on a Saturday, and a rugby game in Thomond Park stadium for Limerick, and
the World Snooker Championship at the Crucible Theatre in April and the December
Christmas Village at the Peace Gardens for Sheffield.
While other researchers emphasized the potential for coordination created by checkins, our findings show that awareness of who else is (or was) in the same public place
is an important element and it is interpreted as a recommendation for the place itself.
Moreover, the digital “buzz” around a venue (many check-ins, many tips and
photographs) is an endorsement of that place’s importance for the community. Users
get a glimpse into their contacts’ favourite places and their trajectories. Awareness of
events going on in the city is another interesting element that is a sort of side-product
of Foursquare.
Through these visible “clouds” of interaction, Foursquare and other LBSN platforms
make navigating an unknown neighbourhood or area less daunting. The code
facilitates the creation of content in the form of Foursquare venues, check-ins, photos
and tips. The Foursquare venues in a city constitute a crowdsourced map of places that most of the times is very different from an official tourist/visitor map. The users’
check-in preferences shape each city’s list of venues that both users and non-users can
consult for finding a good place for a specific purpose: coffee, wi-fi access, etc.
The existence of LBSN such as Foursquare has the potential to change the way people
navigate a city, making new places familiar– particularly if they know that their
friends have been there, and allowing discovery and sharing. Such an overlay over the
physical city is completely invisible to non-users. It can change the perception of a
place radically, just because it is being frequented by friends; their digital traces can
be perceived.
This connects to the issue of “rematerialisation” – of whether the web of digital
interactions enabled by the code can be made visible, or perceivable in real-world
places, either for LBSN non-users or for users by means others than the app. There
are already instances where certain venues’ connection to LBSN is made visible, for
example by displaying signs about Foursquare membership in the physical space.
However, there is much more happening in digital form that is only available to the
app users: being able to see photos, tips and comments, as well as the names of their
Foursquare friends who have checked in there. Check-ins by friends, tips and photos
make a new place feel familiar, allow users to see how it looked like when it was very
crowded, or when a specific event took place, or how a particular dish looked like. We
think it is an important issue to be further developed by human-computer interaction
researchers whether new digital technologies (such as ambient or tangible media)
could be employed to enable some of these interactions in a way that is less confined
to a device (the mobile phone) and more embedded into the materiality of the
environment. Furthermore, this is connected to issues of physicality and
performativity in interaction. The practice of checking in when arriving at a venue is
often frowned upon by some people that happen to accompany a user – as well as
being considered socially unacceptable in certain locations/circumstances. The refined
planning that users conduct in order to make the check-in performance acceptable or
discreet is linked also to their awareness of the visibility of this action to a general
“audience”, beyond one’s social circle (Guha and Birnholtz, 2013). Making check-ins
and other LBSN possible by means of other devices would require careful

9

consideration of aspects of social visibility and acceptability of such practices.
Venues interested in collecting visitor data could be possibly interested to provide a
check-in device at the entrance that would allow automated check in – if this type of
permission is chosen -, or allow check-in by simply approaching the mobile phone to
a physical badge near the entrance or when ordering or paying the bill, in return for
specials (discounts and freebies). More novel solutions could be imagined to provide
tangible ways to conduct such activities or to represent them
5. Conclusions
In this paper we have reflected on people’s interactions with a popular location-based
social media platform – Foursquare – and on how such interactions are entwined with
the code that enables them, with other users, and with the real world spaces and places
that they are linked to. We have presented a summary of findings emerging from an
existing body of human-computer interaction research on Foursquare, and we have
integrated these with the results from a study of Foursquare use that we have
conducted in two cities. In our study, we wished to characterise more the relationship
between LBSN interactions and the city they occur in, so to extend previous work and
to address a gap in human-computer interaction research that is only been partially
filled (Silva et al., 2013). Finally, we have highlighted some issues for further
discussion, particularly on the relationship between the cloud of LBSN interaction and
the real world places they occur in, and on how code enables, shapes and is in turn
shaped by users’ activities and instances of system appropriation. In-depth studies of
other location-based digital activities such as turfing and geocaching and their ties
with the materiality of the city have shed light on such certain digital practices can be
better supported (Neustaedter et al., 2013): deeper understanding of such dynamics in
LBSN can lead to novel contributions in this respect.
References
Barkhuus, L., Brown, B., Bell, M., Sherwood, S., Hall, M., Chalmers, M. (2008), “From Awareness to
Repartee: Sharing Location Within Social Groups”, Proceedings of CHI 2008, ACM Press, 497-506.

Bentley, F., Cramer, H., Hamilton, W., Basapur, S. (2012), “Drawing the city: differing
perceptions of the urban environment”, Proceedings of CHI 2012, New York: ACM

Cramer, H., Rost, M. and Holmquist, L.E. (2011), “Performing a check-in: emerging practices, norms
and ‘conflicts’ in location-sharing using Foursquare”, Proceedings of MobileHCI 2011, New York:
ACM
Eagle, N. and Pentland, A. (2005), “Social Serendipity: Mobilizing Social Software”, IEEE Pervasive
Computing, 4(2), 2005. 28-34.
Farnham, S. D., McCarthy, J.F., Patel, Y., Ahuja, S., Norman, D., Hazlewood, W.R., Lind, J. (2009),
“Measuring the impact of third place attachment on the adoption of a place-based community
technology”, Proceedings of CHI 2009, New York: ACM

Guha, S., Birnholtz, J. (2013), “Can you see me now?: Location, visibility and the management of
impressions on Foursquare”, Proceedings of Mobile HCI 2013, New York: ACM

10

Halegoua, G., Leavitt, A. and Gray, M. (2014), “Jumping for fun? Negotiating Mobility and the
Geopolitics of Foursquare”, International Communication Association Annual Meeting, Phoenix AZ,
July 2014, http://citation.allacademic.com/meta/p555003_index.html
Jin, L., Long, X., Joshi, J.B.D. (2012), “Towards understanding residential privacy by analyzing users’
activities in Foursquare”, Proceedings of BADGERS’12, New York: ACM
Lindquist, J., Cranshaw, J., Wiese, J., Hong, J. and Zimmerman, J. (2011), “I'm the mayor of my house:
examining why people use Foursquare - a social-driven location sharing application”, Proceedings of
CHI 2011, New York: ACM

Neustaedter, C., Tang, A. and Judge, T.K. (2013), “Creating scalable location-based games: lessons
from
Geocaching”,
Personal
and
Ubiquitous
Computing,
Vol
17,
Issue
2,
http://link.springer.com/article/10.1007%2Fs00779-011-0497-7

Noulas, A., Mascolo, C. and Frias-Martinez, E. (2013), “Exploiting Foursquare and Cellular Data to
Infer User Activity in Urban Environments”, Proceedings of MDM 2013, IEEE 14th Int. Conference on
Mobile Data Management

O’Hara, K. (2008), “Understanding geocaching practices and motivations”, Proceedings of CHI 2008,
New York: ACM

Patil, S., Norcie, G., Kapadia, A. and Lee, J.A. (2012), “Reasons, rewards, regrets: privacy
considerations in location sharing as an interactive practice”, Proceedings of SOUPS 2012.

Pontes, T., Vasconcelos, M., Almeida, J., Kumaraguru, P., Almeida, V. (2012), “We know where you
live: privacy characterization of foursquare behavior”, Proceedings of UbiComp 2012, New York:
ACM
Scellato, S., Noulas, A., Lambiotte, R., Mascolo, C. (2011), “Socio-spatial Properties of Online
Location-based Social Networks”, in Proceedings of ICWSM’11.
Silva, T.H., Vaz de Melo, P.O.S., Almeida, J.M., Salles, J., Loureiro, A.A.F. (2013), “A comparison of
Foursquare and Instagram to the study of city dynamics and urban social behavior”, Proceedings of
UrbComp 2013.
Tang, K., Lin, J., Hong, J., Siewiorek, D. and Sadeh, N. (2010), “Rethinking Location Sharing:
Exploring the Implications of Social-Driven vs. Purpose-Driven Location Sharing”, in Proceedings of
UbiComp’10, ACM Press (2010), 85-94.
Vasconcelos, M., Almeida, J. and Conçalves (2014), “What makes your opinion popular?: Predicting
the popularity of micro-reviews in Foursquare”, Proceedings of SAC 2014, the 29th Annual ACM
Symposium on Applied Computing.

11

Feeling place in the city: strange ontologies, Foursquare
and location-based social media
Leighton Evans, National University of Ireland Maynooth
Certain instances of the use of location-based social media in cities can
result in deep understandings of novel locations. The contributions of
other users and the information pushed to users when in particular locales
can help users rapidly attune themselves to places and achieve an
understanding of the place. The use of a computational device and
location-based social networking to achieve this understanding indicates
an alteration in the achievement of placehood using computational
technology. Practices and methods of understanding place can, in some
situations, be delegated to the device and application. This paper explores
how the moment that place is appreciated as place (that is, as a
meaningful existential locale) can be reconciled with the delegation of the
epistemologies of placehood to a computational device and location-based
social media application. Drawing on data from an ethnographic study of
Foursquare users, the phenomenological appreciation of place is
understood as co-constituent between the device, application and the
mood of the user. Code and computational devices are contextualised as a
constant foregrounding presence in the city, and the engagement of the
user, device, code and data in understanding place is a moment of
revealing that is co-constituent of all these elements. This exploratory
paper engages Peter Sloterdijk’s theory of spheres as a framework to
understand how these four elements interact, and how that interaction of
elements can orient a user to a revealing of the city that can be
understood as a phenomenological revealing of place.

Introduction: code as a presence in the city
This paper is an exploration of how code is a part of the life of people in the city.
In exploring this, the case study used will be of a narrow, yet important and
illustrative, example of how code is important in discovering and understanding
cities. Modern cities are infused with code, and the operations of systems and
governance are dependent upon code. Dodge and Kitchin (2012: 22) describe
the operations of software as bound up in, contributing to and altering the
conditions through which society, space, time and spatiality are produced. The
ultimate result of this process is the creation of code/spaces, where the software
and spatiality of everyday life become co-constitutive. Arguments that software
is shaping societal relations and economic processes (Thrift and French, 2002)
and altering the nature of governance of the city (Graham, 2005) are obviously
important in considering the modern, smart city. The view of the city as a site of
urban informatics (Thrift, 2014: 1263) the logical outcome of a view of the city as
1

not only constituted by co-existing software and code, but also of a city that is
made up of sensors and devices designed to capture information and relay
governance through operations of algorithms and code (see Greenfield, 2013;
Batty, 2013).
Accounts of governance of the city do not necessarily account for is the everyday
mundane nature of technology, code and software (Thrift, 2014: 1264). People
adopt technology as part of their everyday practices and adapt to them; digital
computational technologies differ from traditional, modern technology is in their
functioning through the execution of code and algorithms, beyond the
circumspection of the user of the technology. This “withdrawal” of the functioning
of code can be understood as a ‘vicarious causation’ (Berry 2011: 153) that
encapsulates the way the world is presented through devices. The process of
understanding the world is necessarily vicarious through the way that those
devices are continually emerging and withdrawing as the computational device
itself has an internal hidden state through code. Berry (2011: 152) uses the term
‘computational image’ to describe the cultural technique used to select, store,
process and produce the data for the process of computation from the world, and
which is then presented back to the user. This process must necessarily involve a
translation from the physical to the computational (as Dodge and Kitchin term
transduction), and a translation from code to human interfaces. It is the influence
of the latter that this chapter will concentrate upon with reference specifically to
location-based social networking (LBSN). The focus is on how this kind of
application, on smartphones that are sophisticated computational devices,
involve an interaction with code that shapes the experience of place for the user
in the modern city.
The mundane, modern world is one characterised by the increasing presence of
computational technology in everyday life created a common doxa of the world
as deeply computational. This computationality is a function of the code that
operates as part of the functioning of computational device. Code is withdrawn
from conscious experience, but is not fully withdrawn in the sense that it has no
part to play in the co-creation of understanding the world. Previous technology
(for example, second-generation mobile phones, non-networked PC's and
televisions) was exemplified by broadcasting one way, at the user without input
from the user. Berry (2011: 146) argues that we live in the midst of technological

2

devices and these devices become embedded in our way-of-being; a
computational mode of being emerges which informs the understanding of the
world that we have in this milieu. New social ontologies and computational social
epistemologies (Berry, 2012: 381) are dependent on code, as code is critical to
the functioning of the computational devices that are used in the world.
Understanding code in this way is important due to the rise in ubiquitous
computational technologies for mediated interaction with the physical
environment. This embodied interaction with computers centres around “the
creation, manipulation and sharing of meaning through engaged interaction with
artefacts” (Dourish 2001). Tangible computing is allied to social computing
(social networking) and location-services embedded in tangible devices, with
activity using these devices resulting in the production of an embodied agent:
intelligent agents that interact with the environment through a physical or virtual
body within that environment. Mackenzie (2010) develops a similar line of
thinking in discussing the phenomenon of wirelessness, arguing that the
continual engagement with computational devices and gadgets leads to a
tendency to make network connections at all times in the current networked
world. This tendency is an embodiment of an attunement to computational
devices and gadgets that provide information to users and indicates an
awareness of network connections as a fundamental part of living in a world with
a proliferation of computational devices. Mackenzie’s work links the
phenomenological approach with studies and theories of urban space and
cartography that emphasise the growing importance and influence of
computational devices in modern cities and how these devices alter and mediate
the experience of space. For example, Dodge and Kitchin (2011) emphasise the
importance of computer code in the production of urban spaces; Shepard (2011)
argues that increasingly the “dataclouds of the 21 st century” shape experience of
the city; and Gordon (2008; 2011) uses the concept of networked locality to
show how particular usage of networked devices and the information they can
provide from de-localised storage can increase nearness to places rather than
increase distance in a phenomenological sense.
Other work has explored the use of LBSN from an explicitly phenomenological
position (see Evans, 2014), but accepting that the devices that we carry are
involved in both embodied and hermeneutic relations with the user (Ihde, 1990)
and are also in a position of alterity as their functioning and execution of code
3

(see Evans, 2014a for a discussion of the execution of code in LBSN), this chapter
is aiming to conceptualise what role code has in shaping understanding of place
for the user of a computational device as they are in the modern city. This
partially immaterial and withdrawn collection of instructions, algorithms and
commands plays a critical role in how users experience the world, yet users
move in and out of contact with code and enjoy a relationship with code that is
vicarious and beyond circumspection. By engaging Peter Sloterijk’s theory of
spheres to conceptualise the presence of code in the modern city, this chapter
aims to contribute to the debates on the interaction of code and users of devices.
A framework for explaining both the presence of code in the city and its
importance in gaining understanding and sociality in the city will be drawn from
an exposition of Sloterdijk’s Spharen, and this framework will be exemplified
using ethnographic data from a critical case study on the LBSN Foursquare. The
examples used will be indicative of users engaging with devices, code, data and
social media to establish a familiarity and phenomenological feeling of place in
novel environments. The "worlding" of users by code, accessible through
devices, is therefore positioned as a key element in the worlding of the user
(Heidegger, 1962) and as a critical aspect of the post-phenomenology of being in
the smart city.
Sloterdijk: Spheres, Bubbles, Foam and Code
Sloterdijk's Spharen project can be seen as a trilogy of works that answers the
question "where is man?" rather than "what is man?" (Schinkel and NoordegraafEelens, 2011: 11), as an engagement in a Heideggerian project concerning the
nature of being in relation to place rather than time (Elden and Mendieta, 2009:
6). Like Heidegger, Sloterdijk makes much of the thrownness of man into the
world, through the negative gynaecology (Sloterdijk, 1998: 275) of being cast
from the womb into the world. This thrownness or not being comfortable in the
world makes man a restless creature that is always and remaking worlds,
fashioning dwellings and dwelling as a phenomenological being in the world
through connection with the Other (Elden and Mendieta, 2009: 7). Essentially,
man is always looking to normalise its spatial existence and find comfort (van
Tuinen, 2007: 299). The project establishes being-in-the-world as being-inspheres, in that being is always spatial and social (in that it is always being-with).
The concept of the sphere refers to the "da-" of Heidegger's Dasein in that it
4

refers to "there", man being in spaces that are opened up by presence and which
are given form, substance, extension, duration and meaning by man "beingthere". For Sloterdijk, spheres are "the original product of human beingtogether", in other words shared spaces of perception and experience.
Sloterdijk's project moves from micro-spheres (or bubbles), which are the most
intimate spheres of co-existence such as the intra-uteral relationship between
unborn child and mother, to the macro-sphere level of globes and to the
globalised level of foam. It is the last type of spherical relationship, foam, that is
of interest when considering the worlding of humans using code, but an
understanding of this is dependent upon an understanding of the levels of sphere
that precede this as the development of the globalised foam is contingent and
resultant from the development of other spheres in human history.
A sphere is a shared psycho-spatial immunological edifice (Schinkel and
Noordegraaf-Eelens, 2011: 13). In simpler terms, a sphere is a shared, lived in
space and a way to conceptualise social life as consisting of the continual
building up and leaving of spatial connectives, from the basic dyad to the
complex swarm of people. Sloterdijk's historical project traces the development
of these spheres from the micro-level of the interpersonal, to the macro-level of
the globe and terrestrial conquest to the multiplicity of simultaneous connections
that overcome spatial and temporal barriers in the globalised, "foam" sphere.
The "where" conceptualised is a protective sphere that can be virtual, but is
nevertheless always meaningful and reassuring as a place distinguished from the
infinite and fragmentary world (Schinkel and Noordegraaf-Eelens, 2011: 22). This
spherical topos draws attention to where people live, act, practice their everyday
habits and activities and indeed are. This is never a static place, with selfdefining borders and measures nor is it static place in the sense of being
boundless and without measure - it is a dynamic, changing place where one
moves from sphere to sphere as the meaning and intention of life changes.
Societies themselves consist of these "turbulent and asymmetrical associations
of space-multiplicities" or spheres (Sloterdijk, 2004: 57).
The spheres are therefore what being-in-the-world structurally is, in that the
sphere is being-with. Elden (2012: 8) reiterates that the spheres of being-with
come in different sizes, from the dyadic bubbles (micro-spherology), to globes
(macro-spherology) that and the plural-spherology of the foam. The latter is "an
5

interlocking and multiple set of cells" that are representative of connection and
relation. Klausner (in Elden, 2012: 8) identifies four attributes of foam: it is made
up of variable shapes and sizes; it lacks a clear centre; it is both fragile and
interconnected; and part of a process of creation. Foam then is a metaphorical
attempt to conceptualise the ever changing places of being-in-the-world, from
the smaller, more intimate to the networked and globalised. Foam is not centred
on the person; it is a place that is characterised by particular connections, or
being-with. These connections are not just fragile in that they are nonpermanent, but necessarily fragile as the sphere is creative and old connections
(and therefore old bubbles) are constantly being replaced by the new in foam.
Elden (2012: 8) rightly draws parallels between this view and Deleuze and
Guattari's concept of the rhizome, but unlike the rhizome foams are loosely
structured and not reducible to complex arrangements and networks. Foams are
made of bubbles that are connected but always separate. Sloterdijk's bubbles
therefore enter a process of osmotic integration with other bubbles, and this
multitude of bubbles (enabled by networked communications as well as physical
proximity) makes up the foam. Importantly, the bubbles are both connected and
isolated. This kind of vicarious connection indicates that while the bubble is
connected to others it is not reducible to its connections, and therefore is not just
a node brought into being by virtue of a network of connections and extinguished
accordingly at the dissolution of that network.
The mit-sein that is a bubble is always being-among-others, a kind of dwelling
and always a dwelling among others. Like Heidegger's concept of dwelling as a
freedom from the world of Das Man and a technologically enframed mode of
being, Sloterdijk's dwelling is a worlding and bringing-forth of the world rather
than a standing-forth or Bestand that is forced upon man. As Morin (2009: 58)
argues, this is an attempt to theorise contemporary society through a reworking
of Heidegger’s existential analytic of Dasein, and draws on a detailed narrative of
the historical development of humankind and human society to reach this aim.
Sloterdijk interprets the development of humanity as a development of different
forms of spatiality and different ways of understanding and using space. The
move from micro-sphere to plural-sphere is a move that is from strong, close
relationship to weaker, looser ties facilitated by the technological milieu that
allows for such ties to exist. The stage of foam is contingent upon the microspheres of bubbles and macro-spheres of globes (representations of the global as
6

an ontological and epistemological attempt to normalise and conceptualise
space through homogenization) and deliberately goes beyond Heidegger’s own
analysis of technology as Gestell or standing reserve. Indeed, that analysis is
akin to the second phase of spheres, the globes or terrestrial globalisation as a
worldview based on the positioning of the world as a resource to be used. The
third phase of foam addresses the modern thinking and calculative assessment
associated with networked society (Morin, 2009: 59).
In order to understand the relevance of Sloterdijk to understanding place through
LBSN, it is necessary to trace what kinds of world-forming praxis “global foams”
allow for and allow to the be conceived (Morin, 2009: 60). Foams are processes
that lend themselves to stability and inclusiveness (Sloterdijk, 2004: 50). With
regards to the social, the basic component of the social is the dyadic sphere, and
the social itself is composed of inter-subjective relations between autonomous
subjects. The human never exists alone, but only in the world of co-subjectivity
where the human is animated by the presence and gaze of others (Laermans,
2011: 115). The social is effectively a product of the reality where humans only
share the walls that separate well-equipped "ego-spheres" from one another
(Sloterdijk, 2004: 501). The possibility and realisation of this co-existence is
possible through the communication networks that link people to known and
unknown others (Laermans, 2011: 116). Contemporary individualism in the age
of social media is a twist to co-existence. The individual splits itself into an actual
self and a virtual or potential self which results in an endless internal dialogue
between these two selves as well as connections to others (Laermans, 2011:
116). Society itself is conceived as aggregate of microspheres (Sloterdijk, 2004:
59) where each bubble is a “world”, an intimate space that has its own
importance and significance. Each world is simultaneously linked to all other
worlds, but also separated by flexible boundaries that create an overall situation
of co-existence and co-isolation (Sloterdijk, 2009: 255). The whole is not
independent of the smaller parts, but the world view given here is unstable and
chaotic (ten Bos, 2009: 85) where a comfortable existence is always threatened
and needs to be remade through new connections as connections between
bubbles change continually affecting the foam.
With regards to everyday praxis, one can consider the use of media and
computational devices as praxis of world making and sphere creation. Traditional
7

broadcast media produce a constantly renewed and fleeting cohesion-effect
through the production of common news themes and common interests
(Laermans, 2011: 117). Mass media communications arouse temporary interests
that produce an affective involvement in the topic, and which are therefore
responsible for the construction of spheres. Thus, media produces instant
cohesion through a bombarding of the "foam" bubbles that make up
contemporary society (Laermans, 2011: 118). This mass media information is not
stored, but simultaneously produced and used up in its reception, and while
there is a surplus of information in modern society there is still a process of
making and reproducing to attract and sustain attention (Laermans, 2011: 120).
The mass media has power through the centralised position and ability to
synchronise the attention of many individuals and other "ego-spheres"
(Laermans, 2011: 126) thus creating a common sphere of interest or attention.
However, the digital and social media environment lacks this cohesion. Merrin
(2014) contextualises the presence of digital computational devices or gadgets
within a rise of hyper-ludic media – hyperfunctional gadgets that are closely
related to me-dia (media streams and production centred on the individual) and
away from traditional broadcast media. This kind of media therefore allows for a
highly personal media experience that is dependent on the execution of code
and contributes to the subjective experience of the world of the user. When
considering social media and the devices used to connect to these platforms, the
common sphere is the medium, but the messages on platforms such as Twitter
are more numerous, diverse, personalised and fragmentary that on any
broadcast medium and reliant on code to function. In a society that is saturated
with mediation messages are left fishing for attention in an attention economy
and media landscape. In considering the impact of social media and LBSN
specifically it is the notion of attentiveness or mindfulness that is critical. The
media messages (posts, tips, tweets) that create attention in the user create a
"bubble" of attention from the foam of countless media messages carried
through digital media. In this praxis of social media use as a worlding, place and
location are a determiner of attention that allows for the reception and engaging
with particular media messages provided by other users. Hence, LBSN harness
social gazetteers, location information and personal relevance data for users
through the execution of code in a place to present the world in a particular form.
For the remainder of this chapter, the notion of place-specific messages being
8

critical to forming Sloterdijk's bubbles of dwelling in foam will be explored with
reference to the use of the LBSN Foursquare.
Code in praxis: Foursquare and understanding place
The following analysis draws on an ethnographic study – conducted in 2011 and
2012 using mixed methods including online surveys, face-to-face interviews,
Skype interviews and email interviews – of 65 users of the LBSN Foursquare.
There was a dual purpose for this ethnography: firstly, to investigate what
Foursquare was being used for, that is what were the practices of use that users
were actually engaging in; secondly, what effect on the understanding of place
did the practices of use of Foursquare have for the users, and how could this be
conceptually related to and analysed through a phenomenological framework. A
hermeneutic phenomenological analysis (Van Manen, 1997) as a derivative
analytic method from critical discourse analysis (Fairclough, 1995) was employed
to analyse the data with regards to how usage affected an understanding of
place for the user. Some brief excerpts are used here to exemplify the formation
of world-revealing bubbles in the use of the LBSN.
Foursquare as a social media application allows users to make check-ins to
places within its database of places, create check-in spots and explore areas by
virtue of the check-ins and comments on places made by other users. The
following is an example of familiarising oneself with an unfamiliar place through
the application:
In specific circumstances the service has made me aware of places around
me. The majority of check-ins I make are for places I already know, but
there are a few times when I have used Foursquare to find new places. For
example, I had to meet some people at a pub in Cheltenham, which I had
not been to previously. Using the postcode to find the area on GPS, I then
used Foursquare when I had parked the car to navigate to the pub. In York,
I used Foursquare to find a pub that was showing a football match I
wanted to see by looking for pubs and tips, and then using the map
facility. When in places that I don’t know unquestionably Foursquare has
helped make me more aware of places ("James", Foursquare User).
"James" has used the LBSN to find places, and to locate themselves relative to
those places. The definition of place being used here, in conjunction with
Sloterdijk’s concept of the bubble is a place that is meaningful for the user as
they dwell in that place. This requires an establishment of the meaning of that
9

place based on the relations the user has to things in that place. Here, the user is
employing the LBSN to locate and ground themselves in that locale, transforming
the meaningless space of unfamiliarity with the place of familiarity based on the
function of code to provide local information and information contained in the
database of the LBSN. The user is creating a bubble from the information
available through Foursquare and then inhabiting this space created.
There is evidence that the device can, through the provision of data on place
encoded in the databanks of the LBSN, replace learned processes of finding one’s
way in the world and navigating places. Being without the device creates a
feeling of homelessness or an inability to dwell:
Being deprived of this extra sense wouldn't affect my desire or ability but
would perhaps make me feel "underpowered" perhaps in a similar way
that a heavy cold affects people's sense of taste or smell - they still eat,
but don't enjoy it as much. It feels an enhancement of my own
capabilities, extending my knowledge about my immediate environs. Even
aside from Foursquare, the GPS and map functionality seem to add an
extra sense. The GPS abilities of my iPhone do indeed feel like an extra
sense; perhaps not one as important as seeing or hearing, but definitely
on a par with smell or taste. ("Lars", Foursquare user).
"Lars" identifies the device as an augmentation and enhancement of his senses,
heightening understanding of the world when used and being conspicuous in
absence. The device is not a sensory replacement, but an addition to the existing
means of collecting information about the world that is the foundation of
understanding. In navigating the media saturated world, the device is a
necessity and therefore the code that allows it to function is too. The device is in
effect a gateway to the foam that is necessary to create the buddle of dwelling.
Additionally, the user considers the device to be doing some of the work of
being-in-the-world. The following comment is also useful in this context:
When I drive down the road with my phone docked, I see that little blue
and white dot on the screen. I realize that's me, and I see all the cars
around me, and realize they have dots too. I'm just another face in the
world. I suppose programs that are aware of where I am has given me a bit
of a drive to explore this big world. I have a guide that I can fall back on,
and that lets me go out and explore a bit more. I mean, what's that
strange landmark on 4sq called Stabber's Alley? Just how dark and
foreboding is it? Better go see during the day. ("Kirk", Foursquare user).
"Kirk" identifies with the device, and the denotation of the device on the digital
10

map (the “blue dot”) as himself, so the distinction between user and device
withdraws in use (as per Heidegger’s tool analysis; Heidegger 1962: 406-412).
The user extrapolates their own experience and position in the world relative to
the device to others by identifying other people as dots in line with the
withdrawal of the distinction between device and user in their own experience.
The device, which is doing the work of locating oneself in the world in this
instance, is not considered separately as an entity. In the Sloterdijk-influenced
analysis proposed here, the device and user co-exist in the bubble that is the
experience of place. The experience of the device as one with the user –
withdrawn when used as a tool – is one of absence, but as the device is
continually updating, representing the world as one moves through the world
physically, it is becoming present, demanding attention and thinking. The device
is something that links with other things (servers, databases, other devices)
beyond the conscious experience and is continually feeding back to the user.
Ihde (1990: 86) explains this as the hermeneutic relation between technology
and human where the technology acts as an immediate referent to something
beyond that device. While the focus of the user is on the device and interface,
the user’s experience is not with the device itself but the world that it is referring
to and the landscape suggested by the gazetteers. In this case the device
withdraws (while still preforming the work it is tasked with in revealing the world)
to become part of the world. This is reinforced by this comment:
I think my view of the world has changed by using these services – or at
least how I view the world. When visiting new places I used to stick to
small areas, which I could achieve familiarity with quite easily, whereas
now using location-based services means that I can use the device with
confidence to locate myself and familiarize myself with the place. I am
aware that there is a contradiction in that, in that I am only familiarizing
myself with the representation of the place from the service, and so there
is a tension between familiarity with place and service – and in considering
how I see the world, I suppose I am seeing it more through the device than
through exploring it physically. ("James", Foursquare User).
"James" is aware that he familiarises himself with the device, interface and
service, and that the result of this is a familiarity as place that is dependent upon
the device and software. The nature of the tool – what it does – as a navigational
tool, as something to guide the user through the world, is clear. The real time
information is given unobtrusively and so the device is always ready-to-hand
(continuing its presence as a co-constructing element in the understanding and
revealing of place) and always operational and ready to disrupt with information.
11

The device is never fully withdrawn as it interacts with the foam that is the code
and networked information the device accesses. The co-presence of the code in
the "bubble" shapes this understanding of world.
Continual information given in real-time by the device affects understanding of
the world, and changes orientation to the world in a practical way for place and
location:
Suddenly the ability to ask for directions is lost! In the past I’d often end
up wandering around new places relatively aimlessly but it was just as
good as going somewhere specific because that kind of wandering can
lead to making new discoveries. If you are headed in a very specific
direction with a very clear aim, you might risk missing things along the
way, which is a shame. ("Joan", Foursquare User).
With the device (assuming connectivity is a given) the existential possibility of
being lost is reduced, and if the technological conditions are optimal then being
lost could be something that is technologically not possible. The chance
discovery, the valuable new place found, the orienting oneself in the unfamiliar
place that leads to a new familiarity and the creation of an existential locale
through orienting oneself to the objects and entities in the new locale are
replaced by computational co-existence. The feeling of place is dependent on the
device as being lost or “placeless” is not a possibility if one has taken the device
into car as a part of the average everydayness of navigating the world. If this has
been done, then place as a familiar existential locale is always possible through
the use of the device as a co-constructor of the sense of place in the world. As
such, the bubbles that we dwell in according to Sloterdijk can always be created
if one is enabled to access that information through code in the foam, but the
bubble of worldly familiarity and place may not need another person at all.
Conclusions
The examples taken from the ethnography of Foursquare users illustrate an
understanding of the networked world where code, data and information inform
the everyday understanding of place. Although this paper has used a relatively
narrow illustration of this, this information may come from the plethora of
screens and screenic technologies in the modern city, other social media
platforms or traditional media. The dwelling in bubbles in the modern, networked
world through the use of mobile computational devices and applications occurs
12

as those applications (through the execution of code in devices and through
network connections) provide people with information that is used in the
everyday practices of life. Code is an actor in the functioning of these critical
elements (application, device); without the functioning of code these bubbles
would not exist.
In the modern, networked world code, as a withdrawn actor in the functioning of
devices, is necessary to the possibility and actuality of the creation of some of
what Sloterdijk calls bubbles. In a place where networked connectivity is
possible, the feeling of place can be achieved through the use of applications
that inform on place: giving information, relative location and cues and
information from others that provides a social dimension to the praxis (a beingwith or bubble). Code, in this view, acts as a membrane that allows for flows of
data, information and social activity through the foam and into bubbles. Code is
the membrane that allows for the information that characterises the networked
society to flow and influence. The presence of code therefore foregrounds our
presence in modern world, affording the possibilities of dwelling and
understanding while being withdrawn and opaque to the users of computational
devices. Code links foam and bubble and the understanding of the modern world
in inexorably linked to its presence.
Heidegger's great fear of technology was the flattening effect that occurs
through the use of modern technology: the erasing of temporal and spatial
dimensions of being leading to a worldview where the overcoming of these
conditions frames all entities as resource to be used. The view of networked
behaviour in this paper illustrates a de-distancing (van Tuinen, 2009: 111) that
comes from the use of code-dependent devices and applications to understand
places. Users may pick up information left many years before by users they will
never meet, and use this to establish a dwelling in place. The de-distancing that
occurs is not seen as a danger but as a condition of the loose and fragile
connections of bubbles that make up the plural-spherology of modern life. Place
and the feeling of place is, in these examples, a co-constituent between the
device, application and the mood of the user in the bubble that has been created
through digital and computational praxis.
References
13

Batty M (2013) The New Science of Cities, MIT Press, Cambridge, MA
Berry DM (2011) The Philosophy of Software: Code and Mediation in the Digital
Age. London: Palgrave/Macmillan.
Berry DM (2012) The Social Epistemology of Software, Social Epistemology, 26
(3-4)
Dodge M and Kitchin R (2011) Code/Space: Software and Everyday
Life. Cambridge MA: MIT Press.
Dourish P (2001) Where the Action Is: The Foundations of Embodied Interaction.
Cambridge: MIT Press.
Elden S, Mendieta E (2009) Being-with as making worlds: the ‘second coming’ of
Peter Sloterdijk, Environment and Planning D: Society and Space 27(1)
1 – 11.
Elden S (2012) Worlds, Temperaments, Engagements: Introducing Peter Sloterdijk, in
Stuart Elden (ed.), Sloterdijk Now, Cambridge: Polity, pp. 1-16.
Evans L (2014) Being-Towards the Social: Mood and Orientation to location-based

social media, computational things and applications, New Media and
Society, 21/01/2014.
Evans L (2014a) Maps as Deep: Reading the Code of location-based social
networks, IEEE Technology and Science Magazine, 33 (1), pp.73-80.
Gordon E (2008) Towards a theory of Networked Locality. First Monday 13 (10)
6/10/2008.
http://www.firstmonday.org/htbin/cgiwrap/bin/ojs/index.php/fm/article/view
/2157/2035. Retrieved 01/07/2012.
Gordon E and de Souza e Silva A (2011) Net Locality: Why Location Matters in a
Networked World. Chichester: Wiley-Blackwell.
Greenfield A (2013) Against the Smart City (The City is Here for You to Use),
Verso, London
Heidegger M (1962) Being and Time (Trans. J. Macquarrie and E. Robinson).
Oxford: Blackwell.
Heidegger M (1977) The Question Concerning Technology, and Other Essays
(Trans. W. Lovitt). New York: Harper Perennial.
Ihde D (1990) Technology and the Lifeworld: From garden to earth, Bloomington
and Indianopolis: Indiana University Press.
Laermans R (2011) The Attention Regime: On Mass Media and the Information
Society. In In Media Res:Peter Sloterdijk's Spherical Poetics of Being,
Amsterdam: Amsterdam University Press, 2011, pp. 115-133.
Mackenzie A (2010) Wirelessness: Radical Empiricism in Networked Cultures.
Cambridge, Mass.: MIT Press.
Merrin W (2014) The Rise of the Gadget and Hyperludic Me-Dia, Cultural Politics,
10 (1), pp.1-20.
Morin M-E (2009) Cohabitating in the globalised world: Peter Sloterdijk’s global
14

foams and Bruno Latour’s cosmopolitics, Environment and Planning D:
Society and Space 27(1) 58 – 72
Schinkel W and Noordegraaf-Eelens L (2011) Peter Sloterdijk's Spherological
Acrobatics: An Exercise in Introduction. In In Media Res:Peter Sloterdijk's
Spherical Poetics of Being, Amsterdam: Amsterdam University Press, 2011,
pp.7-28.
Shepard M (2011) Sentient City: Ubiquitous Computing, Architecture and the
Future of Urban Space. Cambridge, Mass.: MIT Press.
Sloterdijk P, (1998) Sphären I—Blasen, Mikrosphärologie [Spheres I — Bubbles,
microspherology] (Suhrkamp, Frankfurt am Main)
Sloterdijk P, (1999) Sphären II—Globen, Makrosphärologie [Spheres II — Globes,
macrospherology] (Suhrkamp, Frankfurt am Main)
Sloterdijk P, (2004) Sphären III—Schäume, Plurale Sphärologie [Spheres III—
Bubbles, plural-spherology] (Suhrkamp, Frankfurt am Main)
ten Bos R (2009) Towards an amphibious anthropology: water and Peter
Sloterdijk, Environment and Planning D: Society and Space 27(1) 73 – 86
Thrift N (2014) The Promise of Urban Informatics: some speculations,
Environment and Planning A, 46, pp. 1263-1266.
Thrift N and French S (2002) The Automatic Production of Space. Transactions of
the Institute of British Geographers 27(3): 309-335.
Van Manen M (1997) Researching Lived Experience: Human Science for an action
sensitive pedagogy (2nd ed.). London, Ontario: Althouse press.
van Tuinen S (2009) Air conditioning spaceship earth: Peter Sloterdijk’s ethicoaesthetic paradigm, Environment and Planning D: Society and Space 27(1)
105 – 118.

15

Cultural Curation and Urban Interfaces: Locative Media as
Experimental Platforms for Cultural Data
Nanna Verhoeff, Media and Culture Studies, Utrecht University
(Abstract only, due to late invitation)
My contribution is concerned with the way in which urban interfaces are used for access to cultural
collections – whether institutionally embedded, or bottom-up, participatory collections. Designed in
code and exploring affordances of new location-based and/or mobile technologies for urban spacemaking, these interfaces are thought to be powerful tools for ideals of participatory urban culture. I
propose to approach these “projects” as curatorial machines, as urban experimental laboratories for
cultural data. This entails a threefold perspective, on curation, on code, and on principles of creative
(sometimes artistic or playful) experimentation.
For this, we may remind ourselves of the curatorial project of museal and archival institutions, of
preserving, and “caring” for the object, as well as creating new contexts for the object and providing
access for an urban public – a field which is very much in transition as a result of current ambitions
for new public engagement and ideals of participation, pervasive in all socio-economic and political
regions of contemporary culture. Simultaneously we witness the current interest in the principles of
data curation as the care for, interaction with, interpretation and visualisation of digital data, as the
datafication and codification of culture invades all corners of urban life. Design of interfaces is
central in how we can access, work with, and make meaning with digital culture. Departing from
the concept of dispositif in the analysis of interfaces, I propose to bring together the fact that the
interfaces are coded and designed, to (playfully) experiment with their affordances.
In my approach to this intersection of datafication of, and the proliferation of interfaces for
“culture”, I aim to develop heuristic tools for critical evaluation of this phenomenon, broadly
bracketed as [urban interfaces] as interfaces of cultural curation.

Cities and Context: The Codification of Small Areas through
Geodemographic Classification
Alex Singleton
Department of Geography and Planning, University of Liverpool, UK.
alex.singleton@liverpool.ac.uk

July 8, 2014
Abstract
Geodemographic classifications group small area geography into categories based on shared population
and built environment characteristics. This process of “codification” aims to create a common language
for the description of salient internal structure of places, and by extension, enable their comparison
across geographic contexts. The typological study of areas is not a new phenomenon, and contemporary
geodemographics emerged from research conducted in the 1970s that aimed at providing a new method of
targeting deprivation relief funding within the city of Liverpool. This city level model was later extended
for the national context, and became the antecedent of contemporary geodemographic classification. This
paper explores the origins of geodemographics, to first illustrate that the coding of areas is not just a
contemporary practice; and then extends this discussion to consider how methodological choices influence
classification structure. Being open with such methods is argued as being essential for classifications to
engender greater social responsibility.

Keywords: geodemographics,GIS.

1

Geodemographic Place Coding

Geodemographic analysis continues an extensive history of empirically driven models of urban socio-spatial
structure, extending back to the 1920s and 30s human ecologists and then later, the large body of empirically
driven work producing social area analysis models (Shevky & Williams 1949, Shevky & Bell 1955) for
various urban locations (see Timms (1971, 56)). Representations created through such models attempted to
reduce the complexities of population and built structure into meaningful and simplified typologies, giving
order to multiple attributes about small areas (Abler et al. 1971). Some of the earliest published work
on geodemographics were also described as social area analysis (Webber 1975) and focused on single cities
(in this case, Liverpool, UK). It was only later that geodemographic techniques were expanded, to create
classifications with national coverage (Webber & Craig 1978, Webber 1977). Such geodemographic systems
were presented by Webber (1978) as a methodological solution for handling the highly dimensional 1971 UK
Census:
“What is needed is a solution which will pick out pattern from the detail, without loosing too
much of the original information, and which will admit more detailed examination of parts of the
pattern which become relevant to a particular issue or local area as and when required” Webber
(1978, 275).
Webber (1978) also makes two further points: firstly, that geodemographics provide utility as a method
of performing analysis on sparsely populated census variables which otherwise might su↵er statistical unreliability at the local level. This has contemporary relevance in the context of the US, where the national
census now only represents a limited number of questions, and is supplemented by more uncertain small area
estimates from the American Community Survey (Singleton & Spielman 2013). Secondly, geodemographics
were also argued as a useful framework within which non census indicators could be evaluated over time,
1

and again, would be familiar to contemporary users of geodemographics, with examples of spatial policy
evaluation (Batey et al. 2008) and small area population profiling (Singleton 2010b).
Although this early history concerned analysis in the public sector, during the 1980s geodemographics
were adopted widely by the private sector as a tool for customer segmentation (Sleight 1997), as it was
found that the grouping of areas into clusters showed strong correspondence with the consumption of certain
product categories. This led to numerous commercial classifications being created, however, more recently,
there has been a resurgence of interest in geodemographic applications within the public sector (Longley
2005). Although many geodemographic classifications are commercial, and as such have cost implications,
within the UK, there have been a series of classifications built that correspond to the decennial release of the
1981 (Charlton et al. 1985), 1991(Blake & Openshaw 1995), 2001 (Vickers & Rees 2007) and 2011 Censuses
(ref to be added).
Although of demonstrated utility (Harris et al. 2005, Singleton & Spielman 2013), geodemographics have
been criticized as geographically over simplified (Twigg et al. 2000), or masking of diversity within small
areas (Voas & Williamson 2001). However, there is evidence to suggest that geodemographic classifications
perform well in comparison to more complex statistical models (Brunsdon et al. 2011). In the mid 1990s
there was also extended critique of those negative images place-based marketing initiatives may elicit as part
of a wider critique of GIS (Goss 1995, 2003). Uprichard et al. (2009) more recently raises concerns about the
“automatic production of space” (Thrift & French 2002), through recursive, reiterative and transformative
practices that are embedded within software.
Sociologists (along with numerous other social science discplines) have widely utilized classifications based
on occupation (e.g. in the UK, the National Statistics Socio-Economic Classification –NS-SEC) to code
individuals into occupational class based groupings / hierarchies. However, since the mid 2000s, interest has
grown over the use of contemporary geodemographic classifications as part of research into the spatialization
of class (Parker et al. 2007). Geodemographics have been argued as “emblematic of a significantly changing
relationship between class and status” (Burrows & Gane 2006, 805), and within this context, geodemographics
are seen as usefully encapsulating a wide range of social transactional data that are otherwise of restrictive
access to academia, and additionally, also appearing to be engaging with a “rhetoric of sociological discourse”
(Savage & Burrows 2007, 887), albeit arguably only at the level of cluster description. Other theoretical
work has also made connections between how geodemographics fit within Bourdieu’s field-capital theory
(Tapp & Warren 2010). Most commercial geodemographic classifications are optimized on the basis of
discriminating patterns of consumption (Webber 2007), which have been shown to have similar stratification
by occupational group (Sivadas 1997); and as such, it is perhaps not unsurprising that parallels between
these two classification approaches are drawn, despite their very di↵erent methodology.

2

Subjectivity and Classification Builder Preferences

A geodemographic is created using algorithms that aim to optimize the assignment of small areas into groups
that o↵er the greatest similarity over a typically large set of attributes. However, such representations
are explicitly linked to those methodological decisions taken in their construction. Such choices can be
informed empirically, theoretically and more pragmatically based on the practitioner or collective of industry
experience. As such, the process of geodemographic classification building is regularly described as both art
and science (Harris et al. 2005).
The research presented in this chapter does not attempt to provide an evaluation of geodemographics
relative to other techniques, nor does it aim to provide an exposition about the “best” method of building
a geodemographic, or how this might be assessed. The empirical focus here is to explore how output
geodemographic patterns can be sensitive to changes in methodological approach. Some potential options
that a classification builder might take when building a geodemographic classification are outlined in the
remainder of this section.

2.1

Geographic Extent

The choice of geographic extent impacts how similarity between areas are considered by clustering algorithms.
Geographic extent selection has three impacts: firstly, by altering the statistical distributions of attributes,
for example, the minimum, maximum and average values for each variable will change relative to the selected
2

geographic extent. This alters the shape of the “attribute space” that is searched when a clustering algorithm
is seeking an optimal partitioning of areas into groups. As such, it could be argued that classifications built
for and from data about more localized extents will likely demonstrate greater sensitivity (Openshaw et al.
1980), and some have argued that national classification are not necessarily more complete relative to local
models (Reibel & Regelson 2011). However, to some extent this also reflects a di↵erence of view that
geodemographics are seen as either method (e.g. application of clustering to uncover patterns) or tool (use
of a classification system to illustrate patterns / contexts) (Singleton & Spielman 2013).
The second impact of switching from a national to constrained geographic extent is that the benefits of
appending national surveys onto a classification are lost, unless adequate sample within the restricted extent
can be extracted. Descriptive detail that could be obtained by appending such additional data potentially
impacts the range of possible end user applications. These issues may however be minimized in the future
as greater volumes of open data that can be partitioned into di↵erent geographic extents become available.
Finally, changes from the national extent impact the ability to use geodemographics as a measure for
comparing places, and furthermore, can be expensive to maintain and update, an issue acute for the public
sector (Webber 1980).

2.2

Scale, zones and input variables

The arrangement of areas into geodemographic clusters are impacted by the choice of zonal geography as this
e↵ects the calculation of summary values for input attributes. This is a prescient issue in statistical analysis
involving aggregate geographic data, and is referred to as the modifiable areal unit problem (Openshaw 1984).
Although of concern, Richard Webber, an expert on geodemographics noted “I have yet to come across any
real world example of a conclusion being invalidly reached as a result of this hypothetical possibility” (cited
in de Smith et al. 2009, :133). Nonetheless, sensitivity to this issue is required in selecting an “appropriate”
geography and interpreting results derived at this selected scale. An “appropriate” zonal geography can be
guided by a number of factors such as the availability of data inputs, the intended applications, stability of
patterns over di↵erent scales or other motivations to provide more detailed classifications, such as leveraging
competitive advantage.
Variable choices can be driven by multiple perspectives ranging from theories about what influences sociospatial structure, empirical investigation of attribute influence on cluster formation, and pragmatic choices
based on the experiences of the classification builder or the overarching purpose of the classification (e.g.
general purpose versus bespoke - (see Singleton & Longley 2009a)). Precursors to geodemographics such
a social area analysis (Shevky & Bell 1955) were constructed from a theory about the key drivers of small
area di↵erentiation and change, although, some have argued that these were ex post facto rationalization
of earlier works featuring more ad-hoc choices (Timms 1971). Geodemographics were however established
with a more applied focus. In one of the earliest national classifications Webber & Craig (1978, 6) notes “[a]
general purpose classification should by definition, represent as wide as possible a variety of characteristics
without over representing any particular aspect”. Correlated attributes have a “weighting” e↵ect that gives
greater emphasis to such combined dimensions, thus potentially influencing cluster assignment. Inputs into
this classification were organised around “Dimensions” not dissimilar to those presented in social area analysis
models, and such typology of input attributes have also remained a feature of many present day classifications.
Knowledge about the input variables used to build geodemographics range in degrees of transparency.
For many commercial classifications, the exact specification of inputs will be commercially sensitivive, and as
such, will not typically be fully disclosed (Singleton & Longley 2009b). Conversely, in “open geodemographics”
(Vickers & Rees 2007), a full specification of variables would normally be made, including links to where
these data may be obtained in the public domain. For open geodemographic classifications, transparency
requires that all data be publicly available, and as such, this could also restrict inputs to certain variable
types where licences permit redistribution.
Finally, choice of variables are also related to the selection of scale or extent, given that each of which
impacts whether or not certain attributes would be available to the classification builder, and how they may
be almalagated (e.g. individual versus concatenated age ranges). For example, open data within one context
may not be available in another, or, attributes available more universally, might be restricted in scale for a
target area.

3

2.3

Measurement, weights and transformations

A classification can be built with attributes of numerous measurement types such as rates (e.g. percentages),
averages, ratios, continuous measures (e.g. distance) or relative scores (e.g. index scores). The choice
depends to an extent on the attributes of interest. For example, density would typically be presented as a
ratio of population divided by area, whereas an example of a continuous measure might be the distance of
an area to the coast or other feature of interest. However, the measurement of attributes using either rates
or relative scores are more nuanced. The former relates to the expression of an attribute within an area on a
standard scale, whereas the latter takes a rate for a given attribute, and then compares areas by the extent
these deviate from the national average. Measurement types impact the range of values that an attribute
can hold, for example, percentage scores range between 0 and 100, whereas other measures can hold a wider
range of values, and such di↵erences may alter the shape of output classification.
Historically, managing a large number of attributes when building geodemographic classifications was
more difficult with restricted computing power limitations. Principal component analysis (PCA) was introduced as a method of reducing attribute dimensions (see Webber 1975), and also reducing the impact of
correlated attributes (as PCA by definition comprise linearly uncorrelated variables). As computing power
has increased, the necessity for PCA has been reduced, and given that PCA can remove non linear association between variables emergent within specific geographic contexts, some have argued against the use of
PCA (Harris et al. 2005).
Weights can be added to attributes to increase their importance in a clustering solution, however, the
choice of weights can be considered as subjective, and as such, have been avoided in a number of open
geodemographics (Vickers & Rees 2007). Weighting does however see extensive use in commercial geodemographics, and has also been noted as a method to control unhelpful e↵ects caused by highly skewed or
otherwise problematic attributes (Harris et al. 2005).
Finally, prior to clustering, data standardization is required to ensure that all attributes are measured
on the same scale, and as such, have the same influence on the final cluster solution. However, the exact
methods chosen can either constrain or enhance the impact of outliers. For example, standardization with a
z-score measures how far an attribute score is relative to the mean in standard deviation units, however, this
can accentuate the e↵ect of outliers. Other techniques such as the commonly used range standardization,
redistributes attribute scores onto a fixed scale, typically 0-1, compressing outliers into this range, and
suppressing their impact. Decisions on which techniques are appropriate are framed within classification
builder views on whether they see outliers as an issue to correct, or as an interesting local pattern that is
desirable to influence final cluster assignment. Such decisions will also be guided by practicality, given that
outlier clusters will by definition be small in nature, and this may not be viewed as useful to feature to
appear in a final typology.

2.4

Clustering methods

Clustering algorithms attempt to seek an optimal grouping of areas into clusters by maximizing some measure
of within cluster homogeneity or between cluster heterogeneity. Methods of optimization vary between
clustering approaches, however, choice of algorithm can influence the assignment of areas to into clusters. A
further key decision must be made about how many clusters are desirable in a final solution. Such decisions
are commonly guided by experience (Harris et al. 2005), however, can also be assessed empirically through
analysis of divisions that “fit” the data most e↵ectively. Common techniques include the use of “elbow
criterion” measures (Vickers & Rees 2007) or methods such as silhouette plots (Adnan et al. 2010). A final
consideration is whether the classification is to be hierarchical, and if so, whether these are to be built from
the top down (most aggregate groups first), or bottom up (most disaggregate groups first).

3

Case Study - national versus local geodemographics

In this final section, two geodemographic classifications are compared, illustrating how from the same input
data and methods, two di↵erent assignments of areas into clusters can be created on the basis of adjusting
the geographic extent of the classification boundaries. The 2011 Office for National Statistics Output area

4

Table 1: 2011 Output Area Classification Input Variables
Domain
Demographic

Sub Domain
Age Structure
Family Structure
Ethnicity

Housing

Composition
Type
Tenure

Socio-Economic

Health
Employment
Occupation
Education
Mobility

Variables
Age bands
Marriage; children; dependent children
Ethnic Groups; Spoken English; EU V
New EU
Density; communal establishment; student household; occupancy rating
Detached, semi, terrace, flats
Socially rented; private rented; owned
or shared ownership
Day-to-day activities limited a lot or a
little; standardized illness ratio
Unemployment; full time; part time
Occupation groups
Level 1; Level 2; Level 3; Level 4+
Car ownership; private transport; public transport; active transport

classification (OAC) will be used as the national classification, and the methodology repeated, however for
the localized extent of Liverpool.
The full methodology for OAC 2011 is presented elsewhere (ref to be added). However, in brief: the
input data for OAC are sourced entirely from the 2011 census, and are detailed in Table 1. Variables are
organised around three domains; demographic, housing and socio-economics. These are then divided into a
series of sub-domains comprised of a total of 60 variables. The input variables to OAC are all calculated
as percentages against an appropriate denominator, with the exception of a standardized illness ratio and
population density. Input data were selected on the basis of maintaining similarity to OAC 2001 Vickers &
Rees (2007), but also exploiting some of those new variables added in the 2011 census. Such requirements
were formulated after the outcome of a national consultation exercise delivered by the ONS 1 and extensive
evaluation.
after the 2011 Census data were assembled and the attribute measures calculated, these were first standardized using an inverse hyperbolic sine function that transforms the attributes more closely to a normal
distribution. It can be argued that more normally distributed input attributes assist clustering algorithms
such as k-means given their optimization for finding spherical clusters, although, there is no statistical requirement for the data to be normally distributed, as might be the case with techniques such as regression
analysis. Secondly, prior to clustering, all of the attributes were standardized onto a 0-1 scale using a range
standardization method, thus ensuring that each variable had an equal influence on the clustering result.
The K-means algorithm was then implemented to cluster the UK Output Areas and Small Areas (in Northern Ireland) into 8 initial clusters referred to as Super Groups. The data were then split by these clusters,
and further divided into between 2 and 4 clusters, forming a second level called Groups and comprising 26
clusters in total. A final set of splits created a Sub Group level, comprising a total of 76 clusters. The nested
hierarchy of OAC 2011 is shown in Table 2 and mapped for the UK and Liverpool in Figure 1 and Figure
2. Although the 8 Super Group clusters are visible in the UK map, within Liverpool, only seven clusters are
present, excluding the predominantly rural Super Group “1 - Rural Residents”.

1 Details of the consultation exercise can be found http://www.ons.gov.uk/ons/guide-method/geography/products/
area-classifications/ns-area-classifications/new-uk-output-area-classification/index.html

5

Figure 1: Super Group Level Output Area Classification - UK

6

1 − Rural Residents
2 − Cosmopolitans
3 − Ethnicity Central
4 − Multicultural Metropolitans
5 − Urbanites
6 − Suburbanites
7 − Constrained City Dwellers
8 − Hard−Pressed Living

Figure 2: Super Group Level Output Area Classification - Liverpool

7

Table 2: The 2011 OAC Classification Hierarchy
Super Group
1 - Rural Residents

Group
1a - Farming Communities

1b - Rural Tenants

1c - Ageing Rural Dwellers

2 - Cosmopolitans

2a - Students Around Campus

2b - Inner-City Students
2c - Comfortable Cosmopolitans

2d - Aspiring and Affluent

3 - Ethnicity Central

3a - Ethnic Family Life
3b - Endeavouring Ethnic Mix

3c - Ethnic Dynamics
3d - Aspirational Techies

4 - Multicultural Metropolitans

4a - Rented Family Living

4b - Challenged Asian Terraces
4c - Asian Traits

5 - Urbanites

5a - Urban Professionals and Families

5b - Ageing Urban Living

6 - Suburbanites

6a - Suburban Achievers

6b - Semi-Detached Suburbia

7 - Constrained City Dwellers

7a - Challenged Diversity

7b - Constrained Flat Dwellers

7c - White Communities

7d - Ageing City Dwellers

8 - Hard-Pressed Living

8a - Industrious Communities
8b - Challenged Terraced Workers
8c - Hard-Pressed Ageing Workers

8d - Migration and Churn

Sub Group
1a1 - Rural Workers and Families
1a2 - Established Farming Communities
1a3 - Agricultural Communities
1a4 - Older Farming Communities
1b1 - Rural Life
1b2 - Rural White-Collar Workers
1b3 - Ageing Rural Flat Tenants
1c1 - Rural Employment and Retirees
1c2 - Renting Rural Retirement
1c3 - Detached Rural Retirement
2a1 - Student Communal Living
2a2 - Student Digs
2a3 - Students and Professionals
2b1 - Students and Commuters
2b2 - Multicultural Student Neighbourhoods
2c1 - Migrant Families
2c2 - Migrant Commuters
2c3 - Professional Service Cosmopolitans
2d1 - Urban Cultural Mix
2d2 - EU White-Collar Workers
2d3 - Highly-Qualified Quaternary Workers
3a1 - Established Renting Families
3a2 - Young Families and Students
3b1 - Striving Service Workers
3b2 - Bangladeshi Mixed Employment
3b3 - Multi-Ethnic Professional Service Workers
3c1 - Constrained Neighbourhoods
3c2 - Constrained Commuters
3d1 - Established Tech Workers
3d2 - Old EU Tech Workers
3d3 - New EU Tech Workers
4a1 - Private Renting Young Families
4a2 - Social Renting New Arrivals
4a3 - Commuters with Young Families
4b1 - Asian Terraces and Flats
4b2 - Pakistani Communities
4c1 - Achieving Minorities
4c2 - Multicultural New Arrivals
4c3 - Inner City Ethnic Mix
5a1 - White Professionals
5a2 - Multi-Ethnic Professionals with Families
5a3 - Families in Terraces and Flats
5b1 - Delayed Retirement
5b2 - Communal Retirement
5b3 - Self-Sufficient Retirement
6a1 - Indian Tech Achievers
6a2 - Comfortable Suburbia
6a3 - Detached Retirement Living
6a4 - Ageing in Suburbia
6b1 - Multi-Ethnic Suburbia
6b2 - White Suburban Communities
6b3 - Semi-Detached Ageing
6b4 - Older Workers and Retirement
7a1 - Transitional Eastern European Neighbourhoods
7a2 - Hampered Aspiration
7a3 - Multi-Ethnic Hardship
7b1 - Eastern European Communities
7b2 - Deprived Neighbourhoods
7b3 - Endeavouring Flat Dwellers
7c1 - Challenged Transitionaries
7c2 - Constrained Young Families
7c3 - Outer City Hardship
7d1 - Ageing Communities and Families
7d2 - Retired Independent City Dwellers
7d3 - Retired Communal City Dwellers
7d4 - Retired City Hardship
8a1 - Industrious Transitions
8a2 - Industrious Hardship
8b1 - Deprived Blue-Collar Terraces
8b2 - Hard-Pressed Rented Terraces
8c1 - Ageing Industrious Workers
8c2 - Ageing Rural Industry Workers
8c3 - Renting Hard-Pressed Workers
8d1 - Young Hard-Pressed Families
8d2 - Hard-Pressed Ethnic Mix
8d3 - Hard-Pressed European Settlers

A subset of 1584 Output Areas were extracted for the extent of Liverpool, and inputs were created
that mirrored the attributes, measures, transformation and standardization methods used for the OAC 2011
classification. Prior to clustering the Liverpool classification, a range of k values were considered for the
initial Super Group level by plotting a total within sum of squares statistic for 2-12 cluster solutions. The
purpose of this plot was to identify an “elbow criterion” which is a visual indication of where an appropriate
cluster frequency might be set for Liverpool. As can be seen in Figure 3 there are no large decreases in the

8

within sum of squares, and a minor moderation of the decrease around 7 or 8 clusters; which also mirrors
similar patterns observered within UK OAC (ref to be added). As such, and to maintain comparability with
how national OAC is represented within Liverpool, a 7 cluster solution was chosen.

Total within sum of squares

2200

2000

1800

1600

2

3

4

5

6

7

8

9

10

11

12

k

Figure 3: An “elbow criterion” plot used to consider an appropriate number of Super Group clusters in a
Liverpool OAC
The next stage was to create the 7 cluster solution, and the k-means algorithm was run 10,000 times
on the input data. This repetition is necessary as the initial starting conditions for k means are randomly
allocated, and as such, a pool of outcomes must be generated in order to assess which result represents
a best fit of the data. For full details of how the k-means algorithm makes an assignments of areas into
clusters see (Harris et al. 2005), and for processes of optimization, see (Singleton & Longley 2009a). The
final set of 7 clusters for Liverpool are shown in Figure 4. To contextualize these assignments, rates for input
attributes within each cluster were compared with the Liverpool averages. From these scores, the labels
and descriptions shown in Table 3 were formulated. Furthermore, the OA that were closest in attributes
to their assigned cluster mean were identified, and a random postcode within these zones selected where an
illustrative photograph was taken (see Figure 5).
The purpose of such descriptive material is to give a very brief overview of the “typical” characteristics
of the clusters. Although was not the case here, such processes of labeling are often completed by a wider
review group rather than an individual. For the 2011 OAC, this involved consultation and approval of
names and descriptions by the ONS. An alternative method of validation of both the cluster assignment,
9

1−Family Terraces
2−Students and University
3−Constrained and Aging
4−Central Diversity
5−Affluent Suburbs
6−Struggling Families
7−City and Central

Figure 4: Super Group Level Liverpool Output Area Classification
and the descriptive interpretation was illustrated by Longley & Singleton (2009) who used an online public
consultation portal to gather feedback on the classification. Such systems give the general public a method
of responding to assignments, and this feedback could be incorporated into revised classifications.
Although the colours are not comparable, if the arrangement of areas into clusters between the Liverpool
OAC in Figure 4 and the subset of the 2011 UK OAC for Liverpool (see Figure 2) are compared, the
overall patterns are broadly similar, although, in the Liverpool OAC there is a greater degree of spatial
autocorrelation (less “noise”). Such e↵ects would likely occur because the optimization process in building
the local classification forms clusters in relation to local attribute means rather than those of the UK. The
impact is that the resulting clusters fit the data better for their locality.

10

Table 3: Liverpool OAC labels and brief descriptions
Super Group
1 - Family Terraces

2 - Students and University

3 - Constrained and Aging

4 - Central Diversity

5 - A✏uent Suburbs

6 - Struggling Families

7 - City and Central

Brief Description
Within these predominantly terraced areas, there are many families with young children, however, fewer ethnic minorities than
the Liverpool average. Most property is owner occupied or rented
from the private sector.
The majority of students studying in higher education live within
these areas in shared accommodation, typically rented from the
private sector.
These areas have a high concentration of elderly residents and
others living in constrained circumstances. There are higher than
Liverpool average rates of divorce, and also unemployment. Many
of the property are flats which are rented from the social sector.
These centrally located areas have high ethnic diversity. There
are many families within these areas with young children, although
higher than the Liverpool average rates of divorce. Unemployment
within these areas is high, and those in work tend to work in low
level service occupations.
These a✏uent suburban areas feature larger detached and semidetached houses, many of which are owner occupied. Residents
are typically well qualified and in the latter stages of successful
careers in the public sector, finance or education. Families who
have had children are old enough to be no longer dependent.
Families within these areas typically have young children and live
in terraced housing rented from the social sector. There are high
levels of unemployment in these areas, however those in work typically have blue collar occupations.
These central areas are occupied typically by young professionals,
with high ethnic diversity, and particularly high rates of wider EU
residents. Many residents within these areas are single and living
in flats rented from the private sector, are well qualified and work
in white collar occupations.

11

(a) 1 - Family Terraces - E00034061 - L13 2AY, (b) 2 - Students and University - E00176614 Colwyn Road.
L15 3LE, Borrowdale Road.

(c) 3 - Constrained and Aging - E00034483 L25 5LL - Halewood Place.

(d) 4 - Central Diversity - E00176732 - L7 2PT
- Stamford Street

(e) 5 - A✏uent Suburbs - E00033295 - L12 3HB
- Blackmoor Drive

(f) 6 - Struggling Families - E00034134 - L11
7BG - Faversham Road

(g) 7 - City and Central - E00033032 - L17 8UG
- Parkfield Road

Figure 5: Liverpool OAC Super Groups
This comparison can be extended by cross-tabulating the assignment of OA in the two classifications.
These are presented as percentage scores in Table 4. A number of interesting trends are highlighted, the first
is that the OAC Super Group “2-Cosmopolitans” which represents the gentrified core of most large cities
in the UK, is split within Liverpool OAC into a cluster with similar characteristics “7-City and Central”,
and a further cluster that represents many of the student areas (“2-Students and University”). Such areas
are not necessarily as concentrated or extensive in other urban areas of the UK. OAC Super Groups maintaining similarity to those in the Liverpool classification include “3-Ethnicity Central” and “6-Suburbanites”
with 80.4% and 99.5% similarity respectively. The UK OAC Super Group “4-Multicultural Metropolitans”
maintains broad similarity to the Liverpool OAC Super Group “4-Central Diversity”, although, some OA
are reassigned into “1-Family 2- Terraces” which have lower ethnic diversity and “2-Students and University”
12

which although ethnically diverse, have di↵erent age profiles and many more residents in full time education.
Similarly, the UK OAC Super Group “5-Urbanites” is split into two between the less a✏uent “1-Family Terraces” and “5-A✏uent Suburbs”. The Super Group “7-Constrained City Dwellers” maintains most similarity
to the Liverpool OAC Super Group “3-Constrained and Aging” (67.7%), however OA are also reassigned into
“1-Family Terraces” (15.8%) and “6-Struggling Families” (8.2%). The Super Group “8-Hard-Pressed Living”
has the majority of OA assigned to “6-Struggling Families” (60.6%), however, other OA are assigned into
areas that although are less a✏uent, have either more elderly residents (“3-Constrained and Aging”; 9.3%)
or younger families (“1-Family Terraces”;23.5%). There are also some assignments into the most a✏uent
Super Group in Liverpool (“5-A✏uent Suburbs”). This latter di↵erence is interesting as “8-Hard-Pressed
Living” might be a cluster where use could be envisioned in public sector targeting of resources - for example
- university widening participation or health care initiatives. However, in the context of Liverpool, 6.6% of
these areas are classified as “5-A✏uent Suburbs” when examined with the city focused classification.
1-Family
Terraces

2-Cosmopolitans
3-Ethnicity Central
4-Multicultural Metropolitans
5-Urbanites
6-Suburbanites
7-Constrained City Dwellers
8-Hard-Pressed Living

7.2
0.9
15.0
41.7
0.0
15.8
23.5

2Students
and University
34.3
3.7
8.8
0.5
0.5
0.0
0.0

34-Central
Constrained Diversity
and Aging

5-A✏uent
Suburbs

6Struggling
Families

7-City and
Central

1.8
0.0
0.0
5.9
0.0
67.7
9.3

0.0
0.0
1.8
51.5
99.5
0.3
6.6

0.0
0.0
4.4
0.0
0.0
8.2
60.6

54.8
15.0
0.0
0.5
0.0
0.3
0.0

1.8
80.4
69.9
0.0
0.0
7.6
0.0

Table 4: Percentage of OA assigned to OAC Super Groups (rows) and Liverpool OAC Super Groups
(columns)

4

Discussion and Conclusions

This chapter has provided an overview of how geodemographic classification emerged as a method of describing the characteristics of areas from rich multidimensional census data. The use of contemporary
geodemographics are widespread in the public and private sectors, and e↵ectively code people and the places
in which they live into aggregate groupings based on shared attribute similarities. As a representational
method, details of reality are balanced in favour of generalization, with the aim of providing a model that
has utility in aiding understanding about how places are structured, or, used as a component of area based
targeting strategies. Such codification is informed firstly by those choices made when compiling the classification, and secondly, by the choice of labels and descriptive materials associated with the output typology
to provide context. As such, there are no “correct” or “true” geodemographic representations, and between
classifications these organise a variety of di↵erent granular geographies into aggregate typologies of varying
characteristics.
Methodological decisions that a classification builder might take when they build a geodemographic
vary, and some typical choices were reviewed, alongside discussion of their likely impacts. A comparison
of all possible methods and their combinations would run the length of many doctoral theses, and as such,
an illustrative case study was selected to focus on the impact one specific methodological decision, the
geographic extent of the classification. In this comparison, the national classification OAC 2011 was mapped
for the extent of Liverpool. The methodology used to create this classification was then repeated to derive a
new classification, however, with cluster optimisation restricted to the geographic extent of Liverpool. The
impact of this single decision resulted in a classification which arguably represents the geography of Liverpool
more appropriately, given that the clusters were optimised based on a constrained geographic area, and as
such, do not have to account for the wider variance of a UK dataset. Reassignments from 2011 OAC into the
Liverpool classification were considered, and highlighted local socio-spatial structures which either deviate
or are similar to national patterns.
It is important to di↵erentiate between geodemographic method, that is the process by which a classification can be built and a geodemographic system, which are those classifications pre-compiled and often
13

integrated into software coding solutions that can be applied to a range of applications. In this chapter, a
classification system is compared with an implementation of a method, and the results indicate that, and
perhaps unsurprisingly, a bespoke classification (in this case optimised for local context) o↵ers a potentially
more e↵ective representation than the generic geodemographic system. The purpose here is not to make
the case for general purpose versus bespoke classifications, as such arguments have been rehearsed since the
inception of geodemographics (see: (Openshaw et al. 1980)), and are discussed and evaluated elsewhere (Singleton 2010a). In a geodemographic system, the aim is to provide the “best” representation for a wide range of
purposes. For example, a commercial classification may find utility in the retail, the automotive or insurance
sectors; however, is not designed specifically for any of these application areas2 . Whereas geodemographic
methods aim to provide contextual structure for a given application or locality. Given the divergent aims
and objectives of geodemographic systems and methods, the exact choices about how a classification will be
created become application specific. For example, the UK OAC 2011 required input attributes that would
be available in all counties of the UK, and as such, ignores those attributes that might only be available only
within specific countries. Examples could include the input of Welsh language variables in Wales, or within
England, attributes about second home ownership.
As illustrated by the case study presented in this chapter, choice of methods can impact the output
representation, and as such, it is critical when building a geodemographic to be open and transparent about
methodological specification, and present a clear rationalle about why these decisions were taken. This is of
particular importance for applications in the public sector where life chances might be apportioned through
those decisions informed by geodemographics (Singleton & Longley 2009b). Such methodological clarity
engenders greater scientific rigor, as methods are more open to scrutiny, testing and reproduction. Arguably,
best practice in this regard is to embed code, data and written interpretations, and place these within the
public domain, for example, utilising public code sharing repositories such as github3 . Furthermore, and as
argued elsewhere (Longley & Singleton 2009), mechanisms that enable end users to be empowered to give
feedback about classification reliability should also be encouraged.
Building geodemographics employs scientific methods of data reduction to provide summary measures
of the characteristics of typically small area geography. The art of building geodemographics relates to
methodological choices and their justifications, which are typically guided by classification builder expertise.
Given this subjectivity, there are no “best” solutions, although some classifications may perform better for
certain applications, either serendipitously, or by design such as with a bespoke classification. Given their
prevalence of use, it is argued here, that for geodemographics to attain greater social responsibility, all
aspects of the build process should be placed within the public domain, and additionally, mechanisms should
be enabled to provide end users (either those who are coded or who are coding) with the ability to give
feedback on the quality of assignments.

5

Bibliography

References
Abler, R., Adams, J. S. & Gould, P. (1971), Spatial Organisation: The Geographer’s View of the World,
Prentice Hall, New Jersey.
Adnan, M., Longley, P. A., Singleton, A. D. & Brunsdon, C. (2010), ‘Towards real-time geodemographics: Clustering algorithm performance for large multidimensional spatial databases: Towards real-time
geodemographics’, Transactions in GIS 14(3), 283–297.
Batey, P., Brown, P. & Pemberton, S. (2008), ‘Methods for the spatial targeting of urban policy in the UK:
a comparative analysis’, Applied Spatial Analysis and Policy 1(2), 117–132.
Blake, M. & Openshaw, S. (1995), ‘Selecting variables for small area classifications of 1991 UK census data’,
School of Geography, University of Leeds Working Paper 95/5.
2 Many commercial geodemographic companies in addition to general purpose classifications also o↵er systems that have
been tailored to markets. For example, CACI produce “Financial Acorn” - http://www.caci.co.uk/integrated-marketing/
data-products/financialacorn.
3 https://github.com/

14

Brunsdon, C., Longley, P., Singleton, A. & Ashby, D. I. (2011), ‘Predicting participation in higher education:
a comparative evaluation of the performance of geodemographic classifications’, Journal of the Royal
Statistical Society, Series A. 174(1), 17–30.
Burrows, R. & Gane, N. (2006), ‘Geodemographics, software and class’, Sociology 40(5), 793–812.
Charlton, M. E., Openshaw, S. & Wymer, C. (1985), ‘Some new classifications of census enumeration districts
in britain: A poor man’s ACORN’’, Journal of Economic and Social Measurement 13, 69–96.
de Smith, M., Goodchild, M. F. & Longley, P. (2009), Geospatial Analysis, 3 edn, Matador, Leicester.
Goss, J. (1995), Marketing the new marketing. the strategic discourse of geodemographic information systems, in J. Pickles, ed., ‘Ground Truth’, Guildford Press, New York, pp. 130–170.
Goss, J. (2003), The instrumental rationality of geodemographic systems, in D. Clarke, ed., ‘The Consumption Reader’, Routledge, New York. Published: Paperback.
Harris, R. J., Sleight, P. & Webber, R. J. (2005), Geodemographics, GIS and Neighbourhood Targeting, Wiley,
London.
Longley, P. (2005), ‘Geographical information systems: a renaissance of geodemographics for public service
delivery’, Progress in Human Geography 29(1), 57–63.
Longley, P. & Singleton, A. (2009), ‘Classification through consultation: Public views of the geography of
the e-society.’, International Journal of Geographical Information Science 23(6), 737–763.
Openshaw, S. (1984), The Modifiable Areal Unit Problem, CATMOG 38 Geoabstracts, Norwich.
Openshaw, S., Cullingford, D. & Gillard, A. (1980), ‘A critique of the national classifications of
OPCS/PRAG’, Town Planning Review 51(4), 421.
Parker, S., Uprichard, E. & Burrows, R. (2007), ‘Class places and place classes geodemographics and the
spatialization of class’, Information, Communication & Society 10(6), 902–921.
Reibel, M. & Regelson, M. (2011), ‘Neighborhood racial and ethnic change: The time dimension in segregation’, Urban Geography 32, 360–382.
Savage, M. & Burrows, R. (2007), ‘The coming crisis of empirical sociology’, Sociology 41(5), 885–899.
Shevky, E. & Bell, W. (1955), Social Area Analysis, Stanford University Press, California.
Shevky, E. & Williams, M. (1949), The Social Areas of Los Angeles, University of California Press, Berkley.
Singleton, A. (2010a), Educational opportunity: the geography of access to higher education, International
population studies, Ashgate, Farham.
Singleton, A. (2010b), ‘The geodemographics of educational progression and their implications for widening
participation in higher education’, Environment and Planning A 42(11), 1560–2580.
Singleton, A. & Longley, P. (2009a), ‘Creating open source geodemographics - refining a national classification
of census output areas for applications in higher education.’, Papers in Regional Science 88(3), 643–666.
Singleton, A. & Longley, P. (2009b), ‘Geodemographics, visualisation, and social networks in applied geography’, Applied Geography 2009(29(3)), 289–298.
Singleton, A. & Spielman, S. (2013), ‘The past, present and future of geodemographic research in the united
states and united kingdom’, Professional Geographer In press.
Sivadas, E. (1997), ‘A preliminary examination of the continuing significance of social class to marketing: a
geodemographic replication’, Journal of Consumer Marketing 14(6), 463–479.

15

Sleight, P. (1997), Targeting Customers: How to Use Geodemographic and Lifestyle Data in Your Business,
NTC Publications, Henley-on-Thames.
Tapp, A. & Warren, S. (2010), ‘Field-capital theory and its implications for marketing’, European Journal
of Marketing 44(1/2), 200–222.
Thrift, N. & French, S. (2002), ‘The automatic production of space’, Transactions of the Institute of British
Geographers 27(3), 309–335.
Timms, Duncan, W. (1971), The Urban Mosaic: Towards a Theory of Residential Di↵erentiation, Cambridge
University Press, Cambridge.
Twigg, L., Moon, G. & Jones, K. (2000), ‘Predicting small-area health-related behaviour: a comparison of
smoking and drinking indicators’, Social Science & Medicine 50(7-8), 1109–1120.
Uprichard, E., Burrows, R. & Parker, S. (2009), ‘Geodemographic code and the production of space’, Environment and Planning A 41(12), 2823–2835.
Vickers, D. & Rees, P. (2007), ‘Creating the UK national statistics 2001 output area classification’, Journal
of the Royal Statistical Society. Series A. Statistics in society 170(2), 379.
Voas, D. & Williamson, P. (2001), ‘The diversity of diversity: a critique of geodemographic classification’,
˘ S–76.
Area 33(1), 63ˆ
aA¸
Webber, R. (1975), Liverpool Social Area Study, 1971 Data: PRAG Technical Paper 14., Studies, Centre for
Environmental.
Webber, R. & Craig, J. (1978), Socio-Economic Classifications of Local Authority Areas (Studies on Medical
and Population Subjects), London.
Webber, R. J. (1977), An Introduction to the National Classification of Wards and Parishes, number 23,
London.
Webber, R. J. (1978), ‘Making the most of the census for strategic analysis’, The Town Planning Review
49(3), 274–284.
Webber, R. J. (1980), ‘A response to the critique of the national classifications of OPCS/PRAG’, 51(4), 440–
450.
Webber, R. J. (2007), ‘The metropolitan habitus: Its manifestations, locations, and consumption profiles’,
Environment and Planning A 39(1), 182–207.

16

The City and the Feudal Internet: Examining
Institutional Materialities
Paul Dourish
University of California, Irvine
jpd@ics.uci.edu

Abstract: In "Seeing like a City," Marianne Valverde turns to urban regulation to counter some of
James Scott's arguments about the homogenizing gaze of high modern statehood. Cities, she notes,
are highly regulated, but without the panoptic order that Scott suggests. They operate instead as a
splintered patchwork of regulatory boundaries – postal codes, tax assessment districts, business
improvement zones, school catchment areas, zoning blocks, sanitation districts, and similar divisions
that don't quite line up. Arguments about online experience and the consequences of the Internet
have a similar air to Scott's analysis of statehood – they posit a world of consistent, compliant, and
compatible information systems, in which the free flow of information and the homogenizing gaze of
the digital erases boundaries (both for good and ill).
In fact, the organization of the Internet -- that is, of our technologically- and historically-specific
internet –is one of boundaries, barriers, and fiefdoms. We have erected all sorts of internal barriers to
the free flow of information for a range of reasons, including the desire for autonomy and the
extraction of tolls and rents. In this talk I want to explore some aspects of the historical specificity of
our Internet and consider what this has to tell us about the ways that we talk about code and the city.

Introduction
In her paper “Seeing Like a City,” urban legal scholar Marianne Valverde (2011) uses examples from
urban regulation and management to reassess the claims of panoptic standardization that lie at the
heart of James Scott’s classic “Seeing Like a State” (Scott 1998). Scott explores the operation of what
he calls “high modern statehood,” observing how the seeds of self-destruction in many large-scale
state projects are sown from the start as a consequence of the erasure of locality and specificity implied
by the idealizations of modernist scientific rationalism. To see like a state, in Scott’s sense, is to see in
terms of grids and ideal types, and to see through the lens of regularization and standardization.
Valverde argues that cities demonstrate a different regulatory pattern. Cities, she observes, are not
managed by formal grids; they do not offer or conform to uniform accounts. Instead, cities are
patchworks of overlapping, related but not-quite-consonant regions of regulation and management –
tax assessment districts, construction zones, postal routes, school catchment areas, political wards,
historical districts, council districts, police precincts, and more. Sometimes these line up; sometimes
they don’t. Sometimes they are defined with respect to infrastructure; sometimes they are defined with
respect to historical and social convention. Sometimes they are visible to citizens; sometimes they are
purely matters of professional practice.

1

The sorts of projects that often cluster together under the banner of “digital cities” and similar terms
tend to reflect Scott’s model more than Valverde’s. The breathless invocations of “big data” reflect an
urge towards self-knowledge, on the part of a person, an organization, or a city, that presumes first a
process of rationalization that would be entirely familiar to Scott. Ironically, though, the actual digital
experience of the city may have more to do with Valverde’s analysis. To the extent that our digital
tools provide us with lenses onto the city and our space in it, they do so in ways that reflect not a
uniform or consistent spatial experience, but rather a view that is singular and particular.
Two pieces of anthropology, neither specifically connected to the domain of the digital, are useful
here. The first is Nancy Munn’s study of movement and spatiality for the Warlpiri people of
Australia’s Tanami Desert (Munn 1996). As with many aboriginal Australian peoples, Warlpiri
ontology is deeply relational, and so it is with space. One is connected to space through ones’ kin
relations, through the history of one’s people in space, through historical patterns of migration, and
through the way the space bears the imprint of the actions of totemic Dreamtime creatures. One is
affected more by the resonances in the space of historical actions that involve near relatives than by
those that involve more distant ones; and the space as currently occupied and moved through by
others also reflects a shifting pattern of allegiances, powers, and potencies to which one might
respond. Movements through the space, sparsely populated as it is, might nonetheless be marked by
long detours to avoid places where one cannot be because of the one’s relations to the people or
actions in that space; ritual exclusions between, for instance, classificatory mothers in law and sons in
law can be reflected in the patterns of residence and so in one’s large-scale movements through space.
It is not uncommon to be told that there is “no room” for one in a particular direction – a seemingly
absurd statement in the almost empty desert until one realizes that it’s not a lack of physical room but
rather of moral room that is being identified.
The second piece of social science writing that inspires some of my thinking here is Bill Kelleher’s
book on memory and identity in a small Northern Irish town during the Troubles (2003). What is
particularly telling here is one part of Kelleher’s method, which is to have various of his informants
take him on tours of the town and its environs. What begins to emerge for Kelleher after a series of
these tours is the existence essentially of two towns – one Catholic and one Protestant. It is not merely
that the Catholics stick to their neighborhoods and the Protestants to theirs, but that they navigate the
town differently, they narrate the history of the town differently, they see boundaries differently, they
park differently, they frequent different establishments, and so on. They talk about the different ways
that people walk, the different ways that they dress, the different ways that they decorate their houses,
the different ways that they came to live where they do. The two towns are in places imposed upon
one another, but even then, there is a Catholic side and a Protestant side on which people park in the
main square, and so on.
What I want to reflect on in this paper are the questions of heterogeneity, fragmentation, and
patchwork suggested by Valverde as issues in the digital city – if you will, splintering urbanism in
multiple digital domains (Graham and Marvin 2001). The work of Munn and Kelleher underscore
the moral and cultural elements to these issues as they manifest themselves in everyday life. To the
extent that projects of digitalization of urban life are conceived of in terms of the panoptic view of
Scott’s high modern statehood, I want to make a case for fragmentation and difference as an
important consideration in thinking about code and the city.

2

I will approach this from two directions. First, I want to explore different aspects of the experiential
fragmentation of the digital city. Then, I want to show how the Internet itself is perhaps better
understood in terms of Valverde’s patchwork than one might imagine.

Fragmentation and Splintering of Experience
The first source of fragmentation is the fundamental value proposition of digital production, mass
customization. While the integration of digital control with conventional manufacturing techniques
began to make mass customization possible in the physical domain in the 1980s and 1990s, it is the
move towards purely digital experiences and the application of data mining techniques made possible
both by increases in processor performance and large-scale data aggregation that have made mass
customization of interactive experience the sine qua non of the contemporary digital landscape. The
irony of big data is that its application is in the small; it is my personal experience that is crafted this
way. Indeed, this specific targeting is exactly what’s on offer in the digital city – an experience curated
for each of us individually, which by the same token separates us each from another.
Mass customization is taken one step further when the devices through which we encounter the urban
landscape are ones that themselves embody multiplicity, such as mobile phones. One metaphor I find
particularly useful here is Appadurai’s notion of “scape” (Appadurai 1996). Appadurai addresses
questions of globalization in terms of the multiple scapes produced by different elements of
contemporary life – ethno-scapes, finance-scapes, media-scapes, and so on. The metaphorical appeal
here is to the notion of landscape. Landscape does two different things at once. First, it assembles
different, disparate, and perhaps distant elements into a whole, into a vista. As I stand at the window,
I see a distant mountain juxtaposed with a nearby apartment tower; I see buildings that are blocks
apart brought into immediate alignment, and visually adjacent, glimpses of a distant river. What I
perceive is a whole, made up of different elements, some close, some far, some dominant, some
muted, all partial, all perspectival, and most all disconnected until brought together by this process of
viewing. The second thing that landscape does is to position us. Not only does my view out of the
window bring these elements into juxtaposition, but it also serves to define my position, because there
is only one place to stand that brings together just those elements in just those ways.1 For Appadurai, this
metaphor captures important elements of the contemporary experience of globalization; we
experience phenomena with global reach, but we experience them perspectivally, from a point of view
that aligns them in unexpected ways, that brings disparate elements into local relations, and that
positions us.
One of Appadurai’s scapes is the media-scape; the collection and arrangements of media, media
forms, genres, and transmissions that make up global media culture as experienced and encountered
in different locales. We can apply the notion more locally. A social networking site like Facebook
presents us with the conundrum of scapes. Every status update, every post, and every photo published
to Facebook is, in some sense, public; we know that everything we see, others see too. And yet, we all
have our own networks and our own connections. Nobody else’s newsfeed looks just like mine; the
1 This idea that the vista is more important than the elements that make it up is common in various indigenous encounters
with landscape, including in Native American tribes of the Western Desert (Basso 1996, Stoffle et al. 1997).

3

collection of elements I see on the page that greets me when I log in are essentially unique. They are
my own status-scape, if you will. Similarly, we might think of the app-scape as a specialization of the
media-scape. The apps that we download to our phones, through which we encounter city space, are
all public, available and accessible to all (generally speaking). And yet, the collection of them on my
own phone are unique to me. As these apps interact with each other, then, or even just as their
mutual presence on the phone contextualizes each, they come to form an app-scape, a unique,
singular, private experience of the digital city as configured by just my phone and just my set of apps.
And similarly, that positions me as the person who has configured his phone and his technology for
just that experience. We might add in the vagaries of mobile phone plans as part of that scape –
choices about international data roaming, the connection with other services, family plans that create
differences between messaging one person and another, and so on. We talk quite blithely of a world
experienced through “the” mobile phone and what capacities “it” might offer – but Appadurai would
caution us against allowing the public or global availability of services or data to blind us to the highly
local contextualizations associated with a selection in a world of choices. This is more, then, that
simply a concern that “things take on a different character in different contexts” or that “the local
always trumps the global”, precisely because the fragmentation that it captures is one of assembly and
multiplicity.
Separation and disconnection have, of course, been features of urban life for at least as long as
sociologists have examined it (Simmel 1903). What makes the kinds of separations associated with the
app-scape interesting are the ways that separations might form along not just familiar but also
unfamiliar lines – lines of relation to infrastructure, lines of connection between application
environments, lines of data provenance. The extent to which, for instance, the “right to be forgotten”
is less a right in practice than a capacity to be purchased manifests itself in new ways when the urban
experience itself is something that is responsive to our tracking through a virtual space as well as a
physical (Kitchin and Dodge 2011.)

Experiencing the Fragmented City through Digital Tools
The digital tools that we use to explore the urban landscape – either surveyed from a distance via
Google Maps, or as we move around via smartphones, iBeacons, and GPS – become tools, then, that
reveal the fracturing of infrastructures to us. If the experience of space is primarily an experience of
similarity and difference, of extents and boundaries, then digital tools, responding to and operating in
relation to new boundaries marked by new infrastructures reveal the city to us as organized around a
new set of landmarks and distinctions. Wifi service, cellular coverage of different flavors, access to
power points, GPS signal strength, and so on, become new markers (Dourish and Bell 2007).
Along with his students, my colleague Matthew Chalmers built a series of urban games that makes
some of the seams within apparently seamless digital infrastructures. One game, Treasure, played in a
public park in Glasgow, supports a form of gameplay that relies upon the places where data service
“drops out”, so that people’s actions start to reveal their orientation towards an otherwise invisible
world as they move around the space (Barkhuus et al. 2005). Another, Finding Yoshi, is played on the
scale of the city as a whole (Bell et al. 2006). Although the players may not realize it, the game’s
operation is dependent upon the way that mobile devices encounter nearby Wifi access spots, either
secured or unsecured. The problems of the collapse of digital and physical spaces became apparent

4

only accidentally, when researcher began to note that they had essentially forced their players to walk
slowly up and down residential streets in Glasgow, ostentatiously carrying expensive and exotic pieces
of mobile computing hardware. What made sense in the gamespace was questionable, suspicious, and
potentially dangerous action in the everyday space that players simultaneously occupied.
Mobile digital technologies make space available to people in different ways. The idea that spatial
distinctions, often driven by data, are bound up in the differential provision of services is not new;
Michael Curry’s (2005) studies of geodemographic databases and the rise of demographic
segmentation of urban space or Stephen Graham’s (2005) “software-sorted geographies” provide
plenty of cases. Increasingly, though, what we are seeing are cases where the presence or absence of
mobile devices becomes itself a driver of service provision. One issue of current prominence is the
provision of Uber taxi services – the fact that one requires a mobile phone to call for an Uber ride
means that Uber drivers hover in the sorts of places where smartphones and their owners hang out. A
second example arises in citizen science projects, particularly those that Corburn (2005) refers to as
operating in the mode of “citizen sensors,” where a mobile-equipped urban population is seen as a
potential sensor network poised to detect anything from gas leaks and potholes to air pollution and
rare birds (Dickinson 2010). When smart phones are the means to collect the data upon which urban
decision-making is made, then decisions can be made only about the places where smart phones (and
active citizens) have been.
Interestingly, while we talk a good deal about the differential experience of space, a second critical
consideration that gets less attention is the differential experience of scale.
Several years ago, a group of colleagues and I studied spatial practices amongst paroled sex offenders
whose location was being tracked with GPS units bound to their ankles (Troshynski et al. 2008,
Shklovski et al. 2009, Shklovski et al. in press). At the time, this was a pilot program, and our study
was piggy-backed on a feasibility evaluation that the state of California was conducting in order to see
if this sort of monitoring was useful and practical; as it happened, a ballot proposition was passed
which introduced mandatory lifetime GPS tracking for sex offenders before the feasibility trial was
conducted. We went into the study with an interest in how location-based technologies served as a
lens through which urban space was experienced. What did it mean, for instance, to move around the
city but maintain a two-thousand-foot exclusion radius from every park, playground, school, library,
or swimming pool? How does one manage one’s movements through space in the face of these
conditions, and how does technology reveal the space to you as being organized in such a way as to
facilitate legal wayfinding?
The answer, as it turned out, was that it doesn’t. One reason is significant, if prosaic – not only can
one not ask Google Maps to plot one a route from A to B maintaining those exclusion zones, but
many of the participants in the pilot program were also prevented by their parole conditions from
using the Internet anyway. However, more significantly, conventional urban spaces are simply too
densely dotted with exclusionary hazards that our parolees found that it was simply impractical to
move around the city in any conventional sense. Their solution was not to figure out which side of the
street was further away from hazards that might land them back in jail; their solution instead was to
move to places – exurbs, rural towns, and unincorporated areas – where such amenities as a library or
a public swimming pool, or even a school, weren’t to be found. In the group meetings that were part

5

of their parole regime, they would exchange information about where such “safe” places might be
found.
In other words, the shift that had taken place for them was a shift in scale. The exclusions were
framed in terms of feet, but the changes that they experiences were those of miles – not so much a
simple displacement (walking along one street rather than another so as to maintain more distance
from a school) but rather a search on a different scale for a different places where dangers did not lurk
so densely.
I do not present the case of the sex offenders as a dystopian story about the oppressive nature of
perpetual state or corporate surveillance; we did not enter into that study thinking of parolees as the
canaries in the digital monitoring coal-mine. It’s a story, instead, about technological mediation and
about the forms of differential spatial and scalar reconfiguration in the presence of digital spatial
infrastructures. It highlights aspects of the ways in which digital tools and digital representations,
incorporated into different systems of practice, produce new experiences of space and scale, and often
in unanticipated ways.

Fragmentation and Splintering in Infrastructure
In many ways, of course, the fragmentation associated with this kind of mobile digital experience, or
the forms of fragmentation that can be experienced through these tools, is simply a contemporary
manifestation of a well-understood pattern of development (Graham and Marvin 2001). What I want
to do here, though, is to note a significant relation to a different pattern of fragmentation, one that we
perceive by understanding the digital experience not from above – that is, from the user’s point of
view – but from below, at the level of the infrastructure itself. I want to argue that the pragmatics of
internet architecture undermine the rhetorics of connectivity, interconnection, and seamlessness in
ways that bear important implications for the development of the digital city.
The abstract model of interconnection that the Internet embodies is one of decentralized and
amorphous structure. Indeed, the very term “network” was originally coined to convey not idea of
computers connect together, but the topology of their connection as a loose and variable net-like
mesh, in contrast to the ring, star, or hierarchical arrangements by which other connection fabrics
had been designed. The basic idea of Internet-style networking is that computers can be connected
together in whatever arrangement is convenient, and data units (“packets”) will nonetheless find their
way from one point to another as long as some path (or route) exists from point A to point B. In a
fixed topology, like a ring, star, or hierarchy, the path from one node to another is fixed and predefined. The key insight of the packet-switching design of the Internet is that there need be no prior
definition of the route from one place to another; packets could find their own way, adaptively
responding to the dynamics of network topology and traffic patterns. Amorphous topology is arguably
one of the key characteristics of internet-style technologies.
Early network diagrams from the days of ARPANET, the predecessor to the Internet, do indeed
display this net-work character (figure 1). Over time, though, more hierarchical arrangements have
arisen. These hierarchical patterns arise not least from two sources – geography and economics. The
geographical considerations produce a distinction between metropolitan and long-haul networks,
where metropolitan networks support relatively dense connectivity within small regions (for instance,
the homes and businesses connected to the network in a town or neighborhood), while long-haul
6

networks provide high-speed and high-capacity connections between urban regions (Malecki 2002).
The different demands upon these different kinds of connection are best met with different
technologies. This is where the economic considerations also come into play. Ever since the
decommissioning of the NSFNet backbone in 1995 and the emergence of the commercial Internet,
Internet service provision has been largely in the hands of commercial operators. To function as a
competitive marketplace, network provision must involve multiple competing providers, each of
whom in turn specialize in different aspects of service provision. One result of this specialization is a
hierarchical segmentation of network service provision.

Figure 1: The ARPANET in 1972, exhibiting a traditionally net-like structure.

Broadly, we can distinguish four different commercial entities – and hence four different forms of
service provision and four different technological arrangements – in contemporary Internet service.
The four are content providers, content distribution networks (CDNs), internet service providers
(ISPs), and transit carriers.
Content providers are corporations like Netflix, Amazon, Apple, or others whose business comprises
(in whole or in part) delivering digital material to subscribers and consumers. Internet Service
Providers, by and large, sell internet services to end-users, either individual subscribers or businesses.
We think of our ISPs as delivering the content to us, but in truth they are generally responsible only
for the last steps in the network, in our local cities or neighborhoods. Transit carriers are responsible
for getting data from content providers to the ISPs. While the names of ISPs like Verizon and
Comcast are well known, the names of transit carriers – such as Level 3, Cogent, or XO – are much
less familiar, despite the central role that they play in bringing information to any of our devices.
Content providers will typically contract directly with transit carriers for their content delivery needs.
Transit carriers and ISPs connect their networks through a set of technical and economic
arrangements collectively known as “peering” (as in the connection between two “peer” networks).

7

Peering arrangements are almost always bilateral, i.e. an agreement between two parties. They are
generally bidirectional and often cost-free, although they may have traffic or bandwidth limits beyond
which charges are levied. The term “peer” is a hold-over from the military and non-profit days
preceding the development of the commercial Internet, and speaks directly to the notion of “internetworking” (ie, connecting together different networks and transmitting traffic between them). The
“peers” that are now linked by peering arrangements, though, are not peer academic or research
networks but commercial entities engaging in economic relations. These arrangements are largely
hidden from the view of end users, but become broadly visible when disputes arise around the
adequacy of peering relationships, corporate responsiveness to changing conditions upon them, or the
responsibilities of carriage associated with them. For example, recent (early 2014) debates in the
United States around Internet streaming movie provider Netflix paying ISP Comcast for access to its
facilities and networks have largely ignored the fact that the problem to which Netflix was responding
was a breakdown in relations between Comcast and Cogent, one of the transit carriers that Netflix
pays to transmit its traffic to ISPs (Rayburn 2014). A dispute arose between Comcast and Cogent
concerning whose responsibility it was to address bandwidth limitations when Cogent began to send
more traffic onto Comcast’s network than their peering agreement allowed. In the face of this ongoing
dispute, Netflix arranged to locate its servers with direct access to Comcast’s subscriber network,
eliminating their dependence upon Cogent’s transit network. While this raised the specter in the
popular press and in technical circles of an end-run around “net neutrality” arguments2, the source of
the problem in a dispute between carriers – and in particular at the boundary between an ISP and a
transit carrier – is in some ways more interesting.3

The Feudal Internet
The emergent structure of our Internet – the market niches of transit carrier and ISP, the practical
solution of CDNs, the relationship between mobile carriers, telecommunications firms, and media
content producers, and so on – draws attention to a simple but important truth of internetworking:
the Internet comprises a lot of wires, and every one of them is owned by someone. To the extent that
those owners are capitalist enterprises competing in a marketplace, then the obvious corollary is that,
since all the wires can do is carry traffic from one point to another, the carriage of traffic must become
profit-generating. The mechanisms by which traffic carriage over network connections becomes
profitable is basically either through a volume-based or per-byte mechanism – a toll for traffic – or
2 Net neutrality is the principle that network routers should treat all traffic that flows through them equally. As a policy
matter, it would disallow network carriers from either treating their own traffic or traffic from corporate partners
preferentially, or for charging for prioritized access. This is the favored position of the Federal Communications Commission
although not the subject of specific regulation, and it is a site of significant policy discussion and activism, with carriers
arguing that commercial realities require them to be able to offer tiered service, and consumer advocacy organizations
arguing that such a model would disrupt the “any to any” nature of Internet communication. Initial discussion in the wake
of Netflix’s announcement that they would pay Comcast for access to their network focused on the apparent capitulation to
the carriers’ position in this debate.
3 It’s worth noting that Cogent has been in a number of these disputes, and that a number of them have led to so-called “depeering” events in which two networks become disconnected. On these occasions, hosts connected solely to one network
become unavailable to hosts connected solely to the other. One of the most significant was a de-peering between Cogent and
Sprint in 2008 which disconnected, say, the US Department of Justice (connected via Sprint) from the New York court
system (connected via Cogent) (Underwood 2008, Blum 2012).

8

through a contractual arrangement that places the facilities of one entity’s network at the temporary
disposal of another – a rental arrangement. This system of rents and tolls provides the basic
mechanism by which different autonomous systems, each of which provisions its own services,
manages its own infrastructures, and then engages in a series of agreements of mutual aid.
If this system seems familiar, it is not so much that it encapsulates contemporary market capitalism
but more that it is essentially feudal in its configuration. Marx argued for feudalism and capitalism as
distinct historical periods with their links to material means of production – “The hand-mill gives you
society with the feudal lord; the steam-mill society with the industrial capitalist” (Marx 1847). Recent
writers, though, have used the term “neofeudal” to describe the situation in late capitalism in which
aspects of public life are increasingly become private, gated domains – everything from toll lanes on
the freeway and executive lounges at the airport, on the small end, to gated communities and
tradeable rights to pollute the environment issued to large corporations at the other (e.g. Shearing
2001). The essential consideration here is the erasure of public infrastructure and the erection of a
system of tariffs, tolls, and rents that govern the way we navigate a world made up of privatized but
encompassing domains, within which market relations do not dominate.
Beyond the general use of the term “neofeudal” to refer to the privatization of public goods, let me
take the metaphor of the feudal Internet more seriously for a moment to point to a couple of
significant considerations.
The first is that operating mechanism of feudalism is not the market transaction but rather longstanding commitments of fealty, vassalage, and protection. These are not the instantaneous mutual
engagements of market capitalism but temporally extended (indeed, indefinite) arrangements with
little or nothing by way of choice or options. Indeed, the constraints upon feudal relations are
geographical as much as anything else: infrastructural, if you will. One can see, arguably, some
similarities to the way that geographical and infrastructural constraints lead to a pattern of relations
between internet providers that also relies upon long-term, “residence”-based, partnerships. The ties
that bind individuals to their service providers in semi-monopolistic conditions of the US broadband
market, or perhaps even more pointedly, the links that connect large-scale data service providers such
as Netflix with transit carriers like Level 3 are not simply conveniently structured as long-term
arrangements, but rather can only operate that way because of the infrastructure commitments
involved (such as the physical siting of data stores and server farms.) Similarly, the need for physical
interconnection between different networks makes high-provider-density interconnection nodes like
One Wilshire in downtown Los Angeles (see, e.g., Dourish in press, Varnelis 2008) into “obligatory
passage points” in Callon’s language – that is, to get interconnection between networks, you need to
be where all the other networks are, and they all need to be there too. For all that we typically talk
about the digital domain as fast-paced and ever-changing, these kinds of arrangements – not simply
commitments to infrastructure but commitments to the institutions relationships that infrastructure
conditions – are not ones that can change quickly, easily, or cheaply. The relations that obtain here
are more feudal that mercantile.
The second interesting point that a feudal approach draws attention to is the persistence of preexisting institutional structures – perhaps most obviously, the nation-state. Although John Perry
Barlow’s (1996) classic “Declaration of the Independence of Cyberspace” famously argues that the
“governments of the industrial world… [have] no sovereignty” in the realm of the digital, and
9

notwithstanding the IETF’s famous motto that “rejects kings [and] presidents” in favor of “rough
consensus and running code” (Hoffman 2012), the truth is that governments and presidents continue
to manifest themselves quite significantly in not just the governance but the fabric of our Internet.
National and regional concerns arise in a variety of ways – in the provision of specific linguistic
content, in the regional caching of digital content, in the question of international distribution rights
for digital content (e.g. which movies can be viewed online in which countries), in assertions of
national sovereignty over information about citizens (e.g. Vladimir Putin’s public musings that data
about Russian citizens should be stored only on servers in Russia (Khrennikov and Ustinova 2014)), in
the different regimes that govern information access (e.g. the 2014 EU directive known popularly as
the “right to be forgotten”), and in local debates about Internet censorship (from China’s “Great
Firewall” and Singapore’s self-censorship regime to discussions of nationwide internet filters in
Australia and the UK). The very fact that a thriving business opportunity exists for commercial
Virtual Private Network (VPN) services that allow users to get online “as if” they were located in a
different country signals the persistent significance of nation-states and national boundaries in the
experience of our Internet. Similarly, significant debate has surrounded the role of national interests
in Internet governance (e.g. Mueller 2010) and the International Telecommunications Union or ITU
– a United Nations organization whose “members” are not technical experts or corporations but
nation-states – remains a significant body in the development of network technologies and policy. Just
as feudalism reinforced and made all aspects of everyday life subject to the boundaries of the manor,
the shire, and the nation, so too does our Internet – not necessarily any Internet, but certainly our
Internet – retain a significant commitment to the relevance of similar geographical, national, and
institutional boundaries.

Conclusion
China Mieville’s award-winning 2009 novel, The City and the City, concerns events that connect and
take place in two cities, Besźel and Ul Qoma, which (spoilers!) the reader soon begins to realize are in
fact the same geographical space, occupied by people trained from birth in a form of selective vision
and disregard that allows the two “cities” to coexist in relative independence. Similarly, despite the
rhetorical invocations of the seamlessness of networked experience, the resilient connectedness of
network topologies, and the decreasing relevance of national borders, we find that the Internet –
either in terms of user experience or in terms of infrastructural arrangement – tends not towards
openness and uniformity, but towards fragmentation and multiplicity, with these fragments frequently
superimposed.
I want to argue further that the two sides that I have examined here – the user experience side and
the infrastructure side – are perhaps more closely tied than they might seem. The crucial observation
here is that the infrastructural partitioning that I’ve described, the tendency towards a neofeudal
internet, is not so much an accident of design but rather a historical path. The Internet protocols are
designed around the possibilities of decentralization and a flat structure – and yet, centralization and
hierarchy are emergent properties of the Internet as it has come to be. This suggests that the
fragmentation that we see in user experience – which has similar roots in the need for a granular
approach to application development, and the pressures upon developers to create an exploit
collective yet exclusive data sets – is not merely (as it is often portrayed) a temporary waypoint along
the path towards a fully integrated digital experience, but rather a natural consequence of technical
10

and economic arrangements – arrangements that are further “baked into” the technology as it
evolves.
The question then is not so much how to move beyond such a model, or even how to anticipate the
coming of a more seamless digital urban experience, but rather how to make the realities of
contemporary digital arrangements objects of appropriate analytic attention. That implies, first,
taking the materialities of network arrangements seriously as historically and geographically specific
configurations and outcomes; second, addressing the visibility of the boundaries, transitions, and
domains that digital infrastructures create and making them first class elements of experience; and
third, beginning to unpack and examine the rhetorics and anxieties of seamlessness that underlie
contemporary projects in the digital city.

Acknowledgements
Work on this paper has been supported in part by the Intel Science and Technology Center for Social
Computing and by the National Science Foundation under awards 0838499 and 0917401. Elements
of this argument arose in conversation or collaboration with Tom Boellstorff, Johanna Brewer, Simon
Cole, Jon Crowcroft, Michael Curry, Eric Kabisch, Melissa Mazmanian, Alison Powell, Irina
Shklovski, Jenny Terry, and Emily Troshynski; I am indebted to all for their inspiration and insight.

References
Appadurai, A. 1996. Modernity at Large: Cultural Dimensions of Globalization. University of
Minnesota Press.
Barkhuus, L., Chalmers, M., Tennent, P., Hall, M., Bell, M., Sherwood, S., and Brown, B. 2005.
Picking Pockets on the Lawn: The Development of Tactics and Strategies in a Mobile Game. Proc.
Intl. Conf. Ubiquitous Computing Ubicomp 2005 (Tokyo, Japan). Springer.
Barlow, J. 1996. A Declaration of the Independence of Cyberspace. Davos, Switzerland. Downloaded
from https://projects.eff.org/~barlow/Declaration-Final.html on June 4, 2014.
Basso, K. 1996. Wisdom Sits in Places: Landscape and Language Among the Western Apache.
Albuquerque, NM: University of New Mexico Press.
Bell, M., Chalmers, M., Barkhuus, L., Hall, M., Sherwood, S., Tennent, P., Brown, B., Rowland, D.,
Benford, S., Capra, M., and Hampshire, A. 2006. Interweaving Mobile Games with Everyday Life.
Proc. ACM Conf. Human Factors in Computing Systems CHI 2006 (Montreal, CA). New York:
ACM.
Blum, A. 2012. Tubes: A Journey to the Center of the Internet. New York: Harper-Collins.
Corburn, J. 2005. Street Science: Community Knowledge and Environmental Health Justice. MIT
Press.
Curry, M. 2005. Toward a Geography of a World Without Maps: Lessons from Ptolemy and Postal
Codes. Annals of the Association of American Geographers, 95(3), 680-691.
11

Dickinson, J., Zuckerberg, B., Bonter, D. 2010. Citizen Science as an Ecological Research Tool:
Challenges and Benefits. Annual Review of Ecology, Evolution, and Systematics, 41, 149–172.
Dourish, P. In press. Packets, Protocols, and Proximity: The Materiality of Internet Routing. In Parks,
L. and Starosielski, N. (eds), Signal Traffic: Media Infrastructures and Globalization. University of
Illinois Press.
Dourish, P. and Bell, G. 2007. The Infrastructure of Experience and the Experience of Infrastructure:
Meaning and Structure in Everyday Encounters with Space. Environment and Planning B: Planning
and Design, 34, 3, 414-430.
Graham, S. 2005. Software-sorted Geographies. Progress in Human Geography, 29(5), 562-580.
Graham, S. and Marvin, S. 2001. Splintering Urbanism: Networked Infrastructures, Technological Mobilities and
the Urban Condition. Routledge.
Hoffman, P. 2012. The Tao of IETF. Downloaded from http://www.ietf.org/tao.html on June 4,
2014.
Kelleher, W. 2003. The Troubles in Ballybogoin: Memory and Identity in Northern Ireland. Ann
Arbor, MI: University of Michigan Press.
Kelley, K. and Francis, H. 1993. Places Important to Navajo People. American Indian Quarterly,
17(2), 151-169.
Khrennikov, I. and Ustinova, A. 2014. Putin’s Next Invasion: The Russian Web. Downloaded from
http://www.businessweek.com/articles/2014-05-01/russia-moves-toward-china-style-internetcensorship on June 4, 2014.
Kitchin, R. and Dodge, M. 2011. Code/Space: Software and Everyday Life. Cambridge, MA: MIT Press.
Marx, K. 1847 (1910). The Poverty of Philosophy. Tr: Quelch, H. Chicago, IL: Charles H. Kerr &
Co.
Malecki, E. 2002. The Economic Geography of the Internet’s Infrastructure. Economic Geography,
78(4), 399-424.
Mueller, M. 2010. Networks and States: The Global Politics of Internet Governance. Cambridge, MA: MIT
Press.
Munn, N. 1996. Excluded Spaces: The Figure in the Australian Aboriginal Landscape. Critical
Inquiry, 22(3), 446-465.
Rayburn, D. 2014. Here’s How the Comcast & Netflix Deal is Structured, With Data and Numbers.
Streaming Media Blog, February 27 2014. Downloaded from
http://blog.streamingmedia.com/2014/02/heres-comcast-netflix-deal-structured-numbers.html
Scott, J. 1998. Seeing Like a State: How Certain Schemes to Improve the Human Condition Have
Failed. New Haven, CT: Yale University Press.
Shearing, C. 2001. Punishment and the Changing Face of Governance. Punishment and Society, 3(2),
203-220.

12

Simmel, G. 1903 (2002). The Metropolis and Mental Life. In Gary Bridge and Sophie Watson, eds.
The Blackwell City Reader. Oxford and Malden, MA: Wiley-Blackwell.
Shklovski, I., Vertesi, J., Troshynski, E., and Dourish, P. 2009. The Commodification of Location:
Dynamics of Power in Location-Based Systems. Proc. Intl. Conf. Ubiquitous Computing Ubicomp 2009
(Orlando, FL), 11-20.
Shklovski, I., Troshynski, E., and Dourish, P. In press. Mobile Technologies and Spatiotemporal
Configurations of Institutional Practice. Journal of the Association for Information Science and Technology.
Stoffle, R., Halmo, D., and Austin, D. 1997. Cultural Landscapes and Traditional Cultural
Properties: A Southern Paiute View of the Grand Canyon and Colorado River. American Indian
Quarterly, 21(2), 229-249.
Troshynski, E., Lee, C., and Dourish, P. 2008. Accountabilities of Presence: Reframing LocationBased Systems. Proc. ACM Conf. Human Factors in Computing Systems CHI 2008 (Florence, Italy), 487-496.
Underood, T. 2008. Wresting with the Zombie: Spring Depeers Cogent, Internet Partitioned.
http://www.renesys.com/2008/10/wrestling-with-the-zombie-spri/ (downloaded July 31, 2014).
Valverde, M. 2011. Seeing Like a City: The Dialectic of Modern and Premodern Ways of Seeing in
Urban Governance. Law and Society Review, 45(2), 277-312.
Varnelis, K. 2009. The Infrastructural City: Networked Ecologies in Los Angeles. Actar.

13

Semantic Cities: Coded Geopolitics and Rise of the Semantic web
Heather Ford and Mark Graham
University of Oxford
Oxford Internet Institute
Introduction
In 2012, Google rolled out a service called Knowledge Graph that would answer
basic search queries without the user having to navigate to other websites. In an
introductory blogpost titled, ‘Things not strings’, Senior Vice President for Google
Engineering, Amit Singhal promised that with the Knowledge Graph, Google could
now understand the difference between ‘Taj Mahal’, the monument and ‘Taj Mahal’,
the musician. In addition to the regular search results that Google delivers to a user
in response to a query, the Knowledge Graph presents a summarized ‘fact box’ on
the right hand side of the results page where users can read facts about the Taj
Mahal (the monument) and to narrow the search results to Taj Mahal (the musician)
by clicking on one of the links below it. Google is able to obtain this intelligence
through the use of a number of information repositories such as Wikipedia, the CIA
World Factbook and Freebase1, as well as the data that it has about what people
search for.
For many, this move heralded Google’s recognition of the promise of the semantic
web: an idea and ideal that the Web could be made more efficient and
interconnected when websites share a common framework that would allow data to
be shared and reused across application, enterprise, community, and geographic
boundaries. In the same year, Google helped fund a new project from the Wikimedia
Foundation called Wikidata, another semantic web initiative that provides a central
source for data (for example, city names and their properties) that can be used by
all language versions of Wikipedia as well as other external organisations, including
Google.
For users of Wikipedia, the Wikidata project promises greater efficiencies in the
presentation of information across different language versions of Wikipedia and
provides opportunities for building tools that will automatically populate smaller
language Wikipedias. Wikidata now enables any ‘fact’ (the population of a city, for
instance) to be entered only once in the Wikidata ‘knowledge base’ and then to be
propagated to all other language versions that are pulling data from Wikidata
(rather than being manually inputted for each version). For Google, the semantic
web, and the ready availability of information from platforms like Wikidata, provides
a way to resolve users’ queries faster and to keep them on the Google domain
rather than navigating away.

1 A public knowledge base acquired by Google in 2010.
1

While the Wikidata initiative was introduced in order to increase efficiency and
integration across different Wikipedia pages and language versions, it also has
unintended consequences for the balance of power between Internet users and the
companies and organisations that are driving these changes. This paper extends the
work of others such as Introna and Nissenbaum (2000) who have shown how search
engines ‘systematically exclude (in some cases by design and in some accidentally)
certain sites, and certain types of sites, in favor of others’ (2000, p. 1), and that this
is a sign of increasing centralization and commercialization of the guiding forces of
the Internet. The ‘Society of the Query’ reader (König, 2014) reiterates the
importance of search engines for the public health of the Internet, and calls for
opening up the “black boxes” of search algorithms, and for recognizing the
increasingly concentrated, “monopoly-like” nature of the search engine market. This
building on Eli Parser’s (2012) characterization of the “filter bubbles” created by
search engines and the outsourcing of judgment to Google outlined by Siva
Vaidhyanathan (2012). Despite the resurgence in research on search engines, the
majority of research looks at individual platforms, focusing on Google and other
major search engines, rather than addressing the increasing interdependence of
different non-profit and for-profit organisations. We believe that addressing this
interlinking and sharing of data across multiple platforms complicates our
understanding of who is to blame for these problems and what possible solutions
might be.
One central area that we see a potential impact in is the participation by ordinary
users in the representation of their lived environments. Cities are increasingly more
than bricks and mortar. Their digital dimensions matter, they have meaning, and
they shape how we interact, understand, and enact them. The capital city of Israel,
for instance, is no longer just a human settlement, a concentration of human
activity, or even a digital representation in a Wikipedia article or a series of ranked
pages in a Google search. It is now increasingly comprised of structured pieces of
data that get embedded into key algorithms, platforms, services, and physical
structures that play a key role in how we enact our cities. This move to structure
and codify core parts of the web has important implications for both urban data
shadows and their emergent cities that are both created and reflected by those data
shadows. The altering of the web’s underlying architecture results in the
necessitation of new regimes of truth, and new mechanisms to reach agreement.
This paper seeks to critically interrogate these changes in the digital architectures
and infrastructures of our increasingly augmented cities by asking two key
questions. First, does the Semantic web live up to its promise of centralizing
meaning across different platforms and information repositories that form part of
our urban augmentations?; and, second, how does the semantic web impact
citizens’ abilities to speak back to representations of the cities in which they live?
To tackle those questions, we trace data about the city of Jerusalem as it travels
from Wikipedia to the Semantic web platforms of Wikidata and through to Google.
We chose Jerusalem because of its highly contested status and the ways that its
contested nature might be reflected and resolved within the logics of the semantic
2

web. Through this exploration, we seek to understand how particular reflections of
the city are made visible or invisible and how particular publics are given voice or
are silenced. Our cities and urban experiences are becoming ever more saturated
with the digital and ever more mediated by the digital, but the digital itself is
changing, and a goal of this paper is to understand what these changes ultimately
mean for our augmented and information-saturated cities. Doing so leads us to
ultimately reflect on how new alignments of code and content shape how cities are
presented, experienced, brought into being, and contested.
The promise of the semantic web
The year 2012 marked a milestone in the development of the semantic web. Before
this, the idea of the Web as a platform for sharing data and meaning across
different sites had mostly been just an idea, a dream of the investor of the Web, Tim
Berners-Lee and promoted by the World Wide Web Consortium (W3C), the
international standards organization for the Web. In 2012, the Wikimedia Foundation
announced a new project called Wikidata funded, in part, by Google that would
boost its semantic web efforts by developing a semantically organized knowledge
base sourced with information from Wikipedia and other Wikimedia Foundation
projects.
There had been efforts before Wikidata to extract Wikipedia’s ‘facts’ in projects such
as DBPedia and Yago which both pulled information from Wikipedia categories and
infoboxes (an infobox is a table that offers short and structured bits of information
about a topic; see figure 1 for examples) into their own platforms, as well as free
knowledge bases such as OpenCyc and Freebase. Through such extraction,
Wikipedia data has been used to improve object search in Google’s Knowledge
Graph (based on Freebase) and Google Maps, as well as Facebook’s Open Graph and
answering engines such as Wolfram Alpha, Evi and IBM’s Watson. In contrast to
previous efforts such as DBPedia, Wikidata is an internal (Wikimedia Foundation)
project that aims to provide support for statements in multiple languages,
affordances for users to edit and add citations to statements, and to do so on free
and open source software. Its goals are twofold: to support Wikipedia and other
Wikimedia projects by enhancing consistency across different projects and language
versions, and to support the many different (third party) services and applications
that reuse Wikipedia data in a structured way (Vrandecic & Krotzsch, 2014).
The promise is that Wikidata could improve the efficiency of Wikipedia and other
Wikimedia projects by providing a central platform for different language versions to
could come together to host centralized data they could all share. Instead of having
to edit language links manually, or to change a fact about someone’s death date
across all language versions, for example, Wikidata would provide a central place
where this information could automatically populate all projects that used its data. It
also meant that companies making use of Wikipedia data would be provided with an

3

up-to-date, machine-readable version of Wikipedia data under a less restrictive
copyright license than Wikipedia2, rather than the infrequent dumps of the entire
encyclopedia (or even selected parts) that were previously relied upon to make use
of Wikipedia’s dataset.

Figure 1: French, English, Spanish, and Punjabi Wikipedia infoboxes that contain the
date of birth and death for Ptolemy (note the differences between languages).
Also in 2012, Google launched the ‘Knowledge Graph’, a relational database of
millions of objects, people and places as well as ‘billions of facts’ about and
relationships between these different objects, people and places. According to
Google, the Knowledge Graph is ‘rooted in public sources such as Freebase,
Wikipedia and the (US) CIA (Central Intelligence Agency) World Factbook’ in addition
to data about what people search for on the Web. Google promises that the
Knowledge Graph will enable it to understand what a user means when searching
for particular objects, people and places because of the way in which the underlying
data is semantically structured. For instance, a user could enter the following text
string into a Google search box: “what is 100KM in miles?”; Google would then
translate that text string as a request to convert units of kilometers to miles, look up
the conversion rate (1:0.62), and then output the following result: “100 kilometres
=62.1371192 miles”.
A single Wikidata item now links information to many associated Wikipedia
language versions and provides the ability of every Wikipedia language version to
pull data from Wikidata about ‘facts’ in its database. This, for instance, means that
the population of Rome would be automatically updated on all languages versions
2 Whereas Wikipedia’s Creative Commons Attribution Share-Alike license
(https://creativecommons.org/licenses/by-sa/3.0/) requires attribution to Wikipedia and the Wikimedia
Foundation and to indicate where changes were made Wikidata’s use of the CC0 (Creative Commons
Public Domain dedication) license https://creativecommons.org/publicdomain/zero/1.0/ means that
reusers are not required to attribute Wikipedia or to indicate what changes were made.
4

of the ‘Rome’ page on Wikipedia that employ Wikidata statements when it is
changed only once on Wikidata. If an article’s infobox uses statements obtained
from Wikidata and users want to edit that infobox, those users need to navigate to
Wikidata in order to perform the change (rather than editing an infobox directly).
Making that change would then populate all other articles in all other language
versions that pull data from that particular statement.
Fears on the ground
In addition to the opposition on the basis of viability, debates about Wikidata and
about structured data more generally have surfaced deeper fears about what
semantic web logic might mean for Wikipedia going forward. Opposition to Wikidata
has centered around issues of inaccuracy (since most Wikidata items are botcreated), increased complexity (editors must learn a new interface and vocabulary),
increased obscurity (changes to Wikidata statements aren’t currently reflected in
the article history on Wikipedia), and the fact that citation affordances have yet to
be implemented.3 According to (now retired) Wikipedia editor, Riggr Mortis, Wikidata
represents ‘a brigade of editors forcefully and continuously adding a “hidden backend” to Wikipedia, that has nothing to do with the encyclopedic project, in order to
aid the technologies of private companies’. (Riggr Mortis, 2013)
These debates have roots in earlier opposition to what have been called “Infobox
Wars” (“Wikipedia,” 2014d). This long-running dispute is between those who think
that all Wikipedia articles should contain an infobox for greater readability and more
efficient emission of metadata, and those who believe that infoboxes are not always
necessary, can be reductive and lack the nuance achieved through prose (so-called
‘disinfoboxes’), and are sometimes unwieldy and can overtake the actual content of
the page (so-called ‘monster boxes’). The dispute has been fuelled by the fact that
infoboxes ‘have often been edited behind the scenes, without content contributing
editors being involved4’ (“Wikipedia,” 2014d).
Wikipedia editor, Riggr Mortis, fears that this development is a ‘push to turn
Wikipedia into a database masquerading as an encyclopedia’ and that ‘Wikipedia
will gradually become a pseudo-encyclopedia, with each page having been tailored
more to pretty infoboxes and the ‘”emission of metadata” than to human learning’.
According to Riggr Mortis in an essay that has been since deleted from Wikipedia
entitled ‘Wikipedia as a database’:
3 Although the ability of Wikidata to provide cited statements has been stated as one of its main benefits
over similar projects, the project has yet to implement citation support over a year after infobox support
was enabled.
4 A 2013 ArbCom (Arbitration Committee) ruling reiterated the policy that Infoboxes are ‘neither required
nor prohibited for any article’ and that it was a ‘content’ rather than a ‘maintenance’ decision whether or
not to include the infobox in an article’ (“Wikipedia,” 2014a).
5

At the root, this is about failing to promote encyclopedism. A long-running
trend on Wikipedia continues: emphasizing the simple man’s notion that
there are nothing but “facts” (property–value pairs) in the world: no
interpretation, no points of view, no context. Infoboxes do it; structured data
does it; Wikidata does it. Almanacs also do it: of course such information has
its interest, its purpose, and its place. But Wikipedia is an encyclopedia. It is
trying to do something very unique, by original conception, and let me tell
you, if the concept is watered down by people who mostly talk about “data”,
it wears at the foundation of the encyclopedia, because data collecting is so
much easier than what Wikipedia, the encyclopedia, ideally asks of you.
(http://neotarf.wordpress.com/2013/10/14/surturz-riggr-mortis-wikipedia-asdatabase/)
These fears have been fuelled by projects like Wikidata that enable greater sharing
of Wikipedia data with companies like Google. There are fears that Google’s
presentation of results sourced (in part) from Wikipedia and Wikidata in the
Knowledge Graph is responsible for a reduction in visitors to Wikipedia because
users are able to satisfy their query in the Google domain without having to
navigate to Wikipedia (Kohs, 2014). These results are yet to be verified by the
Wikimedia Foundation but it is probable that at least some users will have their
queries satisfied when they’re presented with the Wikipedia data in the Google
window rather than having to navigate to Wikipedia. The fact that Google doesn’t
link directly to Wikipedia articles to edit when the user provides feedback on
presented data would probably also lead to fewer Wikipedia edits, but more
conclusive research needs to be done to verify these results.
Since its launch in 2012, Wikidata employees and participants have been hard at
work to explain the benefits of Wikidata to the broader Wikipedia and Wikimedia
communities. Like all projects under the Wikimedia Foundation banner, Wikidata is
not forced to interoperate with other Wikimedia Foundation projects, and each of
Wikidata’s three stages of development is accompanied by a request for comment.
There is, however, a sense that this move toward a centralized, cross-version
database is inevitable for Wikipedia, in the same way that the semantic web is seen
as an inevitable progressive step from Web 2.0 to 3.0.
The crucial question at this stage of Wikidata’s development is whether the
promises of the semantic web can be fulfilled. Have semantic web initiatives
resulted in greater sharing of meaning across different sites, places, and contexts or
have certain meanings and voices overpowered and overwritten others? Does the
semantic web really result in a separation of content from its contexts, or does it
merely produce new contexts and terrains for the exercise of voice and power?
In this paper, we place a focus on understanding what a move towards more
semantically structured urban information means for the participation of ordinary

6

people in the representation of their lived environments. As the Web becomes
increasingly structured and abstracted, what happens to the varying descriptions of
those cities and towns by those who live in or near them?
Methods
In order to understand how data about cities is represented in the age of the
semantic web, we chose to look at a city lacking a broad consensus about some of
the basic statements that are represented in knowledge bases. Studies of
controversies are useful means of understanding how power is exercised in a social
system. According to Venturini, controversies are the settings where collective
practices are made visible at the level of everyday practice and are thus useful for
understanding how the social world is constructed (Venturini, 2009).
Jerusalem is a city in the Middle East with a capital claimed by both the State of
Israel and the State of Palestine and whose status as a capital city is one of the
longest running disputes on Wikipedia (“Wikipedia,” 2014b). The city’s borders and
governance have changed significantly over the years, most recently after the 1967
(‘Six Day’) war between Israel and the neighboring states of Egypt, Jordan and
Syria, when Israel annexed East Jerusalem from Jordan. Many Palestinians foresee
Jerusalem as their future capital but there is no widespread international recognition
for Jerusalem (as composed of both East and West parts) as the capital of either
Israel or Palestine. Such disagreement is reflected in the very different perspectives
on ‘basic facts’ about Jerusalem in the Arabic and Hebrew versions of the
encyclopedia and in the heated and long-running disagreements on the text of the
English version (to be discussed in more detail later in the paper).
Jerusalem was therefore an appropriate place to start for questions of how such
disagreements are resolved in semantic web initiatives such as Wikidata, and how
they are consequently represented on Google’s search results. In order to
understand how the city’s contested political contexts are embedded into its digital
layers, we traced some of the key ways that the city is digitally represented. We did
this by analysing representations of Jerusalem across the Arabic, Hebrew and
English versions of Wikipedia (working with a translator on the Arabic and Hebrew
versions), and on Wikidata, Freebase and representations in Google search results.
Other search engines such as Microsoft’s Bing also engage in Semantic Search using
Wikipedia, but we decided to focus on Google because of its widespread usage in
much of the world as the default search engine.
In our following of the Jerusalem entity through this network, we were inspired by
George Marcus’s method of ‘following the thing’ (Marcus, 1995) with a focus on two
key questions: 1) Does the semantic web live up to its promise of centralizing
meaning across different sites? and 2) How does this change impact ordinary users’
abilities to speak back to the data about the cities in which they live?’ We

7

operationalize these questions by analyzing a) the content and design of content
about Jerusalem b) the affordances available for the editing and contestation of
information on each platform, and c) the discourses employed by all four platforms
that guide how information is displayed and contested.
It is important to note that our search results are undoubtedly influenced by where
we are located, our language preferences and browsing history when pursuing this
study. Because of the proprietary nature of Google’s algorithms, it was not possible
to obtain information about how they results are structured, but we tried to mitigate
this by asking collaborators around the world, in different languages, to make the
same queries and found that the data that we were most concerned with (the ‘facts’
in the right hand results table) were the same. We were also able to use what David
Berry (2014) calls ‘coping tests’ to learn about software by deliberately hacking it
(although in this case, we merely tested it by pressing ‘wrong?’ buttons on Google,
flagging entries in Freebase and editing Wikidata entries in order to understand how
the process worked).
In addition, we have consulted and coded a variety of documents and discussions
including Wikipedia talk pages, policy pages, infobox discussion pages, Wikidata
process documents, talk pages, as well as a variety of external articles discussing
the values and threats of these initiatives in this project. We also conducted
informal interviews by posting questions to the Freebase mailing list, to Quora
(unanswered as yet), on Facebook and in personal email correspondence with
volunteers and employees. We also attended an ‘Open Data’ event in London to
gain a better sense of the community practices and discourses governing these
initiatives.
The Jerusalem case
We first trace how Jerusalem is represented on the Arabic, English and Hebrew
versions of Wikipedia, and then on Wikidata, Freebase and Google. We go on to
describe the affordances of the technology on each of these platforms in terms of
their ability to be contested by ordinary users.
1. Similarities and differences in the presentation of information about
Jerusalem
Although the four of these sites are connected via their semantic databases
(Wikidata pulls some information from Wikipedia, Freebase pulls regular dumps from
Wikipedia, Google pulls information from all three as well as from user preferences
and search queries), they all exhibit differences in the way that they represent the
city of Jerusalem. We focus on two key differences below: the different descriptions
of Jerusalem on each of the sites, as well as differences in population figures for
Jerusalem and the way that those figures are cited.

8

a) Labels and descriptions
We begin our analysis with a search for the text string, ‘Jerusalem’ in Google and
follow the links from Google’s Knowledge Graph to its representation on Wikipedia
and Wikidata in Arabic, Hebrew and English.
The first thing one notices when analyzing the representation of Jerusalem on all
platforms is the difference in the top-level description of the city. One important
decision that has been made is that Google represents Jerusalem in the Knowledge
Graph as the ‘Capital of Israel’ (figure 2). In other words, if a user searches for
“capital of Israel” in Google, they receive a page (figure 2) very similar to the one
they would see if they were to search for the “capital of France” (figure 5) or the
capital of many other countries. It is only if a user searches for the “capital of
Palestine” (figure 4) that they receive initial signification of the complex status of
the city.
Looking at figure 2, a user might be mistaken in understanding that this information
comes from Wikipedia. However, the statement that Jerusalem is the capital of
Israel, in fact, the source of one of the oldest debates in Wikipedia history
(“Wikipedia,” 2014b) and does not reflect the current consensus on the English
version of the Jerusalem article or the English version of the Wikidata item (both of
which present a more complex framing for the capitals of Israel and Palestine).

9

Figure 2: The results of a Google search for ‘jerusalem’

10

Figure 3: The results of a Google search for ‘capital of Israel’

Figure 4: Results of a Google search for ‘capital of palestine’

Figure 5: Results of a Google results for ‘capital of france’

11

Opening description of Jerusalem (on 16 July, 2014)

First
line/s

Google
Knowledge
Graph

Wikidata

Wikipedia
(Arabic)

Wikipedia
(English)

Wikipedia
(Hebrew)

Capital of Israel

City in the Middle
East, claimed as
capital by Israel
and Palestine

Jerusalem
(Hebrew:‫יורוָש ליַלִיי ם‬
‫ ) ִי ש‬is
the biggest city in
historic Palestine
in terms of area
and population.

Located on a
plateau in the
Judean Mountains
between the
Mediterranean
and the Dead
Sea, is one of the
oldest cities in the
world.

Yerushalayim
(Arabic: Al-Quds
or Urshalim) is
the capital city of
the State of Israel
and its largest
city.

n/a

933,113 (2012)
(no citation
source)

890,428 (2013)
(link to
moin.gov.il PDF in
Hebrew)

815,308 (2012)
(cite to the CBS –
Central Bureau of
Statistics in Israel

Jerusalem,
located on a
plateau in the
Judean Mountains
between the
Mediterranean
and the Dead
Sea, is one of the
oldest cities in the
world. Wikipedia
Populati
on
figures

12

780,517 (2010)
UNdata (link to
the UN population
data page)

If a user clicks on the ‘Wikipedia’ link in the Google Knowledge Graph results,
they will be directed to the English version of the Jerusalem article on Wikipedia.
The approximately 24,000-word Wikipedia article contains sections on
Jerusalem’s history, politics, geography, education and culture, as well as ‘further
reading’, ‘external links’ and a list of its 375 citations to books, newspaper
articles, academic papers and government documents used in the article 5.
Figure 6: Section of the Jerusalem infobox on English Wikipedia as at 13 July,
2014
The infobox on the right hand side of the Wikipedia
article contains seven images of Jerusalem from
different vantage points and with different focal points
followed by a series of statements. These include the
names of both the Palestinian and Israeli mayors, a
statement that Jerusalem is ‘claimed by both Israel
and Palestine’, as well as statements about the area
and population of the city and the metropolitan area,
its time zone and official website.
This careful wording is the result of long-running
disputes about the representation of Jerusalem in the
English version of the encyclopedia. Due to ongoing
edit warring, and an inability of editors to reach
consensus on how Jerusalem should be represented, a
series of rulings (“Wikipedia,” 2014b) were initiated by
Wikipedia administrators to reach at least partial
consensus on the opening paragraphs of the article
and to lock those edits for a period of three years,
among other remedies.
On the Hebrew and Arabic versions of the article,
editors have been able to take a very localized stance
on the representation of this controversial city. On the Hebrew Wikipedia,
Jerusalem is described as the ‘capital city of the state of Israel’, whereas on the
Arabic Wikipedia, Jerusalem’s relationship to Israel is described as an
‘annexation’ and includes a statement that the international community does not
recognize that Jerusalem’s capital status in Israel. This understanding is reflected
in the different appearances of the infoboxes on both sites. On the Hebrew
Wikipedia, the infobox mentions only the Israeli mayor whereas the Arabic
version displays both the Palestinian and Israeli mayors, with the ‘country’
represented as both Palestine and Israel. The listing of Israel in the Arabic version
is followed by the words, ‘occupied/disputed’ in parentheses.

5 There are additional articles relating to the Jerusalem metropolitan area on Wikipedia, including
West Jerusalem and East Jerusalem. These articles are also reflected in the Google Knowledge
Graph.

Figure 7: Selection of the Arabic and Hebrew infoboxes from the ‘Jerusalem’
articles on Arabic and Hebrew Wikipedias
The Wikidata entry has recently become a venue for new disputes about
Jerusalem’s representation. In early 2013, a group of editors from the Hebrew
Wikipedia tried to change the description tag of the Wikidata entry for the
English interface6. It had originally been populated with the description: ‘A city in
Israel’ by Wikidata administrator, Ymblanter. Other editors came the entry to
produce descriptions in Russian, German, Italian, French and Spanish in the
following months, all of which emphasized Jerusalem’s capital city status in
Israel. After the administrator, Ymblanter reverted an edit to the description from
‘a city in Israel and Palestine’ back to the original, a Hebrew editor changed the
description yet again to ‘Capital city of Israel’.
Ymblanter discussed the disagreement in how to represent the city on the
Wikidata project chat, asking for help from other Wikidata project participants in
6 Each language version can have their own descriptor tag or ‘label’, but, like Wikipedia, the standard
English version is the one that is most controversial.

the item’s talk page after three Hebrew Wikipedia editors came to the page to
revert the description back to ‘Capital city of Israel’ and seven editors to support
those changes in the talk page debate. Ymblanter referred editors to the project
chat7 to conduct the discussion but it continued on the talk page with the Hebrew
Wikipedia editors providing similar arguments to those used in the Wikipedia
debates centering on Israel’s recognition of Jerusalem as the capital. Wikidata
editors attempted to halt the edit warring by noting that the description tag only
serves as context for the item (distinguishing it to the reader from Jerusalem, the
band, for example) and that this was no place for ‘political wrangling’ 8.
In summary, there are key differences both in the content of information that is
represented on Google’s Knowledge Graph, Freebase, Wikipedia and Wikidata
and the way that it is represented. Although the opening paragraph about
Jerusalem on the Google Knowledge Graph representation of the city contains a
link to the English-language Wikipedia article, Google represents Jerusalem
unequivocally as the Capital of Israel and contains no reference to Palestine,
whereas both the introductory paragraph and infobox statements in the Englishlanguage Wikipedia article (and in its representation in Freebase) refer to
Jerusalem as a capital city claimed by both Israel and Palestine.
The English Wikipedia article for Jerusalem lists both Israeli and Palestinian
mayors, as well as administering entities as both the Israeli District and the
Palestinian Protectorate and Wikidata now also refers to Palestine in one of its
statements (‘country: State of Palestine’, ‘refers to part: East Jerusalem’). Thus,
although Google claims that the description of Jerusalem originates from
Wikipedia, it leaves out a key sentence in the opening description from the
Wikipedia article that complicates Google’s representation of Jerusalem simply as
the ‘Capital of Israel’.
Finally, if we look at the Freebase entry for Jerusalem, it appears that the
statement representing Jerusalem as the capital of Israel originates from the
Freebase entry for Jerusalem where it is formed by two structured statements
(‘Country: Israel’ including the statement: ‘Capital’). Here we see how a series of
apparently obscure database entries can make such a powerful political point
with equally powerful effects for those living in the region.

7 The project chat https://www.wikidata.org/wiki/Wikidata:Project_chat is a space on the
Wikidata domain for editors to discuss ‘any and all aspects of Wikidata’
8 The latest description used for the city in the English Wikipedia, as of the writing of this
paper, is ‘holy ancient city on a plateau in the Judean Mountains’

Figure 8: Selection from the Jerusalem item on Freebase.com
Contrary to the claim that the semantic web enables shared meaning across
different sites, then, there are decisions being made in each of these contexts to
decide on representations that align with some perspectives at the expense of
others (in most cases, these tend not to be decisions that favour Palestinians).
This inquiry demonstrates that the semantic web does, indeed, strip the content
from its context so that the content can be shared across sites. But what is lost
when Google serves decontextualized information from Wikipedia is the
accompanying contestations (in the form of talk pages, RFCs, administrator
cases and edit restrictions) that are an essential part of not just Jerusalem, but
most other places that we create, inhabit, and enact. Additionally, the content,
once transferred is not context-free: it is now housed within the new political and
economic context of Google, where the logic of efficiency and economically
powerful users are prioritized.
b) Population figures
In addition to the opening statements about what Jerusalem is, we also focus on
the population statistics for Jerusalem on all platforms. Population statistics are
inherently political. By definition, they serve as a signifier for who is actually
counted and contained within the borders of a city. That is, they tell us
something about both the boundaries of the city and who is counted as being
within those boundaries. In Jerusalem population statistics furthermore often
depend on government institutions like the Israeli Central Bureau of Statistics
(CBS) when such institutions are not recognized by the Palestinians and depend
on which of the contested borders are being recognized by the counting body.
The population figure for Jerusalem that is listed in English Wikipedia (on July 21,
2014), 890,428 does not specify a date but contains a link to a PDF in Hebrew
from the Israeli Interior Ministry website
(http://www.moin.gov.il/Subjects/Bchirot/Documents/num-member.pdf). This is an
official document dated 9 July, 2013 and signed by the Israeli Minister of the

Interior, Gideon Sa’ar. This population figure, then, is clearly attributed to, and
created by, the Israeli government. When Google’s Knowledge Graph represents
the population, 780,517 (2010) with a citation to UNdata, there is less immediate
clarity.

Figure 9: Population data from the English Wikipedia Jerusalem article (left) and
from the Google Knowledge Graph representation (right)
UNdata has collected census figures from national governments and is therefore
not the author of the study in this case, but in order for this to be revealed, a
user would have to click on the ‘UNdata’ hyperlink in Google, search for ‘Israel’
and then discover a figure which is larger than the Google figure by 15,687
people (it is 796,204). This is probably because the UNdata site
(http://data.un.org/) houses the more recent (2013) figures. The user would see
this figure accompanied by two notes:
‘2 - Designation and data provided by Israel. The position of the United
Nations on the question of Jerusalem is contained in General Assembly
resolution 181 (II) and subsequent resolutions of the General Assembly
and the Security Council concerning this question.
3 - Including East Jerusalem’.
A problem with these statistics is that their true institutional origin is obscured,
especially within Google’s domain. Following the link from the population number
for Jerusalem, the user is taken to a Google ‘Public Data’ page that shows the
source as UNdata rather than providing access to the specific dataset and the
method by which the data was selected. The UN’s ‘Public Data’, in other words,
has been extracted from the UN by Google and framed within their own domain.

Figure 10: Screenshot of Google results after clicking on the population figure for
Jerusalem
To some extent, all platforms obscure the actual origins of the population figures.
The English Wikipedia article cites the Israeli CBS and includes a link to the PDF
but the PDF is in Hebrew and thus unintelligible to non-Hebrew speakers. The
Arabic version (the highest figure at 933,113) contains no citation. The Hebrew
version is perhaps most transparent because it cites the CBS and users can at
least read about the origins in their own language. There is, however, no clear
provision of methodological information that accompanies the figures so that
users can understand how they were arrived at, even if they did speak Hebrew.
Despite this, Google’s population figures are most obscured, as is the case in the
previous example of descriptive statements. As the data moves from national
statistics offices to UN statistics offices to the UNdata platform and to Google and
Freebase, the numbers are iteratively stripped of the national and institutional
context that gave rise to their very particular result. This stripping of contextual
information is not a de-politicization of the data, but rather, it proposes a new
political position in the selection of particular figures from specific agencies.
2. Opportunities for ordinary users to contest and develop consensus
around the representation of Jerusalem
In this section, we trace how users are attempting to influence what data is
reflected in Google, Wikipedia and Wikidata, how consensus is reached on these
platforms and what the affordances are for this to happen.
a) Editing in Wikipedia
In the majority of cases, both the container (the infobox) and the content (the
information in the infobox) are editable by any ordinary user on Wikipedia.
Ordinary users are users (logged in or not) who operate at the lowest level of

permissions within the Wikimedia platforms (“Wikipedia,” 2014c). Users can click
on ‘edit’ and edit the statement or relevant infobox directly and/or start a
conversation about their edit on the talk page of the relevant article. Ordinary
users’ ability to edit and participate in the representation of content on the
English version of Jerusalem is limited, however, due to the article’s current
semi-protected status. Users may not edit the opening paragraph of the article
(written as part of an arbitration case and set until January, 2015) and they may
only perform one reversion in a 24-hour period. This does not prevent users from
editing content in the infobox, but they will probably have to gain consensus on
the talk page in order for the edit to stick because of the fact that the page is so
closely monitored by ordinary users and administrators alike.
Similarly, the ability to edit the template used for the infobox on the Jerusalem
article (infobox settlement) is limited to ‘template editors’ and ‘administrators’ 9
because the template is used on almost half a million articles. Ordinary users
must request an edit by filling out a form suggesting a change to the template
and including reasons for the change. Editors can keep track of edit requests by
watching pages added to by a bot that indexes these requests, or by watching
the relevant page. The infobox settlement template is rarely edited (about 15
times in the first half of 2014).

Figure 11: Attempting to edit the Jerusalem Wikipedia article
https://en.wikipedia.org/w/index.php?title=Jerusalem&action=edit as at 7 July,
2014
b) Editing in Wikidata
9 Template editors are editors (must be registered for over a year with at least 1,000
edits and at least 150 to templates) who are granted special privileges for editing
protected templates. Administrators are Wikipedia editors who have been granted the
technical ability to perform certain special actions on the English Wikipedia including the
ability to block and unblock user accounts and IP addresses, protect and unprotect pages
from editing, amongst others.

The infobox for the Jerusalem article on English Wikipedia does not currently use
data from Wikidata since a template needs to be created in the article in order to
call data specifically from Wikidata item.

Figure 12: After clicking on ‘edit’ button adjacent to the description of the
Jerusalem item (number Q1218) with language preference set to ‘English’ as at 8
July, 2014
If editors decide to employ Wikidata in populating this particular infobox 10,
editors will have to navigate to the Wikidata website to edit information rather
than being able to edit it directly in the relevant Wikipedia article. Editors can
click on the properties contained in the statement (‘coat of arms’: ‘Emblem of
Jerusalem’, for example, below) to edit the item. They can also discuss changes
in the ‘Discussion’ page but this needs to take place in a single language
(English). Editors also find that they must learn the norms and architecture of a
new site in order to participate in Wikidata editing.
Wikidata outlines how users should add citations to particular statements and
asks for editors to replace current references that indicate the site from which
the data was imported with the ‘reliable, secondary’ source that can verify
statements. In the case of the Jerusalem item in Wikidata, there are currently no
secondary sources identified and the only reference is to ‘English Wikipedia’ from
which the ‘Emblem of Jerusalem’ was imported.
This is contrary to the prediction of how disputes would be resolved in Wikidata.
In response to an editorial on Wikidata in 2013 written by one of the authors of
this paper (Graham 2012), then-Wikidata project director, Denny Vrandecic
stated that the way that editors would resolve disputes would be to each bring
reliable sources to support diverging statements.
‘First, Wikidata will not be about The Truth. I expect the Wikidata
community to follow the spirit of the Wikipedia community, and require
10 Infobox data has been enabled in Wikidata but the inclusion of Wikidata statements in Wikipedia
articles must be enabled by editors at an article level

citations and references for the data. We do not expect the editors to
agree on the population of Israel, but we do expect them to agree on what
specific sources claim aboiut the population of Israel. They will be able to
gather several sources with their sometimes contradicting data. So we
might have the population according to the Israeli statistics office,
according to the Egyptian staistics office, according to the CIA World Fact
book, and according to even more sources. Instead of hiding these
differences in their respective language editions, we can have one space
to gather them all and display them side by side, making the
disagreement explicit and visible. (Vrandecic in Graham, 2013)
According to Wikidata policy on sources (Wikidata, n.d.), statements do not
require citations when they are ‘common knowledge’ and where ‘these are
obvious to anyone looking at the item’. Each side will likely continue to present
their own statement about the status of Jerusalem as so ‘obvious’ that it does
not require a citation, and since there are few Palestinian supporters currently
involved in the dispute, this is likely to only continue in the future.

Figure 13: The ‘coat of arms’ for Jerusalem is the ‘Emblem of Jerusalem’ imported
from the English Wikipedia as reference.
Clicking on either ‘Emblem of Jerusalem’ or ‘coat of arms’, in Wikidata, enables
users to edit the associated property and value since each has their own page or
item number on Wikidata. If users wish to delete an item or a property, however,
they must make a request for deletion or contact an administrator if it is ‘obvious
vandalism’ https://www.Wikidata.org/wiki/Wikidata:Requests_for_deletions. When
items are deleted, a reason will generally be provided on the ‘requests for
deletion’ page and the deleted item will provide a log of the reason for deletion
and the action taken (see below).
Although Wikidata is the most edited Wikimedia project with about half a million
edits per day (about three times as many as the English Wikipedia), about 90%
of these edits are made by bots that contributors have created for automating
tasks (Vrandecic & Krotzsch, 2014). The majority of editors are technically
proficient because tasks (especially at this early stage) are about writing
programs to extract large data sources into the database. Edit wars are rare right
now, but when more Wikipedia editors start calling data from Wikidata to the
article space, it is possible that that will change.

Figure 14: Deletion page for item number Q9596893 in Wikidata relating to the
‘choral music’ category in Wikipedia and Wikimedia Commons
https://www.Wikidata.org/w/index.php?title=Q9596893&action=edit&redlink=1
c) Editing in Google
In small, grey lettering below the Jerusalem infobox in Google is the word
‘Feedback’. Clicking on this button makes a series of hyperlinked ‘Wrong?’
buttons appear next to each statement in the infobox. Users have the option of
adding a description of what is ‘wrong’ with the information reflected, as well as
to provide a ‘url’ with supporting evidence. No information is available about
what happens to user’s feedback once they’ve provided it. According to a Google
employee, ‘We collect this feedback, process it, and usually it gets fixed after a
while. If the data originated from Wikipedia, we used to share that back, but
there was no interest in that data.’ (cite) The Google employee noted that they
were ‘curious (about) how Google could provide feedback to Wikipedia best’ and
that they were ‘concerned that whatever (they) do it might be regarded as a big
corporation dabbling with Wikipedia, which is why (they) rather err on the side of
not sharing’. He dismissed sending users to Wikipedia to edit the article directly,
however. ‘(J)ust grab a non-Wikipedian, put them in front of an article, and ask
them to change something in an infobox. This will not result in a desirable UX.’

Figure 15: Screenshots after clicking on ‘feedback’ and clicking the ‘Wrong?’
hyperlink above the Jerusalem headline on google.com
If the user clicks on the population figure for Jerusalem and is taken to the
Google ‘Public Data’ platform, they might click on a ‘Discuss’ link that links to a
Google group where users have been posting questions unanswered for months
by Google employees (https://groups.google.com/forum/#!forum/public-datalabs). On May 13, 2014, one user posted:
‘Croatia is listed in the group of "Non EU countries". Actually it is part of
the EU since 1 July 2013.’
This user has not yet had a reply as of July 16, 2014.
Thus, despite the appearance of an information source that is responsive to
feedback (i.e. with the ‘wrong’ hyperlinks), users of Google ultimately have very
little voice in the construction and presentation of codifications of the cities that
they live in.
In summary, whereas Wikipedia enables editors to participate in the editing and

consensus building around content, providing rules of participation and clearly
defining who has greater power to affect change and make decisions as
administrators, on Google, users can provide feedback but such feedback is not
responded to, nor are there any rules available on how such decisions are
actually made and by whom. In addition, Google does not send users directly to
the Wikipedia discussion page to query the Wikipedia data, and it is unclear
whether Google does anything with this feedback. In the case of feedback on the
‘public data’ housed by Google, employees do not seem to track questions in the
message boards, leaving it to other users to perform user support on their behalf.
Queries such as reproduction of certain figures, however, cannot be answered by
other users but by Google alone.
While providing editors with similar affordances to Wikipedia to edit statements
and items, Wikidata restricts the ability of non-English speakers to fully
participate in debates since there is only a single talk page for each item – an
item that can be employed by all 286 versions of the encyclopedia as well as
other Wikimedia projects that make use of the data. Additionally, the abstraction
of structured data on Wikipedia to Wikidata means that Wikipedia editors need to
learn how to edit Wikidata calls, to learn community norms and gain a reputation
within Wikidata so that they can become effective members. This puts increasing
pressure on volunteers and continues to favor those who have the time to
dedicate to such activities.
Discussion
When we look at the example of Jerusalem in Wikipedia and see how information
produced by volunteer editors is used across Wikidata and Google, we notice
some important differences in both the content and the practices associated with
that content. Firstly, although the semantic web promises to centralize meaning
across different sites, there are clear differences in the representation of
Jerusalem across these different platforms. Wikipedia’s structure enables both
Arabic and Hebrew versions to present information about Jerusalem significantly
differently in both the body of the article and in the infobox. The highly contested
English version brings these two together in ways that reflect its position within
both Israel and Palestine, but this is not reflected in the English version of the
Google Knowledge Graph. None of the qualifiers in the Wikipedia infobox or the
Wikidata description or even Freebase’s use of a ‘disputed territory’ qualifier
makes it to Google’s Knowledge Graph.
When information moves from the highly contested and editable space of
Wikipedia to structured databases such as Wikidata, Freebase and Google, it
loses a connection to its contested and unstable nature. According to user:Cla68,
a respondent to a magazine article about Google’s impact on Wikipedia through
the Knowledge Graph (Kohs, 2014), this trend can be seen most starkly in the
presentation of information about Indian politician, Kanu Sanval. S/he notes that
the Wikipedia article for Kanu Sanval (“Kanu Sanyal,” 2014) includes a “citation
needed” tag in the introduction, but the Knowledge Graph results for that article

that shows up when a user uses Google to search for “Kanu Sanval” does not
include that tag. This eradication of evidence of the instability of a particular fact
may appear more aesthetically pleasing and user-friendly from Google’s
(minimalist) perspective, but it conceals important complexity and instability.
In addition to the highly contested description for Jerusalem, there are other key
differences in the representation on different platforms that show that data and
meaning are not shared across sites. One example is the population figure for
Jerusalem on Wikipedia, Freebase and Google Knowledge Graph. Each has a
different figure for population, and each is characterised by a certain level of
obscurity due to factors such as an inability to add citations, an inability to
supply metadata and other methodological information, and an inability to
provide affordances for non-English-speaking users. These problems are most
distinct on Google, however, since it houses data from the United Nations on its
own platform, does not provide a direct link to the actual figures, nor does it
make it clear that the figures actually come from the Israeli CBS rather than the
UN. This has a significant impact on users’ ability to understand and help
improve or at least to contest information that is incorrect.
This means that the average audience member has difficulty evaluating the
veracity and basis for data presented on these cites. If someone were to contest
the figures, it would be more difficult for them to critique those presented on
these sites because they do not know the source or the basis of these figures
that would enable them to construct their critique. Thus, the decontextualization
of population data as part of this semantic web project reduces the ability of
ordinary users to speak back to representations of the cities that they live in or
contest information presented about their lived environments.
Such differences in representation are not seen by Wikidata engineers as
valuable in their own right but as errors that need to be fixed. In an interview
with the then-project director of Wikidata, Denny Vrandečić (now Google
Knowledge Graph employee), the interviewer asked the question: ‘When info
exist in both WD (Wikidata) and FB (Freebase) and it differs, what would you like
to see done?’ to which he answers: ‘The difference to be fixed, obviously! Both
knowledge bases may and do contain errors, and the ability to compare them
can lead to an increased quality level in both. It is obvious that the respective
communities should take care of such errors in their knowledge bases. By
providing links between the knowledge bases, this should get easier to
automate.’ (Meijssen, 2013) Vrandečić and Krotz (2014) note that the existence
of ‘different population numbers for Rome, for example’ is a ‘threat to
Wikipedia’s main goal of providing up-to-date and accurate encyclopedic
knowledge’ (p1). That this goal is chosen over the goal of providing access to the
‘sum of all human knowledge’ (Wikimedia Foundation, 2014) is important
because it explains the focus on centralization and consistency, rather than
diversity and plurality.
One key reason for this is the fact that semantic web discourses are made to

seem a) apolitical and b) ‘purely technical’. In the Wikidata talk page for
Jerusalem, for example, many editors seems to be accusing one another of
pushing a political agenda. Ymblanter, the administrator who started the page,
was accused by User:Hanay of pushing a political agenda when he changed the
description from ‘City in Israel’ to ‘City in Israel which Israel claims to be its
capital’ after Hanay tried changing it to ‘Capital city of Israel’ and another editor
tried changing it to ‘A city in Israel and Palestine’. Both Hanay and Ymblanter
accused one another of pushing a political agenda, asserting their own versions
of what is the ‘clearly neutral’ description (Ymblanter’s talk page
https://www.Wikidata.org/wiki/User_talk:Ymblanter). Wikidata is seen as a place
for facts, not politics as seen in the statement below.
‘Wikidata, on the other hand, does not have any political aims in making
statements acknowledging the existence of certain facts.’ (User:Yair rand,
Wikidata talk page for Jerusalem, 5 February, 2013).
Wikidata users have tended to deride those who are arguing about what the
Jerusalem description should be for their ‘pointless bickering’
(User:Sean.hoyland, Wikidata talk page for Jerusalem, 5 February, 2013).
Wikidata editors believed that is was ‘pointless’ because the descriptions are
technically only used to ‘disambiguate’ items with the same or similar labels
rather than as a semantic statement that can be used across sites. The article
about Wikidata ‘descriptions’ (https://www.wikidata.org/wiki/Help:Description )
urges editors to ‘avoid controversial claims’ and to describe the Pinnacle
Islands11, for example, as a ‘group of islands in East Asia’ rather than ‘a group of
Japanese islands’ or a ‘group of Chinese islands’. The problem is that each group
of editors believes their own perspective to be non-controversial and through
discourse can expound their conception as a concession by defining what they
believe the NPOV position to be.
In summary, as information moves from Wikipedia to Wikidata, Freebase and
Google, not only does the information reflected change, the process of editing
becomes increasingly complex, its discourses focus on the semantic sites as
apolitical and highly technical spaces, and the corresponding rules for, and
expertise with dealing with controversy are increasingly obscured. This has an
impact on the ways in which local people are able to participate, challenge and
speak back to representations of place.
The issue is not just one of content being separated from its contexts through
the logics of the semantic web, but also that content being instilled in a new
political context on Google, where users are not able to speak back to the data
that they themselves helped build. Due to their powerful and trusted position as
information providers Google is often the primary source for information for
individuals making search queries. They are able to utilize peer-produced
Wikidata and Freebase content but in a format that is less transparent and
11 The Pinnacle Islands (also known as the Senkaku Islands) are claimed by Japan, the
People’s Republic of China, and the Republic of China (Taiwan).

reduces that ability to regular users to speak back to the representations of their
lived environment.
Conclusion: Code, Content, and Cities
Wikidata is a notable departure from the kind of visibility architected into
Wikipedia where knowledge was represented as ‘contested, contingent, dynamic,
and overtly the result of political processes’
As our cities become increasingly digital (c.f. Kitchin and Dodge 2011; Graham
et. al. 2014), and as the digital becomes increasingly governed by the logics of
the semantic web, there are important questions to ask about how these new
alignments of code and content shape how cities are presented, experienced,
and brought into being. What we found is that semantic web initiatives attempt
to separate information about our cities from the contexts of their creation and
that this has unexpected consequences. Rather than connecting sites through
shared meaning by divorcing the content from its context, this process creates
new contexts in which necessarily political decisions are being made with far
reaching consequences.
By attempting to separate content from its contexts in order to move it to new
containers, knowledge bases are increasingly distancing (and in some case
cutting off) debate about contested knowledges of places. This effect is achieved
by transferring data about cities from Wikipedia’s participatory framework to
sites like Wikidata, Freebase and Google where the affordances are less
participatory, where the rules are increasingly opaque to the average user and
where the discourses are that these platforms are apolitical and highly technical.
When user-generated knowledge reaches the veiled confines of Google search,
users lose an ability to effectively contest and change information that forms a
key component in the representation of places. Users receive no feedback, there
is no visibility of the process by which decisions are made, and cannot read the
rules that guide such decision-making.
Categorization and classification of information about places offer enormous
efficiencies. Linked data organized through the Semantic web can be much more
easily integrated, repurposed, collected, classified, published, and indexed. Data
will also undoubtedly be more accurate and more current on the whole. But the
move to the Semantic web also means that many decisions about how our places
are represented are increasingly being made by people and processes far from,
and invisible to, people living under the digital shadows of those representations.
Although data can appear clean, simple and factual, the processes, practices,
people, and places that linked data attempts to represent are far from it. But it is
through linked data and the logics of the semantic web that visibilities of
contested knowledges are being divorced from their origins and cleaned up
through categorization and made to look legitimate. Categorization and
classification creates obvious efficiencies, but through those processes we could
lose the connection to the local contestation of knowledge. This calls into
question the extent to which local citizens can determine the representation and

find a voice in the co-construction of the digital augmentations of their cities.
Despite this pessimism, we believe that much can be done to combat this
situation. In order to retain as much informational context as possible as data
moves from sites like Wikipedia to Google, mediators like Google need to make a
better attempt at laying bare the origins of the information that it now hosts, and
to provide opportunities for ordinary users to participate in the improvement and
contestation of that data. Wikidata needs to do the same: prioritizing the ability
of users to cite the statements that are being made and providing more userfriendly mechanisms for editing statements at its origin. Wikipedians have an
important bargaining chip as they decide whether to employ Wikidata in their
projects, something Wikidata knows that it needs in order to improve the data.
In addition, Wikidata needs to recognize early on that they too are a site for
political contestation and that they need to build the functionality and
experience within their administrator community to deal with such disputes
when they arise. Despite Wikidata employees claiming that ‘Wikidata will not be
about the Truth’ (Vrandencic in Graham, 2013), Wikidata is employed as a
repository for truths about our planet, and will therefore exert significant impacts
on our informational environments.
Because platforms like Wikipedia and mediators like Google are becoming not
just central gatekeepers of information, but also integrated parts of our cities, it
is important that different communities are able to create, reproduce, and
represent different truths and worldviews on, and through, those platforms. And
while certain truths are universal (Paris is generally considered to the
uncontested capital city of France), others are more messy and unclear (e.g.
should the population of Israel include occupied and contested territories?).
The reason that the rise of the semantic web matters is because it not only
eliminates some of the scope for culturally contingent representations of places,
processes, people, and events, but also depoliticises and obfuscates some of
those processes of representation. Potentially even more concerning is that fact
that centralised and linked data organised under the logics of the semantic web
are unlikely to reflect the opinions and beliefs of traditionally marginalized
groups. Disagreements over places and the ways that they are represented are
no longer just confined to specific informational silos: they instead must involve
central databases that are unfamiliar contexts to most Internet users.
In following two types of contested urban information through the semantic web,
we have shown how the semantic web is ultimately making the messy political
informational layers of cities more transparent to machines and more opaque to
humans. Many of these projects are evolving: it remains to be seen how
Wikidata, for example, designs citation mechanisms for statements in its
database or whether Wikidata becomes extensively used by Wikipedia and other
Wikimedia projects. Our hope is that future work can further disentangle the
ways that information about places moves across contexts, places, and platforms
as these initiatives evolve. The semantic web has important implications for

representation, voice and ultimately power in cities, and we need to ensure that
we aren't seduced into codifying, categorizing, and structuring in cases when we
should be describing the inherent messiness of a situation. If we ever hope to
move towards a goal of more inclusive informational cities, we need to first
better understand how the semantic web changes urban life. We thus hope that
this paper can serve as a first step towards more sustained interrogations of
inclusions, exclusions, modes of participation, and practices of representation in
the semantic web.
References
Berners-Lee, Tim; Fischetti, Mark (1999). Weaving the Web. HarperSanFrancisco.
pp. chapter 12.
Berners-Lee, Tim; James Hendler; Ora Lassila (May 17, 2001). "The Semantic
web". Scientific American Magazine
Berry, D. M. D. (2014). Critical Theory and the Digital. New York: Bloomsbury 3PL.
Graham, M. (2012, April 6). The Problem With Wikidata. The Atlantic. Retrieved
from http://www.theatlantic.com/technology/archive/2012/04/the-problemwith-wikidata/255564/
Kanu Sanyal. (2014, July 22). In Wikipedia, the free encyclopedia. Retrieved from
https://en.wikipedia.org/w/index.php?
title=Kanu_Sanyal&oldid=613473555
Kohs, G. (2014, January 6). Google’s Knowledge Graph Boxes: killing Wikipedia?
Wikipediocracy. News site. Retrieved from
http://wikipediocracy.com/2014/01/06/googles-knowledge-graph-killingwikipedia/
König, R. (2014). Society of the query reader: reflections on web search.
Amsterdam: Inst. of Network Cultures.
Lucas D. Introna, H. N. (2000). Shaping the Web: Why the Politics of Search
Engines Matters. The Information Society, 16(3), 169–185.
doi:10.1080/01972240050133634

Marcus, G. E. (1995). Ethnography in/of the World System: The Emergence of
Multi-Sited Ethnography. Annual Review of Anthropology, 24(1), 95–117.
doi:10.1146/annurev.an.24.100195.000523
Meijssen, G. (2013, November 20). Words and what not: #Wikidata & #Freebase
- an #interview with Denny Vrandečić. Retrieved from
http://ultimategerardm.blogspot.co.uk/2013/11/wikidata-freebaseinterview-with-denny.html
Pariser, E. (2012). The Filter Bubble: What the Internet is Hiding from You.
Penguin UK.
Vaidhyanathan, S. (2012). The Googlization of Everything: (And Why We Should
Worry). University of California Press.
Venturini, T. (2009). Diving in magma: How to explore controversies with actornetwork theory. Public Understanding of Science.
doi:10.1177/0963662509102694
Vrandecic, D., & Krotzsch, M. (2014). Wikidata: A Free Collaborative Knowledge
Base. Communications of the ACM.
Wikidata. (n.d.). Help: Sources/Items not needing sources. Wikidata. Retrieved
from
https://www.wikidata.org/wiki/Help:Sources/Items_not_needing_sources
Wikipedia:Arbitration/Requests/Case/Infoboxes. (2014a, July 21). In Wikipedia,
the free encyclopedia. Retrieved from
https://en.wikipedia.org/w/index.php?
title=Wikipedia:Arbitration/Requests/Case/Infoboxes&oldid=617840947
Wikipedia:Requests for arbitration/Palestine-Israel articles. (2014b, July 20).
Wikipedia, the free encyclopedia. Retrieved July 23, 2014, from
https://en.wikipedia.org/w/index.php?

title=Wikipedia:Requests_for_arbitration/PalestineIsrael_articles&oldid=617668489
Wikipedia:User access levels. (2014c, July 29). In Wikipedia, the free
encyclopedia. Retrieved from https://en.wikipedia.org/w/index.php?
title=Wikipedia:User_access_levels&oldid=617221831
Wikipedia:Wikipedia Signpost/2013-10-02/Arbitration report. (2014d, July 12). In
Wikipedia, the free encyclopedia. Retrieved from
https://en.wikipedia.org/w/index.php?
title=Wikipedia:Wikipedia_Signpost/2013-1002/Arbitration_report&oldid=588783132
Acknowledgements
Thanks to Dror Kamir for translation assistance. Thank you to Gillian Bolsover for
her comments and suggestions. Thanks to those from Freebase, Wikidata and
Google who answered our (many) questions.
This publication arises from research funded by the John Fell Oxford University
Press (OUP) Research Fund.

Coding alternative modes of governance: learning from
experimental “peer to peer cities”
Alison Powell
London School of Economics and Political Science
Prepared for the “Code and the City” workshop – NUI
Maynooth
24 July 2014
Introduction
Cities are by nature mediated, as well as mediating. As complex
human-built environments, they filter experience and present many
different ways for communication to take place. Urban
communication scholars have often talked about the inherent
dynamism of urban spaces where different people come together
and where new ideas and interpretations are born. Urban scholars
have started to consider this as a recombination of the technological
and social aspects of the city.
In the past twenty years this recombination has focused on the
coded city, from Gibson’s ‘city of bits’ to Kitchin and Dodge’s (2006)
assessment of coded passage points underpinning passage through
and presence in space. The techno-city and its new infrastructures
do perhaps create alternative or novel modes of expression or
different ways of living together with others. These modes may,
however, have much to do with how new communication
technologies are imagined as fitting into existing cities, both by the
institutional actors who are often the object of political economic
analyses, and by other city dwellers, including artists and activists.
New technologies are sites of social construction and cultural
debate, so their impact in cities should be considered not only in
terms of dominant or alternative modes of construction or use of
communication technologies, but in terms of the semiotic, affective
and relational process of meaning construction, which now must
take place within cities equipped with coded infrastructure that
ambiently records information within the city but also information
about its individual residents.
Undoubtedly, coded infrastructure impacts city life, in ways that can
largely be unconscious. Yet coded infrastructures do not necessarily
have to be imposed on the city from outside of it. They may emerge
from within the city, and by doing so demonstrate the connection
between different ways of considering the urban. Coding can be
sense-making, and building coded infrastructures, especially outside
of large institutions, can in turn require sense making – including
decisions about how the code-work should fit into a particular urban
space, and how it ought to be managed and sustained. This paper
develops a perspective on peer-to-peer engagements on the coded
1

city by analyzing how coding practice (in terms of creating
infrastructure) is related to the development of other social and
cultural ‘codes’ that propose alternative ways of integrating
technology into space. It argues that peer-to-peer coded cities are
most significant because they suggest alternative ways of governing
the interface between technology, the social, and the spatial.
To develop this perspective, we need to look at the dominant visions
of how ‘smart’ or ‘coded’ cities are imagined as being governed through reinforcement of top-down governance via centralized
control, or through facilitation of bottom-up engagement in urban
space and politics through the use of information, sensors, and data
processing as part of citizen engagement. We then position these
imaginings historically, considering how ICT projects of the past
were imagined as providing opportunities for collaborative
development and governance of particular urban spaces, in
opposition to top-down efforts at urban communication governance
taking place at the same time. We will see how these past projects,
which often focused on providing access to communication, link with
a ‘politics of the minor’ (Feenberg, 2011; Osborne and Rose, 1999)
that introduces more nuanced ways that individuals, through the
development of technologies, can contribute to effective
governance.
This perspective draws from a broad definition of governance as "all
processes of governing, whether undertaken by a government,
market or network, whether over a family, tribe, formal or informal
organization or territory and whether through laws, norms, power or
language” (Bevir, 2013). In this case, the object of such governance
is the city – or more precisely the code-mediated city - and the
governance itself consists of a set of norms, frameworks or
decisions that configure how ICTs ought to be integrated into city
space and life. While a narrow view of civic governance might focus
on the role of an formal organization (the government), our broader
view of governance here is concerned with the role of informal
organizations, including loose, peer-to-peer organizations who use
peer-to-peer methods to develop coded infrastructures that they
establish in city space.
Peer-to-Peer Urban technology visions
A number of different ICT-enabled projects have tried to establish a
‘peer to peer urbanism’ that would counteract or disrupt more
conventional efforts to bring ICTs to cities. This alternative
imagination of ICTs has developed simultaneously through
discourses, practices and architectures. The outcomes of the
2

attempts at creating peer-to-peer urbanism suggest that ICTenabled cities need meaningful governance of the integration of
technologies into cities – which encompasses how projects are
conceived and discussed (discourse), how they are constructed, in
code and in space (practice), and how they are built (architecture).
These three elements are all simultaneously co-produced, and all of
them have impact on the ability of people who live in cities to speak
and be heard. We use the framework of co-production to investigate
how peer to peer urbanism, as represented by community wireless
networks, establishes alternative governance modes through
discourse, practice and architecture. This analysis will help to
construct a framework for good governance than can then be
applied to future coded or ‘smart’ cities.
The top-down ‘smart city’
Smart cities” projects have emerged over the past decade in an
effort to apply technology to improving the urban experience. Most
smart cities projects have involved, to one extent or another, the
integration of networked communication or data transmission
devices into urban spaces. Dodge and Kitchin (2006) describe the
ways that these types of projects layer software-controlled spaces
over physical and geographic spaces, providing interfaces and data
processing layers that become embedded into the experience of
particular kinds of spaces. These software elements sort and control
the people and things that move through spaces, altering their
relationships. Smart cities projects promise to use the software layer
to positively augment the experience of urban space, for example
by using mobile apps to provide location-specific information. The
software-controlled layer is often perceived as being able to provide
information and calculation that are of broad social benefit: a 2012
collection edited by Foth et al identifies a number of social and
political projects that employ software layers including community
sensing (Salim 2012) and data visualization (Moere and Hill 2012).
“Smart” systems are intended to augment urban spaces: as Aurigi
and De Cindio write, “the gradual development of an enriched
media environment, ubiquitous computing, mobile and wireless
communication technologies, as well as the Internet as a nonextraordinary part of our everyday lives, are changing the ways
people use cities and live in them” (p. 1, 2008). These
augmentations include blending mediated data with built spaces,
presenting media on large screens or on personal devices, and
providing ways to visualize movements, decisions, and contextual
information.

3

These technological layers create data that is available for use by
various actors in various ways. Smart cities are seen on one hand as
being able to enact more efficient control of the complex systems of
cities by creating more data for cybernetic control systems
(Townsend, 2013) and on the other hand, to improve the day to day
decision-making of individuals through ‘street computing’ that
allows everyday users to take advantage of otherwise-hidden
computational interfaces within the city. This is achieved by building
or gaining access to sensor networks, tapping into publicly collected
open data, or employing APIs to capture, use and remix data
collected by mobile phone companies. This apparent opposition
between smart cities facilitating better cybernetic management and
smart cities providing more opportunities for citizens to improve
their own experience seems straightforward, but both the dominant
paradigm of centrally governed cities AND the alternative paradigm
of emergent citizen use of data-collecting ICTs depend on strong
interlinkages with commercial infrastructure and processing power.
One of the main questions at issue when considering this
‘augmentation’ is the way in which particular values are put forth
within proposals for one technological strategy or another. The ethic
of ‘street computing’ is on one level participatory and empowering,
as it seeks a way for individuals to make sense out of data flows, but
on another level it is deterministic and celebratory – like most
authors in this area, Moere and Hill (2012) introduce their
perspective on the opportunities afforded by smart cities with a
description of technological possibility: “recent advances in sensing
devices, wireless network connectivity, and display hardware have
made the ultimate vision of ubiquitous computing finally possible, in
which the ‘computer’ as we know it becomes embedded in physical
objects and surfaces of everyday life” (p. 28). Not only does this
framing imply a technologically-driven vision for the city, it also
implies some linear, forward motion towards that vision, which is
evoked as not just being desirable but inevitable.
Dominant perspectives: technology and cities as neutral
Dominant smart cities rhetoric and smart city projects imply a
neutral, if not straightforwardly positive role for technology within
the city. The city augmented by technology is normally considered
as an improved city, with improvements not only in the efficiency of
service provision created as a result of data collection architectures,
but without much of the messiness and dynamism that scholars of
the urban normally associate with city life. This means that smart
cities are often commercial cities or cities of privatized technology,
when vendors deploy particular systems into urban spaces. In his
critique of the dominant imaginary of smart cities, architect and
urban scholar Adam Greenfield suggests that one problem with
4

smart cities narratives is that they seem to refer to cities as if they
were not real, actual, different places. He writes, "“the canonical
smart city almost has to be staged in any-space-whatever; only by
proposing to install generic technologies on generic landscapes in a
generic future can advocates avoid running afoul of the knotty
complexities that crop up immediately any time actual technologies
are deployed in actual places” (Greenfield, 2013). Greenfield notes
how the discourses used to describe smart city projects by their
promoters encode an hypothesis that the contemporary urban
environment is too difficult for ordinary, unaided human beings to
understand and manage, and that some higher power (in this case,
information processing and computer-aided decision making) need
to step in. One of the consequences of this hypothesis sit that the
dominant vision for smart cities smart cities imagines them as as
‘clean’ and ‘legal’ places where data calculation systems pre-empt
disruptive or illegal activity. Data collection is perceived as operating
in much the same way that centralized surveillance systems do: as
a system of discipline in which the fear of being observed drives
exemplary behavior. Idealizing cities as entities that can be
abstracted and rationalized has a long history that encompasses but
extends past modernity. Expectations of both abstraction and
rationality characterized imaginings of the 19th century city – the
industrial, well-ruled and orderly city – as the model for government,
even while representations of the time returned over and over to the
actual city’s problematic immanence; its ungovernability, crime,
destitution, vice, gambling and drunkenness (Foucault 1984;
Osborne and Rose 1999). But because there is more than one way
of imagining the data city, and more than one way of structuring the
systems that are part of it, there are alternative visions for smart
cities too – much as there were alternative visions for previous
visions of exemplary city life.
Competing imaginaries of governance: a coded city of
‘minor politics’
Some of these alternative visions concern the ability for citizens to
leverage features of new technologies to experience urban life
differently. Urbanist Anthony Townsend suggests that the
technologies behind the smart city, including the sensor networks
and mobile technologies (especially including smart phones) have
made it possible for “a motely assortment of activists,
entrepreneurs, and civic hackers” to tinker with technology as a
means to “amplify and accelerate the natural sociability of city life”
(2013, p. 9). Instead of centrally controlling data collection,
Townsend focuses on how these people imagine a different kind of
data city – one that builds mechanisms to share data and creates
interfaces that allow different perceptions and navigations of city
spaces. This creates a new kind of ‘lattice’ that interconnects local
space and technology. This architectural layer forms one element of
5

peer to peer urbanism. Moving beyond Townsend’s concerns about
the technological capacities of the alternative smart city, we can
also consider the ways that peer to peer alternatives engage in
alternative organizational practices, and promote different kinds of
spatial engagement. These two additional aspects are essential
components of an expanded concept of peer-to-peer urban
governance.
Peer produced or grassroots ICT projects suggest that instead of a
centralized ICT-enabled city with established top-down governance,
it might be possible to develop a peer-to-peer smart city featuring
heterarchical organizational practices and distributed modes of
architecture. These notions about the role of organization and
indeed architectural choices are part of an alternative way of
imagining city governance as occurring in other ways than simply
through institutional, top-down approaches. This perspective
resonates with the notion of a ‘minor politics’ of urbanism (Osborne
and Rose, 1999) that stresses the local and contingent nature of
urban experience, a point of view echoed by Thrift (2013) who notes
that although information practices are presented as if they were
generalizable, they are in fact very local and contingent. The real
variation of experiences at the point where technology,
organization, culture and place combine suggests that the small,
messy or unsustainable interventions enacted through peer-to-peer
urban projects like community technology projects networks have
significant value in rethinking ideas of governance in the era of the
smart city. In the code-saturated space of imagining occupied by
the smart city, the peer-to-peer dynamics first developed as
methods of creating and commenting code appear again as
frameworks for broader governance work.
Peer-to-peer: from coding practice to governance norm?
Peer to peer refers to a relational dynamic based on equipotency
between members. Originally referring to a modification of clientserver information processing architecture that partitions processing
work between a number of interlinked nodes, the concept has been
extended into social and economic fields, reflecting the influence of
ideas about society's networked organization (Castells, 2001). The
success of peer-to-peer music sharing platform Napster focused
attention on the social and economic influences of peer-to-peer
practices, including the influence of distributing digital goods across
a network of individuals. 'Peer-to-peer” came to describe the
relational dynamics at work in distributed networks within
organizations or communities of practice. Yochai Benkler (2006)
develops the concepts of commons-based peer production to refer
to the economic and social impacts of collaborative and contributory
projects including free and open-source software production and the
6

development of Wikipedia. He claims that the network form and
peer production practices create a networked information economy
where freely given peer-to-peer contributions also contribute to
markets. Such a networked information economy supports individual
autonomy and other liberal values. In the wake of Benkler's work,
theoretical and empirical critiques have focused on the relationship
between peer-to-peer processes, economic and organizational shifts
and the value systems of liberal and neo-liberal capitalist systems.
Peer-to-peer contribution systems have been perceived as more
democratic than other systems of production for software code or
knowledge in general, as oppositional to contemporary neoliberal
information orders, or as disruptive to existing intellectual property
regimes. They have also been imagined as intrinsically linked with a
minor or “micro-politics”. Andrew Feenberg writes,
Micro-politics is distinguished from such large scale
interventions as elections and revolutions that aim at state
power. It may lack long term organization and is often focused
on a single issue and sometimes a single location.
Nevertheless, the effects of micro-politics are not trivial.
Democratic interventions are translated into new regulations,
new designs, even in some cases the abandonment of
technologies. They give rise to new technical codes both for
particular types of artifacts and for whole technological
domains.(Feenberg, 2011, NP).
Feenberg stresses the notion that politics provide codes, not only
through social organizing principles and regulations, but also
through designs for technology – modes of coding space. Thus, the
alternative imaginings of peer to peer urbanism are re-coding civic
space by adding a technological layer, but they are also instituting
alternative and emergent social, cultural and organization codes of
practice that are co-produced along with their coded interventions.
This promises a different locus of control for the coded informational
layers of the city that might include a kind of opposition to
centralized data collection and control. This is due to the way that
social and organizational codes are co-produced along with the
technical codes that manage flows of information in the city.
Developing from the modes of sharing that are an intrinsic part of
writing code within free and open source software (F/OSS)
production, ideas and processes are imagined as collective
productions that highlight particular ways of being in space. The
rapid expansion of F/OS modes of production outside of software is
one aspect of this, typified by the expansion of open or peer
produced engagements with city space beyond the realm of code
(Corsin-Jimanez, 2014). Second, collaboration on producing code is
soon augmented by augmentation of the coded environment
required to produce that code in the first place – what Kelty (2006)
refers to as the ‘recursive’ aspect of F/OS production. This techno7

social mode of thinking valorizes the development of architectures
for coded information delivery in cities – for example, selforganizing networks as opposed to centralized networks. Finally,
peer to peer culture implies a different mode of organization and
legitimation, based not on institutional power but on collective
authority as negotiated among participants. This alternative
legitimacy is built into the structure and practice of networked
collaboration as it has emerged from coding work. It involves the
generation of collectively produced knowledge, and the legitimation
of ideas by communities of practice who work together on topics of
their expertise.
The way that these three aspects: F/OS modes of peer production
expanding from coding to other practices, the use of coded
architecture to illustrate alternatives, and the experimentation with
alternative social modes of organization to re-code civic life are
illustrated through an assessment of the history and legacy of
community wireless networks.
History and Legacy of CWNs – peer to peer coded urbanism
Community wireless networks (CWNs), based on local
experimentation with wireless radio technology, emerged around
the world in the years following the drop in price of radio
communication equipment that used unlicensed or license-exempt
radio, which could be re-configured using free and open source
software (F/OSS). These projects perfectly exemplify the interplay of
culture, organization and technical production that characterize the
potential importance of peer-to-peer coded cities and their minor
politics of governance. This section reviews the particular genesis of
CWNs and reflects on the ways that, a decade later, their legacy
might be perceived – particularly in the knowledge that few of these
‘peer produced’ projects remained sustainable.
In 2002, the first ‘free information advocates’ met in Berlin to talk
about free information infrastructures. In 2003 Friefunk (“free radio”)
was founded with the goal of providing internet connectivity across
underserved areas of East Berlin. In the intervening decade
hundreds or perhaps thousands of these community based networks
were set up, bringing together people interested in experimenting
with open wireless technologies and those interested in improving
civic life. Hundreds of these networks were established around the
world, and shared over the internet on maps or directories also
maintained by volunteers. In general, projects embraced one of two
general architectural forms: either using wireless as a means of
broadcasting a single point of internet access, or as a means of
establishing meshed networks that interlinked individual wireless
routing devices. Like other alternative imaginations of technology8

enhanced cities, they influenced dominant imaginations, in some
cases inspiring the development of municipal scale wireless
connectivity projects.
These projects espoused a range of aims and goals that included
providing internet access to underserved areas or using wireless
networks as a mechanism for social engagement, but also focused
on F/OSS development, open hardware (in a nascent form), re-use
and repurposing of computer technology, and public engagement
with communication policy issues. CWNs depended on some form of
community contribution, of expertise, time, money, hardware or
software (Abdelaal and Ali, 2008). A research paper from the New
America Foundation features a dozen networks considered to
illustrate best practice (Forlano et al, 2011). This, along with other
work (Powell, 2008; Shaffer, 2009; Gaved and Mulholland 2008;
Antoniadis et al 2012) illustrates the range of ways that CWNs
experimented with peer to peer urbanism through cultures of peer
production derived from F/OSS development strategies, by
positioning alternative coded architectures as alternative spatial
engagements, and through the promise of alternative legitimacy
through different modes of social engagement. In this brief review
we consider the links between the codes of F/OSS development and
the imaginations of space, revealing how alternative imaginings of
the coded city establish often very different engagements with local
space. This sets the scene for a valorization of unstable, temporary
and contingent encodings of urban space, which permit us to think
about governance of the smart city as a form of politics of the minor.
Peer to peer production and modes of participation
CWN projects depended on the existence of F/OSS software that
permitted modification of wireless equipment in order to effectively
run their projects. This software was collaboratively developed by an
international community of practice who shared the code online,
and by local activists who subsequently modified it and (not always
legally) installed it on to wireless networking hardware. The different
options for F/OSS wireless networking software also linked with the
different ways that activists imagined that CWNs could fit into their
city neighbourhoods – from the expansion of convivial ‘third places’
imagined by participants at Montreal’s Ile Sans Fil (ISF) network to
the alternative media and file-sharing network constructed using
high-powered wireless technology by the members of the Athens
Metropolitan Wireless Network (AMWN). The AMWN was built by
friends who lived around the hills in the centre of Athens, and used
antennas mounted on the tops of apartment buildings to link
together these private spaces in a network that never connected to
the public internet. In contrast to the provision of internet in existing
public spaces imagined by ISF, this presents a highly private view of
9

the city. Other networks imagined wireless connectivity as a form of
media (in Lawrence, Kansas the CWN launched a local online
newspaper) or security infrastructure (in Lompoc, California the
network managers installed virtual networks so police and fire
services could use it for their work, and also provided temporary
service to contractors at the local air base and prison).
Social organization and legitimacy
This range of ways that F/OSS was imagined to be able to augment
space acts a reminder that the social dynamics within peer to peer
processes are also variable. Peer-to-peer processes are often
described as being inherently more democratic than other modes of
engagement. Bauwens (2008, 2009) is a key proponent of this
perspective, arguing that distributed forms of engagement like peerto-peer provide more opportunities for people to participate,
because they are often structured to invite many levels of
participation. Within various forms of F/OSS there are significant
organizational hierarchies, often linked to the availability of time and
resources to complete projects or coordinate distant participation as
required (Mansell and Berdou 2008). In the expansion of coded work
into city space, some parallels with the dynamics of peer to peer
production online emerge. Although some CWNs (especially smaller
projects instigated by one or two enthusiasts) developed their
technical projects using hierarchies where one person was
ultimately responsible for the quality of the code, other strategies
were required in order to maintain interest and participation in
projects over the long term, as well as to secure the roll out and
maintenance of WiFi infrastructure. These included distributed,
heterarchical models of organization, characterized around strong
participation in developing either the physical wireless access
network or the social, organizational and cultural capital also
required to make it ‘go live.’
The different strategies required to institute alternative coded
infrastructures into space can be understood in terms of what
Haythornthwaite (2009) identifies as the two forms of peer
production. The hierarchical management of the production of code,
as well as the instigation of many local projects to augment streets
or neighbourhoods with WiFi is a form of “heavyweight peer
production” characterized by “strong tie affiliation with community
members and community purpose, enacted through internallynegotiated peer reviewed contribution”. In contrast, ‘lightweight
peer production’ functions “by weak-tie attachment to a common
purpose, enacted through authority-determined, rule-based
contribution” (p. 1) – and this kind of participation was well
represented in CWN projects through early CWN projects that invited
people to list their open WiFi hotspots (see XXX for example), but
also in projects that required only technical interconnection to
10

become ‘part of the project.’ Early on at Berlin’s Freifunk network,
participation in the network was both limited to and required the
construction of a mesh network node – although in the end this was
such a difficult task that for many it transformed into a form of
‘heavyweight peer production’. Regardless, the instigators of the
Freifunk network were clear that anyone who was willing to build a
network node was welcome to participate in the construction of the
network: “Freifunk is just a concept, it is not an entity,” reported
one of the network’s founders (Forlano et al, 2009). Each node host
owns an equal portion of the network, making the network the
property of its participants. This architectural heterarchy persisted
for some time in this project in its earliest days Freifunk had no
traffic peering arrangement with any other network operator, and it
took almost a decade for the activist network to negotiate with the
city to expand access to free wireless.
In contrast, other CWNs employed more structured and hierarchical
relationships. This happened both through the choices made about
project architecture and through organizational structures. In rural
Denmark, the Djursland project secured anchor s. Finally, some
CWNs moved from grassroots organizational forms to hybrid
organizational forms including community-university partnerships
(Vienna, Austria), municipally-owned networks (Fredericton, NB,
Wireless Philadelphia), and municipal-community partnerships
(Montreal, QC) (Tapia et al, 2009). These structural relationships
encoded methods of collaboration between very different kinds of
entities, with the shared project of extending the communicational
benefits of coded infrastructure to all.
Architectural choices
In addition to showing the variable ways that F/OS might augment
urban space, and the intersecting modes through which legitimacy
is constructed for CWN proponents, CWNs also demonstrated the
extension of code into space by attempting to politicize architectural
choices. These political positionings worked with the architectural
possibilities available for setting up wireless networks. Two
architectural forms – broadcast and distributed networks – combined
with the social structures that developed around CWNs established
frameworks for an alternative diagramming of the city. Broadcast
networks require internet connectivity at a central point that is of
high enough quality to transmit a signal to receivers in the area,
bearing in mind that the radio spectrum used by community
wireless networks is of low quality. In contrast a distributed network
architecture in which wireless routers are linked together, each
sharing a portion of their connectivity, suggests a reciprocal, peerto-peer diagram of civic relationships. These different modes may
also imply different relationships between people within the city,
11

and even different conceptual frames for civic relations. Osborne
and Rose (1999) use the concept of ‘diagramming’ to suggest the
relationship between space and government of cities. They write,
“the vicious immanence of the city is a never-ending incitement to
projects of government. Such projects seek to capture the forces
immanent in the city, to identify them, order them, intensify some
and weaken others, to retain the viability of the socialising forces
immanent to urban agglomeration whilst civilising their
antagonisms” (738).
We could take community networks as literal ‘diagrams’ of cities,
which propose alternative spatial tendencies by establishing nodes
and links that connect different kinds of spaces, some physical and
some virtual. We could also take them as invitations to employ the
different ‘diagramming’ modes as proxies for understanding the
social and relational aspects of local city governance. A ‘broadcast
lilypad city’ might valorize centres of exchange such as local
community centres (used by many CWNs as installation points for
wireless broadcast antennae) and more aggregate modes of social
relation in keeping with the traditions of social mapping derived
from the Chicago School of Sociology in the 1930s. These modes
focus on a knowable city that can be mapped and whose community
institutions. In contrast a ‘distributed, peer-to-peer city’ might
valorize more informal social links not based around cultural
institutions, or the creation of hybrid, commercial/community ‘third
spaces’ (Oldenberg, 1996).

Spatial engagements: a coded city’s alternative diagrams
CWNs reiterate how such diagramming of the city can be a
sociotechnical project explicitly linking new infrastructures to
existing social and spatial practice. For CWN researchers, network
architecture is seen to both stand in for and reflect alternative social
and spatial relations, which in some cases is valorized above the
network architecture being technically robust. In other words, CWNs
and their interventions created a way for advocates to talk about
and explore what their cities meant to them. For example, in his
report on the Consume network active in London in the early 2000s,
Julian Priest argued that attempts to map the location of Consume
network nodes was actually more successful as a proxy for
measuring the location of geeks living in London, since geeky
participants in the Consume project were likely to have wireless
network nodes on their personal property. Unfortunately for the
‘success’ of Consume, the distribution of geeks was concentrated in
particular areas of the city, and outside of these areas their density
was simply not high enough to create a functioning wireless network
12

(Priest, 2004). In analyzing Adelaide Wireless in southern Australia,
Jungnickel (2012) focused on the messiness of aims to create a
meshed network linking individual residences, which by necessity
included ad hoc and informal meetings of wireless network creators
in backyards and on rooftops. These meetings were social and in
addition to helping to create wireless networks they were also
places where people could tinker with other technologies (like
bicycles).
Outcomes and Implications
The proliferation of CWNs as code-based civic interventions in
particular urban spaces was short lived. By some measures, the vast
majority of these projects failed: in 2005 individuals added
thousands of wireless nodes to collaborative online maps like
nodeDB or the Wikipedia page for community wireless networks. At
present only a fraction of these networks are still in operation. This
lack of sustainability also suggests some lessons for a valorization of
governance within ‘minor politics’. CWNs were not intended to be
‘temporary autonomous zones’ (see Bey); in some ways they were
all attempts at building infrastructures reposing differentially on
social or technical aspects of their formation. Some legacies are
thus social: the network of people who initially set up Serbia’s
BGWireless network found that their monthly picnic hackathons
were more valuable than a functioning network and have carried on
holding the parties without supporting the code. Other legacies are
technical: CWNs actively contributed to the development of free
and open software and hardware, including gateway software like
WiFiDog, and open-source protocol software for creating
autonomous self-organized networks, like the Mesh Potato software,
and the CONSUME mesh routing protocols that allow easy
configuration of servers. These collective efforts go quite some
distance to establishing an information commons: “the ‘open and
free’ availability of the raw material; participatory ‘processing’; and
commons oriented output” (Bauwens, 2009 p. 122). Since these
products of peer produced efforts remain in commons, they
maintain the possibility of peer produced F/OSS code production.
Finally, the many projects that achieved some sustainability through
encoding new social relationships among techno-enthusiasts, small
businesses, city governments and NGOs demonstrated the most
interesting consequence of the CWN version of peer to peer
urbanism: locally specific modes of integrating technology into the
minor politics of the urban. The fact that it is impossible to
generalize about the outcomes of any of these efforts is actually
quite important. They succeeded in producing technology in space,
as engagement with space, in ways that were appropriate to the
spaces they were in, for as long as it made sense to be there. Some
remain, as parts of infrastructure and others leave traces in the

13

cultural and social spaces of cities, and in the codes that can still be
used to augment them.

Conclusion
This paper contrasts two modes of combining citizenship,
technology and space, the ‘hierarchical city’ espoused in many
‘Smart city’ technology projects, and the ‘peer to peer’ city
suggested by establishing four modal scales that, in combination,
can help to describe the different elements that comprise such
socio-technical systems. Community wireless networks give us a
range of alternative means of organizing access to communications.
The ‘coding’ work they do is not only so much in the coded
architectures they produce but in the kinds of social or cultural
codes that align with the way the F/OSS architecture is adopted and
the way that the wireless architecture is imagined as being
integrated into the city.
The extent to which projects oriented around the smart city can
produce forms of ‘technological citizenship’ depends on how
citizenship, space and technology are combined. Although it is
tempting to automatically oppose dominant and alternative visions
of cities, history has not always worked that way. The alternatives of
the peer to peer city have also influenced the dominant imaginaries,
at least in the way they have organized infrastructures and
positioned discourses that facilitate the development – temporary,
contingent – of coded city projects that can generate alternative
modes of imagining a smart city.
There are, as always, a few caveats to this assessment. CWNs
offered only an alternative to technological citizenship based around
consumption of ICT connectivity. Another way of looking at the
partnerships created as these networks became more sustainable
would be as an appropriation of the alternative into the dominant
(Cammaerts, 2012). Indeed the very notion of citizenship has now
been challenged by the dominant neoliberal political order.
Therefore, there is a compelling question about whether peer to
peer forms of production can help to address this political lack.
This appears to pose a particular problem for the emerging forms of
encoding that are bound in to the contemporary city. Is the nature of
14

the ‘smartness’ is changing? In either imagination, the
augmentation of the city through technology is now based less on
the opportunity to be ‘connected’ (as it was for CWN projects) and
more on the production and processing of data via information
networks.
As the technological city shifts from being a place where new
innovations are discussed as creating new ways to listen and speak,
and towards a place where subjects produce and clients consume
data, the alternative modes of techno-social governance sketched
here will need to be better developed. In the coming re-iteration of
the smart city, who writes the codes? How open will they be and in
what way? How will data be able to speak for people’s interest? The
architectures of WiFi and the augmentations of space they promised
have given way to architectures of management of other kinds of
information. As these develop and mature we need to examine how
they, too, might be governed – and what techno-social alternatives
remain.
References
Abdelaal, N. (2013) Social and economic effects of community
wireless networks and infrastructures. IGI Global.
Antoniadis, P., B. Le Grand, A. Satsiou, L. Tassiulas, R. Aguiar, J.
Barraca, and S. Sargento. 2008. “Community Building over
Neighborhood Wireless Mesh Networks.” IEEE Society and
Technology 27 (1): 48–56
Aurigi, Alessandro and de Cindio, Fiorella (2008) (Eds.) Augmented
urban spaces: Articulating the physical and electronic city. Design
and the Built Environment. Farnham, UK: Ashgate Publishing
Bauwens, M. (2005) “The Political Economy of Peer Production”
CTheory. Available at
Benkler, Y. (2006) The Wealth of Networks: How social production
transforms markets and freedom. New Haven: Yale University Press
Bevir, M. (2009) Key Concepts in Governance. Thousand Oaks: Sage
Publications.
Cammaerts, B. (2011). “Disruptive Sharing in a Digital Age:
Rejecting Neoliberalism?” Continuum: Journal of Media and Cultural
Studies 25 (1): 47–62.

15

Castells, M (2001) The Internet Galaxy. Oxford: Oxford University
Press.
Corsin-Jimanez, A. (2014) ‘The right to infrastructure: a prototype for
open source urbanism‘. Environment and Planning D: Society and
Space 32 (2): 342-362.
Dodge, M., and R. Kitchin. (2005). “Code and the Transduction of
Space.” Annals of the Association of American Geographers 95 (1):
162–80.
Feenberg, A. (2011) “Agency and Citizenship in a Technological
Society” Lecture presented to the Course on Digital Citizenship, IT
University of Copenhagen, 2011.
Forlano, L. and Powell, A. (2011). “From the Digital Divide to Digital
Excellence:Global Best Practices for Municipal and Community
Wireless Networks.”New America Foundation. Washington, D.C.
Foucault, M. (1984) (Rabinow) The Foucault Reader, ed. Paul
Rabinow
Gaved, M. and Mulholland, P. (2008). Pioneers, subcultures and
cooperatives: The grassroots augmentation of urban places. In:
Aurigi, Alessandro and de Cindio, Fiorella eds. Augmented urban
spaces: Articulating the physical and electronic city. Design and the
Built Environment. Farnham, UK: Ashgate Publishing, pp. 171–184.
Greenfield, A. (2013). Against the Smart City (The City is There for
You to Use). New York: DO projects.
Haythornthwaite, C. (2009). “Crowds and Communities: Heavy and
Lightweight models of peer production”. Proceedings of the Hawaii
International Conference on System Sciences, January 5-8, 2009.
Available at:
https://ideals.illinois.edu/bitstream/handle/2142/9457/HICSS
%2042%20PPVCC%20Jan%202009.pdf?sequence=2
Jungnickel, K. (2013) DiY WiFi: Re-imagining connectivity, London:
Palgrave MacMillan ‘Pivot’.
Kelty, C. (2005). “Geeks, Social Imaginaries, and Recursive Publics.”
Cultural Anthropology 20 (2): 185–214.
Mansell, R.and Berdou, E.(2010) ‘Political economy, the Internet and
free/open source software development’, in Allen, M., J. Hunsinger
16

and L. Klastrup (eds), International handbook of Internet research,
Boston: Springer: 341-61.
Oldenburg, Ray. 1989. The Great Good Place: Cafés, Coffee Shops,
Community Centers, Beauty Parlors, General Stores, Bars, Hangouts
and How They Get You through the Day. New York: Paragon House.
Osborne, T. and N. Rose (1999) “Governing Cities: Notes on the
spatialisation of virtue” Environment and Planning D: Society and
Space. 17. pp 73-77.
Powell, Alison. 2008. “Wi-Fi Publics: Producing Community and
Technology.” Information, Communication & Society 11 (8): 1034–
56.
Priest, J. (2004). The State of Wireless London. Informal.org.
Available at:
http://informal.org.uk/people/julian/publications/the_state_of_wireles
s_london/
Shaffer, G. (2013) Lessons learned from grassroots wireless
networks in Europe. In Social and economic effects of community
wireless networks and infrastructures (p. 236-254), edited by N.
Abdelaal. IGI Global Publishing.
Tapia, Andrea Hoplight, Ortiz, Julio Angel and Powell,
Alison (2009) Reforming policy to promote local broadband
networks. Journal of Communication Inquiry, 33 (4). pp. 354-375.
Townsend, A. (2013) Smart Cities: Big Data, Civic Hackers, and the
Quest for a New Utopia - See more at:
http://anthonymobile.com/work/#sthash.p7JKNXf0.dpuf
Thrift, N. (2014). “The ‘sentient’ city and what it may portend”, Big
Data & Society, 1:1, 1-21.

17

Big Data & Stratified Urban Futures

Agnieszka Leszczynski
School of Geography, Earth and Environmental Science
University of Birmingham

Introduction

The ways in which cities are (re)produced through software and attendant
processes of codification have been extensively explored by geographers and others
(e.g. Amin and Thrift 2002; Burrows and Ellison 2004; Burrows and Gane 2006;
Crutcher and Zook 2009; de Souza e Silva 2013; de Souza e Silva and Frith 2012;
Dodge and Kitchin 2005; Dodge, Kitchin and Zook 2009; Gordon and de Souza e
Silva 2011; Goss 1995b; Graham 2013; Graham and Zook 2013; Graham, Zook and
Boulton 2013; Graham and Wood 2003; Graham 2005; Hochman and Manovich
2013; Kitchin and Dodge 2011; Sutko and de Souza e Silva 2010; Thrift 2014; Zook
and Graham 2007b). The city as made by software and code is, however,
geographically uneven. Software sorts the city; this is to say, the “negotiat[ion] of the
social geography of cities” by code is informed by a spatial politics underwritten by
software as a technology of classification, the binary architectures of which mandate
differentiation (Bowker and Star 1999; Graham 2005, 571; Lyon 2007; Lyon 2003).
The result is that the spaces of the city, as well as the people who inhabit them, are
distinguished on the basis of perceived status and/or location, with algorithms
mediating and enacting processes of socio-spatial sorting that discriminate against
certain
ertain places and persons whilst privileging others. Cities have always been
characterized by highly asymmetrical distributions of not only amenities and
resources but also of access to “options in life” that are “largely controlled and
constrained by the places in which [people live], the local expectations, resources,

Leszczynski

Stratified Urban Futures

schools, job opportunities, child care expectations, and housing opportunities”
(Dorling 2001, 1338). As a result of the pervasive embedding of software within and
across urban environments, and the extent to which city spaces are increasingly
dependent upon code for their very constitution and functioning, code and software
are deeply implicated in practices of the (re)enactment and rationalization of urban
inequalities and their uneven geographies (Dodge and Kitchin 2004; Graham 2005;
Kitchin and Dodge 2011). Furthermore, the machinations of how software functions
as a sorting technology that reinforces socio-spatial stratification remains largely
hidden from view, normalizing the inequality effects of algorithmic automation by
positioning them as neutral and transparent (Monahan 2008).
These practices are being intensified in an urban present characterized by big
data and their enrollment within urban regimes such as ‘smart city’ initiatives
(Klauser and Albrechtslund 2014). This chapter explores the significance of the rise
of big data for practices and processes of algorithmic socio-spatial stratification. Big
data and analytics are being taken up within regimes of urban governmentality and
governance in the service of optimization across a range of urban processes and
interventions including city planning, the functioning of infrastructure, and the
streamlining of mobilities through automation, the exploitation of crowdsourced
content, and the capture of labor within phenomena such as the ‘sharing economy’
(Batty 2013; Townsend 2013). The enlisting of big data towards urban efficiency
gains must be understood as increasingly ad hoc, stochastic, anticipatory, and
posed to curtailing spatialities and mobilities through the
predicated on enabling as opposed
management of flows (of persons, information, and objects) and processes rather than
the direct negotiation of urban social geographies characteristic of archetypal
orting such as CCTV and geodemographic information
technologies of socio-spatial sorting

!

2

Leszczynski

Stratified Urban Futures

systems (GDIS) (see Klauser and Albrechtslund 2014). Yet despite identifiably
qualitative differences in the orientation of urban informatics as compared to
antecedent technologies implicated in the algorithmic sorting of cities, big data and
attendant analytics continue to underwrite practices of urban stratification that
(re)produce geographies of inequality, often reenacting the same socio-spatial
inclusions and exclusions associated with antecedent technologies. This is playing out
at two ends of a continuum of urban big data practices that may be discursively
framed around two modes of an anticipatory politics: i) within practices of
anticipatory governmentality (Gandy 2006), observable in the digital mediation of
individual experiences of the city commensurate with the pervasiveness of locative
media that increasingly dynamically interface content productions to manage rather
than discipline mobilities; and ii) within practices of anticipatory governance
(Amoore 2007), discernible in the rise of predictive/sentiment analytics which
similarly exploit real-time big data flows, but in this case as proxies of social
disaffection and unrest to anticipate ephemeral spatialities of urban deviance and risk.
The speculative practices of big data enrollments within projects of urban
optimization – whether it be to secure consumption, or preempt criminal activity –
serve to project socio-spatial inequalities forwards into imaginaries and material
enactments of city futures.

From sorting to optimizing the city

In the late 1990s and early 2000s, concerns around inequality and the
‘softwirization’1 of the city coalesced around two technologies in particular: closed
closedcircuit television systems, in particular their merging
ng with automated facial

1

!
!

!Burrows and Ellison (2004).!

3

Leszczynski

Stratified Urban Futures

recognition systems (CCTV; for examples see Coleman 2004; Graham 1999; Graham
2002; Graham and Wood 2003; Graham 2005; Introna and Wood 2004; Norris 2003;
Phillips and Curry 2003); and, geodemographic information systems (GDIS), which
are underwritten by a geographic information systems (GIS) engine underlain by
demographic databases (see for instance Burrows and Ellison 2004; Burrows and
Gane 2006; Goss 1995a; Goss 1995b; Graham 2005; Phillips and Curry 2003). CCTV
monitoring, whether public or private, has always been a project of the securitization
of the city, particularly as a way of securing spaces for commerce (Graham and Wood
2003; Kanashiro 2008; Norris, McCahill and Wood 2004; Raco 2003). The
blanketing space with CCTV cameras is an overwhelmingly urban phenomenon; UK
cities in particular have been identified as comparatively densely covered by CCTV
monitoring apparatuses (Coleman 2004; Norris and Armstrong 1999; Norris,
McCahill and Wood 2004). Parts of London, for example, have had permanent CCTV
monitoring in effect since the 1960s (Murakami Wood 2006). The more recent
coupling of CCTV monitoring with automated facial recognition software enables the
algorithmic targeting of individuals for direct surveillance, which flags them as
spatially anomalous – i.e., as bodies whose presence in a space is undesirable and
therefore subject to monitoring as they move through the cityscape. The
determination of spatial undesirability extends beyond past demonstrations of deviant
behavior established via the automated matching of individual biometric markers to
those stored for reference in databases of known criminals or suspects to the ability to
broadly select for characteristics such as race, gender, and age. While who is deemed
ially anomalous and thereby undesirable is socially determined and must be
spatially
instructed to the algorithm, CCTV with facial recognition automates discrimination,
positioning certain kinds of bodies as worthy of inclusion and others as ripe for

!

4

Leszczynski

Stratified Urban Futures

exclusion from particular kinds of spaces (retail environments, public transportation,
etc.) while presenting this codification of inequality as the objective results of
supposedly neutral technological processes which, because they often remain
invisible, are rendered transparent (Coleman 2004). !
Whereas CCTV with automated facial recognition may be understood as a
technology of urban stratification insofar as it constitutes a disciplinary project
actualized through the sorting of people-in-place, geodemographic information
systems (GDIS), through the establishment of linkages between socioeconomic
databases and a mapping interface, sort city spaces on the basis of the socioeconomic
characteristics (age, gender, income, education, etc.) of the individuals living,
working, and moving through them. GDIS have their origins in marketing, driven by
the desire for companies to best advertise their products to potential consumers by
targeting the areas in which these individuals live and/or work (Goss 1995a; Goss
1995b). In effect, however, GDIS collapse socioeconomic variables into mutuallyexclusive spatial zones artificially constructed from trends in the datasets. This
reconfigures urban spaces into zones of privilege and exclusion that serve as proxies
for determining individuals as deserving or underserving of the allocation of and
access to amenities, resources and services – for example, whether or not they qualify
for a loan - on the basis of where they reside (Burrows and Ellison 2004; Burrows and
Gane 2006; Graham 2005).
The practices of socio-spatial sorting enacted through CCTV and GDIS figure
centrally within larger regimes of urban ordering. CCTV with automated facial
recognition constitutes an apparatus for negotiating the social geographies of the
urban present (identifying
entifying bodies as spatially undesirable) through the dynamic
determination of socio-spatial
spatial anomaly as determined from past demonstrated

!

5

Leszczynski

Stratified Urban Futures

behavior (e.g., previous criminal convictions discerned on the basis of biometric
correlations across databases). GDIS are predicated on the dividing-up of cityscapes
into easily discernible, calculable areal units such as ‘neighborhoods’ on the basis of
their aggregate historical socioeconomic characteristics so as to shape and justify
highly spatialized practices of amenity allocation and resource eligibility in the
present (for example, real estate maps representing city neighborhoods as ideally
suitable or unattractive to homebuyers). In both instances, urban governance is
operationalized through various spatial tactics of controlling and disciplining bodies
and spaces. As technologies that rationalize the city – i.e., render it governable, or
amenable to regulation and intervention – CCTV and GDIS are inherently
preoccupied with temporalities of the present and the past (see Lyon 2014). They are
moreover predicated and dependent upon intentionally curated collections of
structured data which, because they must be expressly maintained, represent static
snapshots of cities and their social geographies that are only as current as the last
update to the dataset.
As urban planning initiatives and city governments as well as software
developers and hardware manufactures turn to the vast volumes of digital content
produced by and about cities that emanate from the aggregate of embedded sensors,
transactional technologies (e.g., credit card machines), mobile devices, and other
connected technics such as in-car navigation systems as a resource to be exploited to
maximize profit generation, governance efficiency, or both (Puschmann and Burgess
sorting of cities are being sped up, becoming highly
2014), practices of the software-sorting
individualized, and rendered more transparent than ever before. Rather than a
practices of
disciplining of space (and of persons in those spaces) a la conventional practices
spatial stratification associated with technologies such as CCTV and GDIS, big
socio-spatial

!

6

Leszczynski

Stratified Urban Futures

data are conversely being enlisted within broader projects of urban optimization that
are speculative in their orientation (Klauser and Albrechtslund 2014; Lyon 2014),
ephemeral in the real-time data flows that are exploited to realize these spatial futures,
and dependent upon pervasive individual enrollments of proximate, synchronous
mobile devices that comprise the central platforms for accessing, intentionally
generating, and ‘leaking’2 the volumes of content comprising big data flows that cast
digital shadows over and transduce cities.
Big data here refers not only to the volumes, variety, and continuous flows
(velocity) of data that are generated by cities about cities, but also to the broader
socio-techno-spatial phenomenon in which data have become, as per Taylor et al.
(2014), ordinary – part of the “surfaces [of] encounter” (Thrift 2014, 1264; emphasis
in original), recognizable as a pervasive feature of the city form and of the urban
experience, understood as inimical to the very constitution and functioning of the
spaces and practices of everyday urban life, and normalized as an input to attendant
algorithmic analyses, the results of which are discursively framed as objectively
maximizing urban efficiencies in infrastructure development, housing, navigation and
routing, municipal service provision and delivery, consumerism and consumption,
resource allocation, improvements to public safety, the preservation of law and order,
and a sweeping alleviation of urban inequalities. In the vein of such utopianism, Nigel
Thrift (2014) has recently suggested that big data will reduce urban poverty by
making it visible (prominent in the data) and thereby less amenable to obfuscation. In
the first instance, such pronouncements ignore the deep-seated socio-economic
economic
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
2

Mobile device ‘leak’ data by both automatically tracking the locations of their users
as they move through the city, storing and sharing this data with network service
providers as well as third-party
party applications installed on those devices, and by having
their locations registered as data events collected by sensors (cell towers, WiFi
network emulators, etc.) densely embedded across the urban landscape.
landscape.!

!

7

Leszczynski

Stratified Urban Futures

inequalities that are echoed in big data productions, such that those at the bottom end
of the socioeconomic spectrum, such as the urban poor, “do not [necessarily] register
as digital signals” in content flows (Crawford, Miltner and Gray 2014, 1667). For
instance, elderly urban residents in poverty are highly unlikely to own a smartphone
and therefore participate in generating content about their everyday mobilities
(Crawford 2013). But more importantly, they do not account for the ways in which
big data are enlisted and enrolled within identifiably spatial projects of ordering and
optimization that work to socially and spatially stratify the city. These effects may be
observed across what may initially appear to be distantiated and unrelated moments of
tapping into spatial big data flows to support activities across multiple scales of
digital practice, from the highly individualized installation and use of mobile
applications (apps) that optimize the personal urban experience by mediating
mobilities, to the organized real-time mining of geocoded social content flows to
optimize regulatory spatial interventions by prefiguring and preempting spatial prefutures of social disorder.

Anticipatory governmentality: urban mobility futures

Locationally-aware mobile devices, namely smartphones, are ubiquitously
present on city streets (de Souza e Silva and Frith 2012; Sutko and de Souza e Silva
2010; Townsend 2013). Locative media support the synchronous (real-time) and
proximate (in-space) generation of spatial content (auto-geotagged Instagrams,
Facebook check-ins,
ins, geocoded Tweets, etc.) through highly personalized interactions
with apps and services installed on mobile devices. They simultaneously
aneously support the
referenced information about places as meets individual
calling-up of geographically-referenced
search criteria at any one given point and place in time (for instance, looking up a
restaurant review to determine whether or not an establishment onee passes by is
!

8

Leszczynski

Stratified Urban Futures

suitable; accessing a Wikipedia entry for a historic building one notices walking by).
Locative media have therefore become an intrinsic component of the urban
experience, profoundly influencing the spatial practices of everyday life as these
become increasingly digitally mediated. Location-enabled portable devices and
mobile applications and services that exploit their locational affordances do not only
enhance and streamline quotidian activities, such as navigating through traffic or
making public transportation connections, but they actively produce the cityscape that
is served up as codified content interfaced through locative media. The geographers
Zook and Graham (Graham 2013; Graham and Zook 2013; Graham, Zook and
Boulton 2013; Zook and Graham 2007a; Zook and Graham 2007b) have widely
attended to the ways in which spatial distributions of geocoded content, the languages
in which they are generated, and the sorting of these data productions by black-boxed
algorithms produce uneven urban geographies by, for example, promoting certain
places to prominence while obfuscating others. Looking at Tel Aviv, for instance,
they identify that a Google Maps search for ‘restaurant’ conducted from the same
location in Arabic and Hebrew, respectively, returns radically different results, with
different establishments appearing at the top of the results chain for a query
conducted in either language (Graham and Zook 2013).
Linguistic differences in geocoded content about a city, and the availability of
such content in specific languages, have a socio-spatial sorting effect - in the Tel Aviv
case, linguistic differences in geocoded content direct Arab and Hebrew speakers to
divergent eateries located in different parts of the city, materializing socio-spatial
spati
imaginaries of which kinds of bodies belong in which kinds of spaces (e.g.,
individuals conducting queries in Arabic potentially being directed to Arab enclaves
of the city). As per Graham (2013),, the result of such Balkanization of spatial content

!

9

Leszczynski

Stratified Urban Futures

(in this case along linguistic lines) is that it produces Balkanized cities inhabited by
different linguistic/ethnic groups. This reifies any socioeconomic disparities that
manifest along these divisions and the ways in which these socially stratify the
geography of the city (e.g., poor versus affluent neighborhoods).3 Enrollments of
geocoded information shape individual spatial trajectories by presenting particular
spaces and establishments in a city as destinations that meet personalized search
criteria, selectively routing individuals between them.
But geocoded content does not only discipline urban mobilities by either
opening up or foreclosing options for consumption, recreation, association, and
accessing services through intentional callings-up of spatial big data through directed
queries executed from a specific place at a particular point in time, at which point any
‘sorting’ effect on people-in-place is realized or manifest in those moments at which
geocoded content is brought up on a personal mobile device. Increasingly mobile
application and service developers are looking to interface circuits of uninterrupted
content flows in real-time through exploiting the locational awareness of positionallyenabled personal devices on a continuous basis as supported by the passive operation
of locational utilities in the background of the mobile operating system. The utilities
of these applications and services are varied, but they are predicated on anticipating
individual motilities by seeking to manage, rather than outright curtail, the
movements of bodies through cities. This is realized by continuously algorithmically
predicting potential spatial trajectories and presenting these as possible lines of/for
calculated for users on the basis of current
travel that are themselves dynamically re-calculated
sition, spatial history, social interactions, and behaviour, all of which
geographic position,
are subject to capture as data.
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

!
!

10

Leszczynski

Stratified Urban Futures

The rebranding of the geosocial service Foursquare from an application reliant
on check-ins intentionally generated by users declaring their presence at a location to
a spatial discovery service that pushes recommendations to users on the basis of their
real-time spatial position is illustrative of how the digital tailoring of the
individualized urban experience is operationalized. Under the guise of its new
identity, Foursquare runs ‘ambiently’ on a device, sending users push notifications
with suggestionsfor a variety of consumptive activities (such as eating and drinking)
at specific establishments on the basis of a user’s present location (Datoo 2014;
Hamburger 2014; Verge Staff 2014). Which venues get pushed as recommendations
to a user’s screen is determined on the basis of correlations established between
where a user’s “device has been, and the things that [s/he] might like based upon
where [they’ve] been in the past or where [their] friends have been” (Crowley in
Verge Staff 2014, n.p.) – in other words, from feeding the spatial trajectories of users
and that of their friends (social graph) as data inputs to algorithmic analysis so as to
predict which kinds of places a user is likely to patronize in service of optimizing the
individualized consumption of the city. This optimization is achieved by calculating
potential future scenarios of consumptive behaviour and subsequently managing
urban mobilities by presenting these as a range of possibilities for patronage, with the
consumptive choices of users and of their friends as well as others in the network
(whether or not they visited an establishment recommended to them through the
service) fed back in as data points for dynamics analytics that allow for subtle, realtime adjustments to projected geographies of consumption.
Despite being anticipatory in its approach to predicting and shaping individual
urban mobilities, Foursquare big data analytics themselves encode and reproduce
social inequalities past and present, particularly those that materialize along axes of

!

11

Leszczynski

Stratified Urban Futures

class consumerism. Because the algorithm factors in places previously frequented,
which parts of a city a user spends most of his/her time in, as well as the consumption
patterns of both a user’s friends and the patronage decisions of other users occupying
similar spaces with similar frequencies, the pre-packaged spatial futures presented to
users in the form of push notifications reinscribe the geographical effects of
disparities in purchasing power: the spatial trajectories anticipated for those with
more purchasing power are likely to be different as compared to those anticipated for
individuals with comparatively less. Different kinds of (classed) bodies belong to
different kinds of consumer spaces. The socio-spatial stratification effect bound up in
the optimization of individual urban mobilities via big data analytics is all the more
apparent in the instance of Microsoft’s (2012) Pedestrian Route Production patent,
popularly dubbed the ‘Avoid Ghetto GPS,’ for a dynamic foot-traffic travel
application to run on the Windows phone. While never actually built, this was
envisioned as a map-based service that would calculate a set of walking directions for
users taking into account “user history, weather information, crime statistics,
demographic information, etc.” and subjecting data to algorithmic data analytics to
optimize for travel across the city “according to at least one criterion, such as keeping
a user safe,” by “taking the user through neighborhoods with violent crime statistics
below a certain threshold” (Microsoft Corporation 2012, n.p.). In any eventual
prototype and eventual commercial product, the service as described in the patent
filing would dynamically recalculate the route on the basis of real-time changes to
conditions in any of the above factors, namely the user’s current position.
What constitutes ‘demographic information’ or ‘crime statistics,’ and/or where
such data is to be sourced, was nowhere specified in the patent application. This
similarly holds for the vague designator ‘crime statistics.’ The repeated use of

!

12

Leszczynski

Stratified Urban Futures

language around the safety utility of the service to be realized through its ability to
direct pedestrians around “unsafe neighborhood[s]” (Microsoft Corporation 2012,
n.p.) designates soft-speak for racialized and ethnic-minoritized poor inner-city
American urban imaginaries that are the legacy of the Chicago school (Thatcher
2013). Accordingly Thatcher (2013) identifies the Pedestrian Route Production patent
as more than simply a prospectus for a directional application that optimizes
pedestrian navigation of the city. Even in its very envisioning the hypothetical service
promises to algorithmically enact and prefigure spatial futures that are always-already
raced and classed. The promise of the technology to ensure “efficiency, safety, and
new forms of coordination” is inseparable from, and is indeed predicated upon, its
“[opening up of] a future wherein encounters on the city street are sorted by race; an
unseen algorithm enabling users to only ever encounter those already sorted as
demographically similar (967, 974). As with Foursquare push recommendations, the
Pedestrian Route Optimization patent proposes to optimize individual urban
mobilities through analytics approaches to establishing correlations across content
flows so as to make real a spatial utopia in which the encumbrances of having to
physically embody the spaces of the poor, racialized other are technologically
ameliorated. Yet this enactment of a data-driven future is predicated on the
reinscription of extant, longstanding socio-spatial inequalities that are re-materialized
through any potential deployments of an as-yet unbuilt mobile service, extending
forward in time and space the segregation of privileged bodies and underprivileged
places.

Anticipatory governance: securitizing the city

Inasmuch as the city is pervasively interfaced via mobile devices which
digitally mediate personal experiences
nces of the urban, cities themselves function as
!

13

Leszczynski

Stratified Urban Futures

interfaces for data generation, circulation, and aggregation (Barreneche 2012; de
Waal 2014). The speculative ethos that underwrites the algorithmic calculation of
possible urban futures similarly informs interventions in those data futures so as to
actively enable (optimize) desirable socio-spatial scenarios whilst foreclosing others.
This is evident not only in the optimization of individual urban mobilities, which
constitute a form of anticipatory governmentality (Gandy 2006) enacted through the
sorting of bodies in and across immanent city spaces, but also within city-scale
practices of anticipatory governance (Amoore 2007) that are operationalized within
and towards the securitization of urban environments predicated on the algorithmic
identification and isolation of spaces for preemptive intervention, particularly as
concerns crime and civil unrest. This is the thrust behind predictive analytics, which
describes an approach to operationalizing big data by establishing correlations across
data streams so as to determine future event phenomena – such as online purchasing
behavior, disease outbreaks and terrorist attacks – so as to influence how they unfold
through either formative (suggesting book titles to Amazon customers) or
preventative (stocking up on flu vaccine) interventions that enable or forestall the
materialization of (un)favourable scenarios.
Predictive analytics have become embraced within urban policing practices,
informing preemptive approaches to maintaining law and order based on the basis of
the projected forecasting of where crime and protest activity are algorithmically
determined as likely to occur, and who is likely to have a propensity for engaging in
criminal activity or participating in organized civic displays of disaffection
(Barreneche 2012; Crawford and Schultz 2014; Friend 2013; Grabianowski 2013;
Lyon 2014; Perng 2014; Executive Office Of The President 2014;; Stroud 2014).
Typically, the prefiguring of where crime is likely to occur – and who is likely to be a

!

14

Leszczynski

Stratified Urban Futures

perpetrator – has been premised on identifying trends across datasets and establishing
associations between these content flows so as to generate new (additional)
information that is (potentially) more revelatory of identities, spaces, and behaviours
than the sum of information contained within the data themselves (Crawford and
Schultz 2014; President 2014). Areas where criminal activity appears as clusters in
the datasets are isolated as geographical ‘hotspots’ in need of increased police on the
ground and/or heightened electronic surveillance, and individuals living in these areas
are identified as potential perpetrators of future crimes in those areas. These
predictive analytics outcomes may be correlated to data about known individuals with
patterns of recidivism who are deemed as likely to reoffend, and areas of cities where
these individuals congregate as discrenred from clusters within data streams inform
the algorithmic speculation of immanent urban geographies of crime. The
implications of these policing algorithms are elucidated by Crawford and Shultz
(2014), who assert that the logic underwriting preemptive analytics - that certain parts
of cities are more prone to crime – is seen to justify an increased police presence in
these areas, with the result of a concentration of arrests therein, producing even more
“‘historical crime data’ for these areas and increase[ing] the likelihood of patrols”
(104). These statistics are fed back into the analytics, intensifying the ‘hotspot’ effect
for these areas, sorting them and the individuals living within them as amenable to
preemptive interventions. This has extended beyond the overpolicing of often poor,
ethnic-minoritized and racialized neighborhoods and their (poor, racial/ethnic
minority) residents to the a priori criminalization of individuals on the basis of their
area of residence and their social graph (i.e., if they ‘associate’ with convicted felons,
ganized crime, or other persons known to police on social media)
members of organized
(Doctorow 2014; Executive Office Of The President 2014; Stroud 2014).

!

15

Leszczynski

Stratified Urban Futures

The enrollment of social media content within predictive analytics is
significant in that it is associated with a shift from analytics of largely historical crime
data to determine areas of ‘hotspot’ activity to the dynamic exploitation of usergenerated data flows within practices of anticipatory governance that are known as
‘sentiment analytics.’ These systems interface social media contributions (Tweets,
Facebook posts, Instagrams, etc.) as they are generated across platforms in real time,
“modeling [a] population’s behavior (opinions and sentiments) so as to produce
geographic risk alerts” to inform urban governance interventions – such as increased
police presence and preemptive kettling measures (blocking off access routes into/out
of neighborhoods) – to forestall organized expressions of civil strife (Barreneche
2012, 215; The Economist 2012). While several such analytics suites have been
developed (see Barreneche 2012; The Economist 2012), a particularly illustrative
example is the British sentiment analytics EMOTIVE (Extracting the Meaning of
Terse Information in a Geo-Visualization of Emotion) program (EMOTIVE 2014;
Marsden 2013 n.p.; Press Association 2013). EMOTIVE filters Tweets as they are
being generated in real-time, scraping them for words and emoticons “that indicate
emotions, such as anger, disgust, fear, happiness, sadness, surprise, shame and
confusion” as well as geographical metadata (embedded within the text of the Tweet,
autogeotagged, or self-reported) to produce dynamic ‘mood maps’ of British cities as
a riot and protest suppression measure (EMOTIVE 2014; Marsden 2013, n.p.; Press
Association 2013). The utility of tapping directly into unstructured, piecemeal data
events (Tweets) that betray the immanence of urban anarchy and/or unrest only in the
aggregation of ephemeral, performative content flows generated by individuals
usually not bound by any social or spatial ties is realized in the latent aspiration
towards intervening not only in the future (by preempting it in the present), bu
butt the

!

16

Leszczynski

Stratified Urban Futures

indeed in the pre-future – before the viral contagion of disaffection from which social
disorder (rioting, peaceful protest) may be projected forward in time as a speculative
trajectory. An earlier platform designed specifically for modeling protest dynamics,
Condor, factors in the reputation, or clout, of Twitter users in determining the
likelihood and viability of public demonstrations – if negative sentiments and or those
calling for collective action are shared by users with a large number of followers, they
are likely to be retweeted (spread) with greater frequency and rapidity, having greater
influence in incentivizing demonstration, civic disobedience, etc. (The Economist
2012).
While EMOTIVE aspires to act upon the (pre)future, its very development is
informed by historical and enduring socio-spatial inequalities that have been
architectured into the technology and are rematerialized in its deployments.
Specifically, the EMOTIVE platform was designed in the wake of the 2011
Tottenham protests and subsequent riots which first spread through
socioeconomically deprived and racial/ethnic minoritized burroughs of London and
subsequently outwards to other British cities in response to the police shooting of an
unarmed Black man at point-blank range in what marked the climax of an escalation
of long-standing tensions between the police and Black communities (Lewis 2011;
Newburn et al., 2011). Police and intelligence forces, as well as the press, identified
social and mobile media - in particular Twitter, BlackbBerry Messenger, and
Facebook – as having enabled the coordination of rioting and subsequent looting and
vandalism (see for example Adams 2011; Press Association 2013). Indeed the lead
researchers behind EMOTIVE identify the “[r]ecet urban disturbances”
ces” of the “fast“fast
moving events of Summer 2011,” and the “key role played by social networks”
therein as an event horizon precipitating the development of the sentiment analytics

!

17

Leszczynski

Stratified Urban Futures

platform to help both city police departments and national security agencies “to
predict and monitor selected events” (EMOTIVE 2014, n.p.). The approach to
analytics ensconced within EMOTIVE is discriminatory by design, predicated on an
imaginary of ‘the city’ as necessarily spatially and socially stratified - that riots, for
example, are likely to occur in certain kinds of (socioeconomically deprived) areas,
and to be incentivized and performed by certain kinds of (Black, Asian, student)
bodies that inhabit those spaces.

Conclusion

While big data in the service of anticipatory regimes of city governance and
governmentality are predicated on the envisioning of future urbanisms, the cities that
are speculated and anticipated within predictive policing and sentiment analytics as
well as the management of individualized urban mobilities are bound and committed
to a conception of the city as always-already unequal. In the context of the turn
towards big data in practices of urban optimization (securitization, mobilities), big
data are future oriented insofar as they project the socio-spatially stratified city
forwards in time and space, enacting and reenacting what are often longstanding
socio-economic disparaities and the persistence of their geographies in the present.
Therefore, while Thrift (2014) may conjecture that urban informatics will alleviate
poverty by making it apparent as trends and correlations across data streams, in
reality, as Bowker (2014) argues, big data may, in a best case scenario, inform
policies to intervene in the production of inequality; in the worst case scenario,
rio, “and
most commonly,” big data may deny that those inequalities exist by refusing “that
there are indeed broad social forces” (1797).
It is precisely through this refutation of the social – of the social construction
and resulting biases of data themselves, and of the theory- and value-laden
laden nature of
!

18

Leszczynski

Stratified Urban Futures

analytics (Kitchin 2014) – that discourses of big data look to the future. In so doing,
they work to divest data, their productions, and deployments of the encumbrances
(contestations and critiques) of the past. But big data are no (new) digital sublime
signaling the end of politics, theory, history, or geography (Mosco 2004). Geography
and history – i.e., longstanding spatialities of urban inequality - endure and indeed
permeate the anticipatory rationalities that underwrite the enrollments of big data
within projects that may broadly be understood in terms of the optimization of the
city. In this chapter, I have identified that these anticipatory rationalities, which
prefigure the city as inevitably socio-spatially uneven rather than radically reenvisioning how urban environments may be equalized, inform both practices of
urban governmentality and governance. That big data intensify the ‘software-sorting’
of cities rather than ameliorating socio-spatial urban stratification requires an
understanding of how this sorting is effected across multiple scales of big data praxis.
Here, I have profiled two extremes of the scalar spectrum: i) at the level of the
individual, where big data as a personalization of the city experience mediates urban
mobilities in ways that reproduce cities as socio-spatially uneven by, for example,
shaping individual urban consumption behavior around class (as a corollary of
purchasing power); and, at the level of the city itself, where big data are enrolled
within processes of urban securitization that reify longstanding geographic
inequalities through, for instance, reinforcing positive feedbacks between police
presence in an inner-city neighborhood, the incidences of observed and codified (as
data points) crimes that occur there, and the intensified overpolicing of those areas.

!

19

Leszczynski

Stratified Urban Futures

References

Adams, W. L. 2011. Were Twitter or BlackBerrys Used to Fan Flames of London’s
Riots? Time, 08 August.
http://content.time.com/time/world/article/0,8599,2087337,00.html Accessed
14 July 2014.
Amin, A. & N. Thrift. 2002. Cities: Reimagining the Urban. Cambridge; Malden,
MA: Polity.
Amoore, L. (2007) Vigilant Visualities: The Watchful Politics of the War on Terror.
Security Dialogue 38, 215-232.
Barreneche, C. 2012. Localizing the media, locating ourselves: a critical comparative
analysis of socio-spatial sorting in locative media platforms (Google AND
Flickr 2009-2011). PhD Thesis, School of Media, Arts and Design, University
of Westminster.
Batty, M. 2013. The New Science of Cities. Cambridge, MA: The MIT Press.
Bowker, G. C. (2014) The Theory/Data Thing. International Journal of
Communication 8, 1795-1799.
Bowker, G. C. & S. L. Star. 1999. Sorting Things Out: Classification and Its
Consequences. Cambridge, MA: The MIT Press.
Burrows, R. & N. Ellison (2004) Sorting Places Out? Towards a social politics of
neighborhood informatization. Information, Communication & Society 7, 321336.
Burrows, R. & N. Gane (2006) Geodemographics, Software and Class. Sociology 40,
793-812.
Coleman, R. (2004) Reclaiming the Streets: Closed Circuit Television, Neoliberalism
and the Mystification of Social Divisions in Liverpool, UK. Surveillance &
Society 2, 293-309.
Crawford, K. 2013. The Hidden Biases in Big Data. HBR Blog Network, 01 April.
http://blogs.hbr.org/2013/04/the-hidden-biases-in-big-data/ Accessed 10 June
2014.
Crawford, K., K. Miltner & M. L. Gray (2014) Critiquing Big Data: Politics, Ethics,
Epistemology. International Journal of Communication 8, 1663-1672.
Crawford, K. & J. Schultz (2014) Big Data and Due Process: Toward a Framework to
Redress Predictive Privacy Harms. Boston College Law Review 55, 93-128.
Crutcher, M. & M. A. Zook (2009) Placemarks and waterlines: Racialized
cyberscapes in post-Katrina Google Earth. Geoforum 40, 523-534.
Datoo, S. 2014. Why data science matters to Foursquare. The Guardian, 27 January.
http://www.theguardian.com/technology/2014/jan/27/why-data-sciencematters-to-foursquare?CMP=twt_gu Accessed 28 January 2014.
de Souza e Silva, A. (2013) Location-aware mobile technologies: Historical, social
and spatial approaches. Mobile Media & Communication1, 116-121.
de Souza e Silva, A. & J. Frith. 2012. Mobile Interfaces in Public Spaces: Locational
Privacy, Control, and Urban Sociability. New York; Abingdon, Oxfordshire:
Routledge.
de Waal, M. 2014. The City as Interface: How New Media Are Changing the City
(Kindle edition). nai010 publishers.
Doctorow, C. 2014. Chicago PD's Big Data: using pseudoscience to justify racial
profiling. Boing Boing, 25 February.
using.html Accessed
http://boingboing.net/2014/02/25/chicago-pds-big-data-using.html
26 February 2014.

!

20

Leszczynski

Stratified Urban Futures

Dodge, M. & R. Kitchin (2004) Flying through code/space: the real virtuality of air
travel. Environment and Planning A 36, 195-211.
--- (2005) Code and the transduction of space. Annals of the Association of American
Geographers 95, 162-180.
Dodge, M., R. Kitchin & M. Zook (2009) Guest Editorial: How does software make
space? Exploring some geographical dimensions of pervasive computing and
software studies. Environment and Planning A 41, 1283-1293.
Dorling, D. (2001) Anecdote is the singular of data. Environment and Planning A 33,
1335-1340.
EMOTIVE, 2014. Emotive. http://emotive.lboro.ac.uk/ Accessed July 11 2014.
Friend, Z. 2013. Predictive Policing: Using Technology to Reduce Crime. FBI Law
Enforcement Bulletin, 09 April. http://www.fbi.gov/statsservices/publications/law-enforcement-bulletin/2013/April/predictivepolicing-using-technology-to-reduce-crime Accessed 07 July 2014.
Gandy, M. (2006) Zones of indistinction: bio-political contestations in the urban
arena. cultural geographies, 13, 497-516.
Gordon, E. & A. de Souza e Silva. 2011. Net Locality: Why Locaiton Matters in a
Networked World. Malden, MA; Oxford; Chicester, West Sussex: WileyBlackwell.
Goss, J. 1995a. Marketing the New Marketing: The Strategic Discourse of
Geographic Information Systems. In Ground Truth: The Social Implications of
Geographic Information Systems, ed. J. Pickles, 130-170. New York; London:
The Guilford Press.
--- (1995b) 'We know who you are and we know where you live': the instrumental
rationality of geodemographic systems. Economic Geography 71, 171-198.
Grabianowski, E. 2013. West Point's ORCA software knows if you're in a gang. i09,
12 December. http://io9.com/west-points-orca-software-knows-if-youre-in-agang-1488752018 Accessed 26 February 2014.
Graham, M. 2013. The Virtual Dimension. In Global City Challenges: Debating A
Concept, Improving The Practice, eds. M. Acuto & W. Steele, 117-139.
London: Palgrave.
Graham, M. & M. Zook (2013) Augmented realities and uneven geogrpahies:
exploring the geo-linguistic contours of the web. Environment and Planning A
45, 77-99.
Graham, M., M. Zook & A. Boulton (2013) Augmented reality in urban places:
contested content and the duplicity of code. Transactions of the Institute of
British Geographers 38, 464-479.
Graham, S. (1999) Spaces of surveillant simulation: New technologies, digital
representations, and material geographies. Journal of Planning Literature 14,
483.
--- (2002) CCTV: The Stealthy Emergence of a Fifth Utility? Planning Theory and
Practice 3, 237-241.
Graham, S. & D. Wood (2003) Digitizing surveillance: categorization, space,
inequality. Critical Social Policy 23, 227-248.
Graham, S. D. N. (2005) Software-sorted geographies. Progress in Human
Geography 29, 562-580.
Verge, 23 July.
Hamburger, E. 2014. The next age of Foursquare begins today. The Verge,
new-foursquare
foursquare
http://www.theverge.com/2014/7/23/5926843/this-is-the-new-foursquare
Accessed 24 July 2014.

!

21

Leszczynski

Stratified Urban Futures

Hochman, N. & L. Manovich (2013) Zooming into an Instagram City: Reading the
local through social media. First Monday: Peer-Reviewed Journal On The
Internet 18, n.p.
Introna, L. D. & D. Wood (2004) Picturing Algorithmic Surveillance: The Politics of
Facial Recognition Systems. Surveillance & Society 2, 177-198.
Kanashiro, M. M. (2008) Surveillance Cameras in Brazil: exclusion, mobility
regulation, and the new meanings of security. Surveillance & Society 5, 270289.
Kitchin, R. (2014) Big Data, New Epistemologies and Paradigm Shifts. Big Data &
Society 1, 12 pp.
Kitchin, R. & M. Dodge. 2011. Code/Space: Software and Everyday Life. Cambridge,
MA; London: The MIT Press.
Klauser, F. R. & A. Albrechtslund (2014) From self-tracking to smart urban
infrastructures: towards an interdisciplinary research agenda on Big Data.
Surveillance & Society 12, 273-286.
Lewis, P. 2011. Tottenham riots: a peaceful protest, then suddenly all hell broke
loose. The Guardian, 07 April.
http://www.theguardian.com/uk/2011/aug/07/tottenham-riots-peaceful-protest
Accessed 14 July 2014.
Lyon, D. 2007. Surveillance Studies: An Overview. Cambridge: Polity Press.
Lyon, D. (2014) Surveillance, Snowden, and Big Data: Capabities, consequences,
critique. Big Data & Society 1, 1-13.
Lyon, D. E. 2003. Surveillance as Social Sorting: Privacy, risk and digital
discrimination. London and New York: Routledge.
Marsden, R. 2013. Emotive: Mapping the Mood of a Nation. The Business of
Emotions, 09 October. http://businessofemotions.org/2013/10/09/emotivemapping-the-mood-of-a-nation/ Accessed 12 November 2013.
Microsoft Corporation. 2012. Pedestrian Route Production. US Patent: US8090352.
http://www.google.com/patents/US8593277 Accessed 07 July 2014.
Monahan, T. (2008) Editorial: Surveillance and Inequality. Surveillance & Society 5,
217-226.
Mosco, V. 2004. The digital sublime: myth, power, and cyberspace. Cambridge,
Mass.: MIT Press.
Murakami Wood, D. E. 2006. A Report on the Surveillance Society.
Newburn, T., P. Lewis & J. Metcalf. 2011. A new kind of riot? From Brixton 1981 to
Tottenham 2011. The Guardian, 09 December.
http://www.theguardian.com/uk/2011/dec/09/riots-1981-2011-differences
Accessed 14 July 2014.
Norris, C. 2003. From personal to digital: CCTV, the panopticon, and the
technological mediation of suspicion and social control. In Surveillance as
Social Sorting: Privacy, risk and digital discrimination, ed. D. Lyon, 249-281.
London and New York: Routledge.
Norris, C. & G. Armstrong. 1999. The Maximum Surveillance Society. Oxford: Berg.
Norris, C., M. McCahill & D. Wood (2004) Editorial. The Growth of CCTV: a global
perspective on the international diffusion of video surveillance in publicly
accessible space. Surveillance & Society, 2, 110-135.
City,, 30 June.
Perng, S-Y. 2014. Predictive analytics in the city. The Programmable City
analytics-in-the-city/
-the-city/
city/
http://www.nuim.ie/progcity/2014/06/predictive-analytics-in-the-city/
Accessed 01July 2014.

!

22

Leszczynski

Stratified Urban Futures

Phillips, D. & M. Curry. 2003. Privacy and the phenetic urge: Geodemographics and
the changing spatiality of local practice. In Surveillance as Social Sorting:
Privacy, risk and digital discrimination, ed. D. Lyon, 137-152. London and
New York: Routledge.
President, E. O. o. t. 2014. Big Data: Seizing Opportunities, Preserving Values.
Washington, D.C.: The White House.
Press Association. 2013. New computer program analyses Twitter to map public
sentiment. The Guardian, 06 September.
http://www.theguardian.com/technology/2013/sep/06/computer-programtwitter-public-mood-emotive Accessed 06 September 2013.
Puschmann, C. & J. Burgess (2014) Metaphors of Big Data. International Journal of
Communication 8, 1690-1709.
Raco, M. (2003) Surveillance and security: Technological politics and power in
everyday life. Urban studies 40, 1869–1887.
Stroud, M. 2014. The minority report: Chicago's new police computer predicts
crimes, but is it racist? The Verge, 19 February.
http://www.theverge.com/2014/2/19/5419854/the-minority-report-thiscomputer-predicts-crime-but-is-itracist?utm_content=bufferc4058&utm_medium=social&utm_source=twitter.c
om&utm_campaign=buffer Accessed 20 February 2014.
Sutko, D. M. & A. de Souza e Silva (2010) Location-aware mobile media and urban
sociability. New Media & Society, 13, 807-823.
Taylor, A. S., S. Lindley, T. Regan & D. Sweeney (2014) Data and life on the street.
Big Data & Society 1, 1-7.
Thatcher, J. (2013) Avoiding the Ghetto through hope and fear: an analysis of
immanent technology using ideal types. GeoJournal 78, 967-980.
The Economist. 2012. The science of civil war: What makes heroic strife. The
Economist, 21 April. http://www.economist.com/node/21553006 Accessed 01
July 2014.
Thrift, N. (2014) The promise of urban informatics: some speculations. Environment
and Planning A 46, 1263-1266.
Townsend, A. 2013. Smart Cities: Big Data, Civic Hackers, and the Quest for a New
Utopia. New York, London: W. W. Norton & Company.
Verge Staff. 2014. Meet Swarm: Foursquare's ambitious plan to split its app in two.
The Verge, 01 April. http://www.theverge.com/2014/5/1/5666062/foursquareswarm-new-app Accessed 07 May 2014.
Zook, M. & M. Graham. 2007a. From Cyberspace to DigiPlace: Visibility in an Age
of Information and Mobility. In Societies and Cities in the Age of Instant
Access, eds. H. Miller & H. Rheingold, 231-244. Dordrecht: Springer.
Zook, M. A. & M. Graham (2007b) Mapping DigiPlace: geocoded Internet data and
the representation of place. Environment and Planning B: Planning and
Design 34, 466-482.

!

23

