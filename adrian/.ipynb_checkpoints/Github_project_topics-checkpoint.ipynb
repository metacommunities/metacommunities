{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('..')\n",
      "import github_api_data as gad\n",
      "import google_bigquery_access as gba\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import datetime as dt\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn\n",
      "import gensim as gs\n",
      "import MySQLdb\n",
      "import nltk\n",
      "import lsh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Ways of characterising what Github projects are actually about\n",
      "\n",
      "How do we know what repositories are about? Can we know even know whether a repository has any software in it?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "query = \"\"\"select repository_name, repository_description, repository_language \n",
      "from [publicdata:samples.github_timeline]\n",
      "limit 5000;\"\"\"\n",
      "\n",
      "repo_df = gbq.query_table(query, 5000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Your browser has been opened to visit:\n",
        "\n",
        "    https://accounts.google.com/o/oauth2/auth?scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fbigquery&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&response_type=code&client_id=237471208995.apps.googleusercontent.com&access_type=offline\n",
        "\n",
        "If your browser is on a different machine then exit and re-run this\n",
        "application with the command-line parameter \n",
        "\n",
        "  --noauth_local_webserver\n",
        "\n",
        "Authentication successful."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "executing query:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "select repository_name, repository_description, repository_language \n",
        "from [publicdata:samples.github_timeline]\n",
        "limit 5000;\n",
        "has a rows attribute"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5000 of   5000 (5000, 3)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "repo_df.repository_description = repo_df.repository_description.fillna(' ')\n",
      "stoplist = set('for is or that a of the and to in'.split())\n",
      "texts = [[word for word in document.lower().split() if word not in stoplist] for document in repo_df.repository_description.tolist()]\n",
      "# remove words that appear only once\n",
      "all_tokens = sum(texts, [])\n",
      "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      "texts = [[word for word in text if word not in tokens_once]\n",
      "          for text in texts]\n",
      "print(texts[0:10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[u'simple', u'application', u'android'], [u'selenium', u'tests', u'case', u'conductor'], [u'personal', u'project'], [u'archive', u'formulae', u'removed', u'from', u'homebrew', u'package', u'manager'], [u'web-based', u'management', u'system'], [u'2012', u'wiki'], [u'simple', u'tool'], [u'an', u'automated', u'project', u'mirror.'], [u'scipy', u'main', u'repository'], [u'real-time', u'log', u'monitoring', u'your', u'browser']]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = gs.corpora.Dictionary(texts)\n",
      "print(dictionary)\n",
      "git_corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "gs.corpora.BleiCorpus.serialize('data/github_desc.lda_c', git_corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(3031 unique tokens)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda_model = gs.models.ldamodel.LdaModel(corpus=git_corpus, id2word=dictionary, num_topics=10,update_every=0, passes=50)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[[i, lda_model.print_topic(i)] for i in range(10)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "[[0,\n",
        "  u'0.021*library + 0.013*official + 0.013*on + 0.012*jquery + 0.012*with + 0.011*web + 0.010*collection + 0.010*data + 0.010*are + 0.010*website'],\n",
        " [1,\n",
        "  u'0.021*my + 0.016*2 + 0.015*web + 0.014*with + 0.013*project + 0.012*tag + 0.012*finder + 0.012*fuzzy + 0.012*file, + 0.012*buffer,'],\n",
        " [2,\n",
        "  u'0.019*on + 0.016*your + 0.013*with + 0.013*javascript + 0.010*simple + 0.009*tool + 0.009*programming + 0.009*language + 0.008*node.js + 0.008*code'],\n",
        " [3,\n",
        "  u'0.036*library + 0.021*project + 0.018*from + 0.016*implementation + 0.011*with + 0.010*wordpress + 0.010*source + 0.009*using + 0.009*api + 0.009*open'],\n",
        " [4,\n",
        "  u'0.033*rails + 0.033*on + 0.029*ruby + 0.027*an + 0.016*api + 0.016*plugin + 0.010*client + 0.010*it + 0.009*blog + 0.009*c'],\n",
        " [5,\n",
        "  u'0.041*framework + 0.021*php + 0.017*with + 0.017*server + 0.016*site + 0.014*by + 0.010*library + 0.009*from + 0.009*project + 0.008*building'],\n",
        " [6,\n",
        "  u'0.017*code + 0.015*platform + 0.015*system + 0.015*app + 0.010*files + 0.010*this + 0.010*an + 0.010*forms + 0.009*ruby + 0.009*plugin'],\n",
        " [7,\n",
        "  u'0.020*-- + 0.019*at + 0.017*clone + 0.016*into + 0.016*symfony + 0.015*subtree + 0.014*(master + 0.014*symfony/symfony) + 0.014*split + 0.014*[read-only]'],\n",
        " [8,\n",
        "  u'0.022*with + 0.020*this + 0.019*web + 0.017*framework + 0.016*as + 0.015*an + 0.012*- + 0.011*mobile + 0.010*using + 0.009*simple'],\n",
        " [9,\n",
        "  u'0.031*source + 0.027*open + 0.017*de + 0.015*your + 0.011*using + 0.011*code + 0.010*with + 0.009*on + 0.009*tikz + 0.009*app']]"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Estimating similarity: trying again with the readme corpus\n",
      "\n",
      "Maybe we don't really need to find the topics. We can just go with similarities, and from there decide whether to put things in classes/topics or not. A similarity based approach means we can augment the readmes with any other data we find (languages, titles, size of projects, growth etc), and it will help the similarity measure. Given a good similarity measure, we can then work with clustering techniques rather than classification techniques?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#text file with MySQL user on 1st line and password on the 2nd needed!\n",
      "mysql_details = open('mysql_user_login.txt', 'r')\n",
      "credentials = mysql_details.readlines()\n",
      "user = credentials[0].strip()\n",
      "password = credentials[1].strip()\n",
      "\n",
      "\n",
      "# mysql database name where the table lives -- could put this into mysql_details.txt?\n",
      "gh_db = 'github_analysis'\n",
      "db_conn = MySQLdb.connect(db =gh_db, user=user, passwd=password)\n",
      "#the table that Richard made from BQ\n",
      "query = 'select * from readmes'\n",
      "\n",
      "repos_df = pd.io.sql.read_sql(query, db_conn)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lower case, strip out punctuation and whitespacing, then tokenize readmes\n",
      "repos_df['readme_tok'] = repos_df.readme.map(lambda x: nltk.word_tokenize(nltk.re.sub('\\W{2}', ' ',x.lower())))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "readme_tok.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "0    [introduction, media-service-upnp, is, a, high...\n",
        "1    [prerequisites, 1, rib, supports, running, onl...\n",
        "2    [0install, copyright, thomas, leonard, and, ot...\n",
        "3    [cubebox, logo, http, /cubebox.bplaced.net/log...\n",
        "4    [0x10c, standards, committee, the, 0x10c, stan...\n",
        "Name: readme, dtype: object"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# take out the na readmes\n",
      "repos_df = repos_df[repos_df.readme_tok.apply(len)>1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'repos_df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-2-48fdf14874a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# take out the na readmes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrepos_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrepos_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadme_tok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'repos_df' is not defined"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def shingle_n(s, n):\n",
      "    \"\"\" Shingles for the text.\n",
      "    s: the text to be shingled\n",
      "    n: number of tokens in the shingle\n",
      "    \n",
      "    Returns a set of shingles for the text\n",
      "    \"\"\"\n",
      "\n",
      "    return {' '.join(s[i:i+n]) for i in range(0,len(s))}\n",
      "\n",
      "\n",
      "#construct all shingles\n",
      "readme_shingles = readme_tok.map(lambda x:shingle_n(x,7))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#construct the universal set of shingles\n",
      "universal_set = set()\n",
      "{universal_set.update(e) for e in readme_shingles}\n",
      "print('There are %s shingles in the collection' % len(universal_set))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def jaccard_distance(s1, s2):\n",
      "    \"\"\" Returns the ratio of the intersection and the union of elements of the two sets\"\"\"\n",
      "    return float(len(s1.intersection(s2)))/len(s1.union(s2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#drop empty readmes\n",
      "readme_shingles = readme_shingles[readme_shingles.apply(len) >1]\n",
      "readme_count = readme_shingles.shape[0]\n",
      "dist_matrix = np.zeros(shape=(readme_count, readme_count))\n",
      "readme_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "9561"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "readme_shingles.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "0    set([treated as errors during compilation shou...\n",
        "1    set([lib/deflate.js mit/x11 arnaud renervier [...\n",
        "2    set([packaging format unmodified tarballs or z...\n",
        "3    set([guides or linux package dependencies http...\n",
        "4    set([you want to write dcpu-16 assembly probab...\n",
        "Name: readme, dtype: object"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make list of shingles from pandas series to avoid indexing problems\n",
      "readme_count = 5000\n",
      "readme_shingles_l = readme_shingles.tolist()\n",
      "for i in range(0, readme_count):\n",
      "    for j in range(0, readme_count):\n",
      "        if i != j:\n",
      "            dist_matrix[i,j] = jaccard_distance(readme_shingles_l[i], readme_shingles_l[j])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b,s,y = plt.hist(dist_matrix.flatten(), bins=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEGCAYAAACevtWaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0xe190f350>"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_distances = sorted(dist_matrix.flatten(), reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(sorted_distances)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "91412721"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But all of this is too slow. Very 5000 readmes, the distance matrix takes ages (30 minutes?). It will crash with 1,000,000 repos. So better to try a different technique\n",
      "\n",
      "### Locality-sensitive hashing of readmes\n",
      "\n",
      "Even if we find there is very little similarity, it might give us a handle on the levels of duplication going on"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "repos_df['tokens'] = repos_df['readme_tok']\n",
      "repos_df['index'] = repos_df.index\n",
      "repos_df['lsh_tuple'] = zip(repos_df.tokens,repos_df.index )\n",
      "repos_df.lsh_tuple.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'repos_df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-ccad0170f2c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrepos_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokens'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'readme_tok'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lsh_tuple'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepos_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrepos_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlsh_tuple\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'repos_df' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cache = lsh.LSHCache()\n",
      "dups = {}\n",
      "for t,i in zip(repos_df.tokens, range(0,repos_df.tokens.shape[0])):\n",
      "    dups[i] = cache.insert(t,i)\n",
      "#res = [cache.insert(t,i) for t,i in zip(repos_df.tokens, range(0,repos_df.tokens.shape[0]))]\n",
      "\n",
      "\n",
      "#cache.insert_batch(repos_df.lsh_tuple)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "object of type 'int' has no len()",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-20-f4b6fe2af784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlsh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSHCache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepos_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlsh_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#cache.insert_batch(repos_df.lsh_tuple)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/mackenza/Downloads/lsh/lsh/__init__.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, doc, id, date_added, passive)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_added\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpassive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mlsh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lsh_from_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id: %d lsh: %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mdup_buckets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insert_lsh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlsh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_added\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/mackenza/Downloads/lsh/lsh/__init__.py\u001b[0m in \u001b[0;36m_get_lsh_from_doc\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mgiven\u001b[0m \u001b[0man\u001b[0m \u001b[0miterable\u001b[0m \u001b[0mof\u001b[0m \u001b[0mhashable\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'got tokenized doc: len(doc)=%d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[0mshingle_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_shingle_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'got shingle_vec: len(shingle_vec)=%d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshingle_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
       ]
      }
     ],
     "prompt_number": 20
    }
   ],
   "metadata": {}
  }
 ]
}